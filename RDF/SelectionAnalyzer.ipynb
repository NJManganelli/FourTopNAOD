{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz --user\n",
    "#!echo $PYTHONPATH\n",
    "#!ls -ltr /eos/user/n/nmangane/.local/lib/python2.7/site-packages/\n",
    "#!export PATH=/eos/user/n/nmangane/.local/lib/python2.7/site-packages/:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import ROOT\n",
    "from IPython.display import Image, display, SVG\n",
    "#import graphviz\n",
    "ROOT.ROOT.EnableImplicitMT()\n",
    "RS = ROOT.ROOT\n",
    "RDF = RS.RDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"2017_booker.py\", \"r\") as f:\n",
    "    for line in f:\n",
    "        #print(line, end=\"\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME: Need filter efficiency calculated for single lepton generator filtered sample. First approximation will be from MCCM (0.15) but as seen before, it's not ideal. \n",
    "#May need to recalculate using genWeight/sumWeights instead of sign(genWeight)/(nPositiveEvents - nNegativeEvents), confirm if there's any difference.\n",
    "lumi = {\"2017\": 41.53,\n",
    "        \"2018\": 1}\n",
    "era = \"2017\"\n",
    "leg_dict = {\"tttt\": ROOT.kAzure-2,\n",
    "            \"ttbar\": ROOT.kRed,\n",
    "            \"singletop\": ROOT.kYellow,\n",
    "            \"ttH\": ROOT.kMagenta,\n",
    "            \"ttVJets\": ROOT.kViolet,\n",
    "            \"ttultrarare\": ROOT.kGreen,\n",
    "            \"DY\": ROOT.kCyan,\n",
    "            \"Data\": ROOT.kBlack,\n",
    "           }\n",
    "microbooker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017.root\",\n",
    "        },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017.root\",\n",
    "        },\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tW_2017.root\",\n",
    "        },\n",
    "}\n",
    "theOriginal = {\n",
    "    \"tttt_orig\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt-orig_2.root\",\n",
    "        },\n",
    "}\n",
    "booker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017.root\",\n",
    "        },\n",
    "    \"tt_SL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8836856,\n",
    "        \"nEventsPositive\": 8794464,\n",
    "        \"nEventsNegative\": 42392,\n",
    "        \"sumWeights\": 2653328498.476976,\n",
    "        \"sumWeights2\": 812201885978.209229,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 6,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL-GF_2017.root\",\n",
    "        },\n",
    "    \"tt_DL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8510388,\n",
    "        \"nEventsPositive\": 8467543,\n",
    "        \"nEventsNegative\": 42845,\n",
    "        \"sumWeights\": 612101836.284397,\n",
    "        \"sumWeights2\": 44925503249.097206,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1.4705,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL-GF-*_2017.root\",\n",
    "        },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL_2017.root\",\n",
    "        },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017.root\",\n",
    "        },\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tW_2017.root\",\n",
    "        },\n",
    "    \"ST_tbarW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7745276,\n",
    "        \"nEventsPositive\": 7715654,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 270762750.172525,\n",
    "        \"sumWeights2\": 9611964941.797768,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tbarW_2017.root\",\n",
    "        },\n",
    "    \"ttH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8000000,\n",
    "        \"nEventsPositive\": 7916867,\n",
    "        \"nEventsNegative\": 83133,\n",
    "        \"sumWeights\": 4216319.315884,\n",
    "        \"sumWeights2\": 2317497.816608,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.2934,\n",
    "        \"color\": leg_dict[\"ttH\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttH_2017.root\",\n",
    "        },\n",
    "    \"ttWJets\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 9425384,\n",
    "        \"nEventsPositive\": 9404856,\n",
    "        \"nEventsNegative\": 20528,\n",
    "        \"sumWeights\": 9384328.000000,\n",
    "        \"sumWeights2\": 9425384.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.611,\n",
    "        \"color\": leg_dict[\"ttVJets\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWJets_2017.root\",\n",
    "        },\n",
    "    \"ttZJets\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8536618,\n",
    "        \"nEventsPositive\": 8527846,\n",
    "        \"nEventsNegative\": 8772,\n",
    "        \"sumWeights\": 8519074.000000,\n",
    "        \"sumWeights2\": 8536618.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.783,\n",
    "        \"color\": leg_dict[\"ttVJets\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttZJets_2017.root\",\n",
    "        },\n",
    "    \"ttWH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199491,\n",
    "        \"nEventsNegative\": 509,\n",
    "        \"sumWeights\": 198839.680865,\n",
    "        \"sumWeights2\": 199704.039588,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.001572,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWH_2017.root\",\n",
    "        },\n",
    "    \"ttWW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 962000,\n",
    "        \"nEventsPositive\": 962000,\n",
    "        \"nEventsNegative\": 0,\n",
    "        \"sumWeights\": 962000.000000,\n",
    "        \"sumWeights2\": 962000.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.007882,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWW_2017.root\",\n",
    "        },\n",
    "    \"ttWZ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199379,\n",
    "        \"nEventsNegative\": 621,\n",
    "        \"sumWeights\": 198625.183551,\n",
    "        \"sumWeights2\": 199708.972601,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.002974,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWZ_2017.root\",\n",
    "        },\n",
    "    \"ttZZ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199686,\n",
    "        \"nEventsNegative\": 314,\n",
    "        \"sumWeights\": 199286.628891,\n",
    "        \"sumWeights2\": 199816.306332,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.001572,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttZZ_2017.root\",\n",
    "        },\n",
    "    \"ttZH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199643,\n",
    "        \"nEventsNegative\": 357,\n",
    "        \"sumWeights\": 199192.234990,\n",
    "        \"sumWeights2\": 199794.753976,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.01253,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttZH_2017.root\",\n",
    "        },\n",
    "    \"ttHH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 194817,\n",
    "        \"nEventsPositive\": 194516,\n",
    "        \"nEventsNegative\": 301,\n",
    "        \"sumWeights\": 194116.909912,\n",
    "        \"sumWeights2\": 194611.090542,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.0007408,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttHH_2017.root\",\n",
    "        },\n",
    "    \"tttW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199852,\n",
    "        \"nEventsNegative\": 148,\n",
    "        \"sumWeights\": 199552.187377,\n",
    "        \"sumWeights2\": 199697.648421,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.007882,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttW_2017.root\",\n",
    "        },\n",
    "    \"tttJ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199273,\n",
    "        \"nEventsNegative\": 727,\n",
    "        \"sumWeights\": 198394.878491,\n",
    "        \"sumWeights2\": 199663.384954,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.0004741,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttJ_2017.root\",\n",
    "        },\n",
    "    \"DYJets_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 49125561,\n",
    "        \"nEventsPositive\": 49103859,\n",
    "        \"nEventsNegative\": 21702,\n",
    "        \"sumWeights\": 49082157.000000,\n",
    "        \"sumWeights2\": 49125561.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 5075.6,\n",
    "        \"color\": leg_dict[\"DY\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/DYJets_DL_2017.root\",\n",
    "        },\n",
    "    \"ElMu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_B_2017.root\",\n",
    "        },\n",
    "    \"ElMu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 15595214,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_C_2017.root\",\n",
    "        },\n",
    "    \"ElMu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 9164365,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_D_2017.root\",\n",
    "        },\n",
    "    \"ElMu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 19043421,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_E_2017.root\",\n",
    "        },\n",
    "    \"ElMu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_F_2017.root\",\n",
    "        },\n",
    "}\n",
    "cutout = {\n",
    "    \"MuMu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 14501767,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_B_2017.root\",\n",
    "        },\n",
    "    \"MuMu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 49636525,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_C_2017.root\",\n",
    "        },\n",
    "    \"MuMu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 23075733,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_D_2017.root\",\n",
    "        },\n",
    "    \"MuMu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 51589091,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_E_2017.root\",\n",
    "        },\n",
    "    \"MuMu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 79756560,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_F_2017.root\",\n",
    "        },\n",
    "    \"ElEl_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 58088760,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_B_2017.root\",\n",
    "        },\n",
    "    \"ElEl_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 65181125,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_C_2017.root\",\n",
    "        },\n",
    "    \"ElEl_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 25911432,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_D_2017.root\",\n",
    "        },\n",
    "    \"ElEl_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 56233597,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_E_2017.root\",\n",
    "        },\n",
    "    \"ElEl_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 74307066,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_F_2017.root\",\n",
    "        },\n",
    "    \"Mu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136300266,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_B_2017.root\",\n",
    "        },\n",
    "    \"Mu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 165652756,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_C_2017.root\",\n",
    "        },\n",
    "    \"Mu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 70361660,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_D_2017.root\",\n",
    "        },\n",
    "    \"Mu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 154630534,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_E_2017.root\",\n",
    "        },\n",
    "    \"Mu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 242135500,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_F_2017.root\",\n",
    "        },\n",
    "    \"El_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 60537490,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_B_2017.root\",\n",
    "        },\n",
    "    \"El_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136637888,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_C_2017.root\",\n",
    "        },\n",
    "    \"El_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 51526710,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_D_2017.root\",\n",
    "        },\n",
    "    \"El_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 102121689,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_E_2017.root\",\n",
    "        },\n",
    "    \"El_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 128467223,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_F_2017.root\",\n",
    "        },\n",
    "    }\n",
    "minibooker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017.root\",\n",
    "        },\n",
    "    \"tt_SL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8836856,\n",
    "        \"nEventsPositive\": 8794464,\n",
    "        \"nEventsNegative\": 42392,\n",
    "        \"sumWeights\": 2653328498.476976,\n",
    "        \"sumWeights2\": 812201885978.209229,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 6,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL-GF_2017.root\",\n",
    "        },\n",
    "    \"tt_DL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8510388,\n",
    "        \"nEventsPositive\": 8467543,\n",
    "        \"nEventsNegative\": 42845,\n",
    "        \"sumWeights\": 612101836.284397,\n",
    "        \"sumWeights2\": 44925503249.097206,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1.4705,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL-GF-*_2017.root\",\n",
    "        },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL_2017.root\",\n",
    "        },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017.root\",\n",
    "        },\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tW_2017.root\",\n",
    "        },\n",
    "    \"ST_tbarW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7745276,\n",
    "        \"nEventsPositive\": 7715654,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 270762750.172525,\n",
    "        \"sumWeights2\": 9611964941.797768,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tbarW_2017.root\",\n",
    "        },\n",
    "\n",
    "    \"DYJets_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 49125561,\n",
    "        \"nEventsPositive\": 49103859,\n",
    "        \"nEventsNegative\": 21702,\n",
    "        \"sumWeights\": 49082157.000000,\n",
    "        \"sumWeights2\": 49125561.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 5075.6,\n",
    "        \"color\": leg_dict[\"DY\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/DYJets_DL_2017.root\",\n",
    "        },\n",
    "    \"MuMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 14501767 + 49636525 + 23075733 + 51589091 + 79756560,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_*_2017.root\",\n",
    "        },\n",
    "    \"ElEl\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 58088760 + 65181125 + 25911432 + 56233597 + 74307066,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_*_2017.root\",\n",
    "        },\n",
    "    \"ElMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465 + 15595214 + 9164365 + 19043421 + 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_*_2017.root\",\n",
    "        },\n",
    "    \"Mu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136300266 + 165652756 + 70361660 + 154630534 + 242135500,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_*_2017.root\",\n",
    "        },\n",
    "    \"El\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 60537490 + 136637888 + 51526710 + 102121689 + 128467223,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_*_2017.root\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "#Set up channel bits for selection and baseline. Separation not necessary in this stage, but convenient for loops\n",
    "Chan = {}\n",
    "Chan[\"ElMu_selection\"] = 24576\n",
    "Chan[\"MuMu_selection\"] = 6144\n",
    "Chan[\"ElEl_selection\"] = 512\n",
    "Chan[\"Mu_selection\"] = 128\n",
    "Chan[\"El_selection\"] = 64\n",
    "Chan[\"selection\"] = Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"] + Chan[\"Mu_selection\"] + Chan[\"El_selection\"]\n",
    "Chan[\"ElMu_baseline\"] = 24576\n",
    "Chan[\"MuMu_baseline\"] = 6144\n",
    "Chan[\"ElEl_baseline\"] = 512\n",
    "Chan[\"Mu_baseline\"] = 128\n",
    "Chan[\"El_baseline\"] = 64\n",
    "Chan[\"baseline\"] = Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"] + Chan[\"El_baseline\"]\n",
    "\n",
    "\n",
    "#samples[\"tt_DL-GF\"] = {}\n",
    "#samples[\"tt_DL-GF\"][\"path\"] = base + \"crab_tt_DL-GF_2017/results/tree*.root\"\n",
    "#booker[\"tttt\"]['nEvents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineLeptons(input_df, input_lvl_filter=None, channel=None, isData=True, useBackupChannel=False):\n",
    "    \"\"\"Function to take in a dataframe and return one with new columns defined,\n",
    "    plus event filtering based on the criteria defined inside the function\"\"\"\n",
    "    if channel == None:\n",
    "        raise RuntimeError(\"channel must be selected, such as 'MuMu' or 'ElMu'\")\n",
    "    elif channel == \"MuMu\":\n",
    "        nMuExp = 2\n",
    "        nElExp = 0\n",
    "    elif channel == \"ElMu\":\n",
    "        nMuExp = 1\n",
    "        nElExp = 1\n",
    "    elif channel == \"MuMu\":\n",
    "        nMuExp = 0\n",
    "        nElExp = 2\n",
    "        \n",
    "    #Set up channel bits for selection and baseline. Separation not necessary in this stage, but convenient for loops\n",
    "    Chan = {}\n",
    "    Chan[\"ElMu_selection\"] = 24576\n",
    "    Chan[\"MuMu_selection\"] = 6144\n",
    "    Chan[\"ElEl_selection\"] = 512\n",
    "    Chan[\"Mu_selection\"] = 128\n",
    "    Chan[\"El_selection\"] = 64\n",
    "    Chan[\"selection\"] = Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"] + Chan[\"Mu_selection\"] + Chan[\"El_selection\"]\n",
    "    Chan[\"ElMu_baseline\"] = 24576\n",
    "    Chan[\"MuMu_baseline\"] = 6144\n",
    "    Chan[\"ElEl_baseline\"] = 512\n",
    "    Chan[\"Mu_baseline\"] = 128\n",
    "    Chan[\"El_baseline\"] = 64\n",
    "    Chan[\"baseline\"] = Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"] + Chan[\"El_baseline\"]\n",
    "    b = {}\n",
    "    b[\"baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + \n",
    "                                                                            Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"] + Chan[\"El_baseline\"])\n",
    "    \n",
    "    b[\"ElMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) > 0\".format(Chan[\"ElMu_baseline\"])\n",
    "    b[\"MuMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"], \n",
    "                                                                                                                                Chan[\"MuMu_baseline\"])\n",
    "    b[\"ElEl_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"], \n",
    "                                                                                                                                Chan[\"ElEl_baseline\"])\n",
    "    b[\"Mu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"], Chan[\"Mu_baseline\"])\n",
    "    b[\"El_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + \n",
    "                                                                                                                    Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"], Chan[\"El_baseline\"])\n",
    "    b[\"selection\"] = \"ESV_TriggerAndLeptonLogic_selection > 0\"\n",
    "    b[\"ElMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) > 0\".format(Chan[\"ElMu_selection\"])\n",
    "    b[\"MuMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"], Chan[\"MuMu_selection\"])\n",
    "    b[\"ElEl_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"], Chan[\"ElEl_selection\"])\n",
    "    b[\"Mu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"], Chan[\"Mu_selection\"])\n",
    "    b[\"El_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"]\n",
    "                                                                                                                                 + Chan[\"Mu_selection\"], Chan[\"El_selection\"])\n",
    "    if input_lvl_filter == None:\n",
    "        rdf_input = input_df\\\n",
    "                .Define(\"mu_mask\", \"Muon_pt > 0\").Define(\"e_mask\", \"Electron_pt > 0\")\n",
    "    else:\n",
    "        if \"baseline\" in input_lvl_filter:\n",
    "            lvl_type = \"baseline\"\n",
    "        elif \"selection\" in input_lvl_filter:\n",
    "            lvl_type = \"selection\"\n",
    "        else:\n",
    "            raise RuntimeError(\"No such level permissable: must contain 'selection' or 'baseline'\")\n",
    "        rdf_input = input_df\\\n",
    "                .Filter(b[input_lvl_filter], input_lvl_filter)\\\n",
    "                .Define(\"mu_mask\", \"(Muon_OSV_{0} & {1}) > 0\".format(lvl_type, Chan[input_lvl_filter]))\\\n",
    "                .Define(\"e_mask\", \"(Electron_OSV_{0} & {1}) > 0\".format(lvl_type, Chan[input_lvl_filter]))\n",
    "    indexDefineCode = '''ROOT::VecOps::RVec<int> i({0}.size());\n",
    "                     std::iota(i.begin(), i.end(), 0);\n",
    "                     return i;'''\n",
    "    rdf = rdf_input\\\n",
    "                .Define(\"Muon_idx\", indexDefineCode.format(\"mu_mask\"))\\\n",
    "                .Define(\"GMuon_idx\", \"Muon_idx[mu_mask]\")\\\n",
    "                .Define(\"GMuon_pfIsoId\", \"Muon_pfIsoId[mu_mask]\")\\\n",
    "                .Define(\"GMuon_looseId\", \"Muon_looseId[mu_mask]\")\\\n",
    "                .Define(\"GMuon_pt\", \"Muon_pt[mu_mask]\")\\\n",
    "                .Define(\"GMuon_eta\", \"Muon_eta[mu_mask]\")\\\n",
    "                .Define(\"GMuon_phi\", \"Muon_phi[mu_mask]\")\\\n",
    "                .Define(\"GMuon_mass\", \"Muon_mass[mu_mask]\")\\\n",
    "                .Define(\"GMuon_charge\", \"Muon_charge[mu_mask]\")\\\n",
    "                .Define(\"GMuon_dz\", \"Muon_dz[mu_mask]\")\\\n",
    "                .Define(\"GMuon_d0\", \"sqrt(Muon_dz*Muon_dz + Muon_dxy*Muon_dxy)[mu_mask]\")\\\n",
    "                .Define(\"GMuon_ip3d\", \"Muon_ip3d[mu_mask]\")\\\n",
    "                .Define(\"GMuon_jetIdx\", \"Muon_jetIdx[mu_mask]\")\\\n",
    "                .Define(\"nGMuon\", \"GMuon_pt.size()\")\\\n",
    "                .Define(\"nLooseGMuon\", \"Muon_looseId[mu_mask && Muon_looseId == true].size()\")\\\n",
    "                .Define(\"nMediumGMuon\", \"Muon_mediumId[mu_mask && Muon_mediumId == true].size()\")\\\n",
    "                .Define(\"nTightGMuon\", \"Muon_tightId[mu_mask && Muon_tightId == true].size()\")\\\n",
    "                .Define(\"Electron_idx\", indexDefineCode.format(\"e_mask\"))\\\n",
    "                .Define(\"GElectron_idx\", \"Electron_idx[e_mask]\")\\\n",
    "                .Define(\"GElectron_cutBased\", \"Electron_cutBased[e_mask]\")\\\n",
    "                .Define(\"GElectron_pt\", \"Electron_pt[e_mask]\")\\\n",
    "                .Define(\"GElectron_eta\", \"Electron_eta[e_mask]\")\\\n",
    "                .Define(\"GElectron_phi\", \"Electron_phi[e_mask]\")\\\n",
    "                .Define(\"GElectron_mass\", \"Electron_mass[e_mask]\")\\\n",
    "                .Define(\"GElectron_charge\", \"Electron_charge[e_mask]\")\\\n",
    "                .Define(\"GElectron_dz\", \"Electron_dz[e_mask]\")\\\n",
    "                .Define(\"GElectron_d0\", \"sqrt(Electron_dz*Electron_dz + Electron_dxy*Electron_dxy)[e_mask]\")\\\n",
    "                .Define(\"GElectron_ip3d\", \"Electron_ip3d[e_mask]\")\\\n",
    "                .Define(\"GElectron_jetIdx\", \"Electron_jetIdx[e_mask]\")\\\n",
    "                .Define(\"nGElectron\", \"GElectron_pt.size()\")\\\n",
    "                .Define(\"nLooseGElectron\", \"Sum(GElectron_cutBased >= 2)\")\\\n",
    "                .Define(\"nMediumGElectron\", \"Sum(GElectron_cutBased >= 3)\")\\\n",
    "                .Define(\"nTightGElectron\", \"Sum(GElectron_cutBased >= 4)\")\\\n",
    "                .Define(\"GLepton_argsort\", \"Reverse(Argsort(Concatenate(Muon_pt[mu_mask], Electron_pt[e_mask])))\")\\\n",
    "                .Define(\"GLepton_pt\", \"Take(Concatenate(Muon_pt[mu_mask], Electron_pt[e_mask]), GLepton_argsort)\")\\\n",
    "                .Define(\"GLepton_eta\", \"Take(Concatenate(Muon_eta[mu_mask], Electron_eta[e_mask]), GLepton_argsort)\")\\\n",
    "                .Define(\"GLepton_phi\", \"Take(Concatenate(Muon_phi[mu_mask], Electron_phi[e_mask]), GLepton_argsort)\")\\\n",
    "                .Define(\"GLepton_jetIdx\", \"Take(Concatenate(Muon_jetIdx[mu_mask], Electron_jetIdx[e_mask]), GLepton_argsort)\")\\\n",
    "                .Define(\"GLepton_pdgId\", \"Take(Concatenate(Muon_pdgId[mu_mask], Electron_pdgId[e_mask]), GLepton_argsort)\")\\\n",
    "                .Define(\"nGLepton\", \"GLepton_pt.size()\")\\\n",
    "                .Define(\"GLepton_pt_lep0\", \"GLepton_pt.size() > 0 ? GLepton_pt.at(0) : -0.000000000001\")\\\n",
    "                .Define(\"GLepton_pt_lep1\", \"GLepton_pt.size() > 1 ? GLepton_pt.at(1) : -0.000000000001\")\\\n",
    "                .Define(\"GLepton_jetIdx_0\", \"GLepton_jetIdx.size() > 0 ? GLepton_jetIdx.at(0) : -1\")\\\n",
    "                .Define(\"GLepton_jetIdx_1\", \"GLepton_jetIdx.size() > 1 ? GLepton_jetIdx.at(1) : -1\")\n",
    "    #Things that don't work...\n",
    "    #NOPE doesn't work .Define(\"nLooseGMuon\", \"Sum(Muon_looseId[mu_mask])\")\\\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineWeights(input_df, crossSection=0, sumWeights=-1, lumi=0,\n",
    "                  nEvents=-1, nEventsPositive=2, nEventsNegative=1,\n",
    "                  channel=None, isData=True, verbose=False):\n",
    "    \n",
    "    mc_def = {}\n",
    "    mc_def[\"wgt_NUMW\"] = \"({xs:s} * {lumi:s} * 1000 * genWeight) / (abs(genWeight) * ( {nevtp:s} - {nevtn:s} ) )\"\\\n",
    "            .format(xs=str(crossSection), lumi=str(lumi), nevt=str(nEvents),\n",
    "                    nevtp=str(nEventsPositive), nevtn=str(nEventsNegative))\n",
    "    mc_def[\"wgt_SUMW\"] = \"({xs:s} * {lumi:s} * 1000 * genWeight) / {sumw:s}\"\\\n",
    "            .format(xs=str(crossSection), lumi=str(lumi), sumw=str(sumWeights))\n",
    "    mc_def[\"wgt_SUMW_PU\"] = \"wgt_SUMW * puWeight\"\n",
    "    data_def = {}\n",
    "    data_def[\"wgt_NUMW\"] = \"1\"\n",
    "    data_def[\"wgt_NUMW_V2\"] = \"1\"\n",
    "    data_def[\"wgt_SUMW\"] = \"1\"\n",
    "    data_def[\"wgt_SUMW_PU\"] = \"1\"\n",
    "    #data_def[\"wgt_SUMW_LSF\"] = \"1\"\n",
    "    if verbose == True:\n",
    "        print(\"===data and mc weight definitions===\")\n",
    "        print(data_def)\n",
    "        print(mc_def)\n",
    "    \n",
    "    if channel == \"MuMu\":\n",
    "        pass\n",
    "        #mc[\"wgt_SUMW_LSF\"] = \"wgt_SUMW*GMuon_\"\n",
    "        \n",
    "    if isData:\n",
    "        rdf = input_df\\\n",
    "                .Define(\"wgt_NUMW\", \"1\")\\\n",
    "                .Define(\"wgt_SUMW\", \"1\")\\\n",
    "                .Define(\"wgt_SUMW_PU\", \"1\")\\\n",
    "                .Define(\"wgt_SUMW_LSF\", \"1\")\\\n",
    "                .Define(\"wgt_diff\", \"abs(wgt_NUMW - wgt_SUMW)/max(abs(wgt_SUMW), abs(wgt_NUMW))\")\n",
    "    else:\n",
    "        rdf = input_df\\\n",
    "                .Define(\"wgt_NUMW\", mc_def[\"wgt_NUMW\"])\\\n",
    "                .Define(\"wgt_SUMW\", mc_def[\"wgt_SUMW\"])\\\n",
    "                .Define(\"wgt_SUMW_PU\", mc_def[\"wgt_SUMW\"])\\\n",
    "                .Define(\"wgt_diff\", \"abs(wgt_NUMW - wgt_SUMW)/max(abs(wgt_SUMW), abs(wgt_NUMW))\")\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineJets(input_df, era=\"2017\", doAK8Jets=False, debugInfo = True):\n",
    "    \"\"\"Function to take in a dataframe and return one with new columns defined,\n",
    "    plus event filtering based on the criteria defined inside the function\"\"\"\n",
    "    indexDefineCode = '''ROOT::VecOps::RVec<int> i({0}.size());\n",
    "                     std::iota(i.begin(), i.end(), 0);\n",
    "                     return i;'''\n",
    "    bTagWorkingPointDict = {\n",
    "        '2016':{\n",
    "            'DeepCSV':{'L': 0.2217, 'M': 0.6321, 'T': 0.8953, 'Var': 'btagDeepB'},\n",
    "            'DeepJet':{ 'L': 0.0614, 'M': 0.3093, 'T': 0.7221, 'Var': 'btagDeepFlavB'}\n",
    "        },\n",
    "        '2017':{\n",
    "            'CSVv2':{'L': 0.5803, 'M': 0.8838, 'T': 0.9693, 'Var': 'btagCSVV2'},\n",
    "            'DeepCSV':{'L': 0.1522, 'M': 0.4941, 'T': 0.8001, 'Var': 'btagDeepB'},\n",
    "            'DeepJet':{'L': 0.0521, 'M': 0.3033, 'T': 0.7489, 'Var': 'btagDeepFlavB'}\n",
    "        },\n",
    "        '2018':{\n",
    "            'DeepCSV':{'L': 0.1241, 'M': 0.4184, 'T': 0.7527, 'Var': 'btagDeepB'},\n",
    "            'DeepJet':{'L': 0.0494, 'M': 0.2770, 'T': 0.7264, 'Var': 'btagDeepFlavB'}\n",
    "        }\n",
    "    }\n",
    "    print(\"FIXMEFIXME: Setting Jet_pt min to 30GeV! Must fix!\")\n",
    "    rdf = input_df\\\n",
    "                .Define(\"jet_maskALT\", \"(Jet_OSV_baseline & {0}) > {0}\".format(23))\\\n",
    "                .Define(\"jet_submask\", \"(Jet_pt >= 20 && abs(Jet_eta) <= 2.5 && Jet_jetId > 2)\")\\\n",
    "                .Define(\"Jet_idx\", indexDefineCode.format(\"Jet_pt\"))\\\n",
    "                .Define(\"jet_mask\", \"(jet_submask && Jet_idx != GLepton_jetIdx_0 && Jet_idx != GLepton_jetIdx_1)\")\\\n",
    "                .Define(\"jet_ptsort\", \"Reverse(Argsort(Jet_pt[jet_mask]))\")\\\n",
    "                .Define(\"jet_deepcsvsort\", \"Reverse(Argsort(Jet_{0}[jet_mask]))\".format(bTagWorkingPointDict[era][\"DeepCSV\"][\"Var\"]))\\\n",
    "                .Define(\"jet_deepjetsort\", \"Reverse(Argsort(Jet_{0}[jet_mask]))\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"]))\n",
    "    rdf = rdf\\\n",
    "                .Define(\"GJet_idx\", \"Jet_idx[jet_mask]\")\\\n",
    "                .Define(\"GJet_pt\", \"Jet_pt[jet_mask]\")\\\n",
    "                .Define(\"GJet_eta\", \"Jet_eta[jet_mask]\")\\\n",
    "                .Define(\"GJet_phi\", \"Jet_phi[jet_mask]\")\\\n",
    "                .Define(\"GJet_mass\", \"Jet_mass[jet_mask]\")\\\n",
    "                .Define(\"GJet_jetId\", \"Jet_jetId[jet_mask]\")\\\n",
    "                .Define(\"nGJet\", \"GJet_pt.size()\")\n",
    "    rdf = rdf\\\n",
    "                .Define(\"GJet_btagDeepB\", \"Jet_btagDeepB[jet_mask]\")\\\n",
    "                .Define(\"GJet_btagDeepB_jet0\", \"GJet_btagDeepB.size() > 0 ? Reverse(Sort(GJet_btagDeepB)).at(0) : -0.000000000001\")\\\n",
    "                .Define(\"GJet_btagDeepB_jet1\", \"GJet_btagDeepB.size() > 1 ? Reverse(Sort(GJet_btagDeepB)).at(1) : -0.000000000001\")\\\n",
    "                .Define(\"GJet_btagDeepFlavB\", \"Jet_btagDeepFlavB[jet_mask]\")\\\n",
    "                .Define(\"GJet_btagDeepFlavB_sorted\", \"Take(Jet_btagDeepFlavB[jet_mask], jet_deepjetsort)\")\\\n",
    "                .Define(\"GJet_btagDeepFlavB_sorted_jet0\", \"GJet_btagDeepFlavB_sorted.size() > 0 ? GJet_btagDeepFlavB_sorted.at(0) : -0.000000000001\")\\\n",
    "                .Define(\"GJet_btagDeepFlavB_sorted_jet1\", \"GJet_btagDeepFlavB_sorted.size() > 1 ? GJet_btagDeepFlavB_sorted.at(1) : -0.000000000001\")\\\n",
    "                .Define(\"GJet_MediumDeepCSV\", \"GJet_{0}[GJet_{0} > {1}]\".format(bTagWorkingPointDict[era][\"DeepCSV\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepCSV\"][\"M\"]))\\\n",
    "                .Define(\"nGJet_MediumDeepCSV\", \"GJet_MediumDeepCSV.size()\")\\\n",
    "                .Define(\"GJet_MediumDeepJet\", \"GJet_{0}[GJet_{0} > {1}]\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepJet\"][\"M\"]))\\\n",
    "                .Define(\"nGJet_MediumDeepJet\", \"GJet_MediumDeepJet.size()\")\n",
    "    #These might be more efficiently calculated with my own custom code, instead of this... well, lets try for the sake of experimentation\n",
    "    #HT is just the sum of good jet pts\n",
    "    # HT2M is the sum of jet pt's for all but the two highest-b-tagged jets (2016 analysis requires 4+ jets to define this quantity), so here Take() is used twice.\n",
    "    # The first call acquires the good jet pt's sorted by b-tagging, the senond Take() gets the last n-2 elements, thereby excluding the two highest b-tagged jet's pt\n",
    "    # HTRat = HT(two highest b-tagged) / HT, so it's useful to define this similarly to HT2M (and crosscheck that HTNum + HT2M = HT!)\n",
    "    # H and H2M are defined similarly for the overall momentum magnitude...\n",
    "    # \n",
    "    rdf = rdf\\\n",
    "                .Define(\"GJet_HT\", \"Sum(GJet_pt)\")\\\n",
    "                .Define(\"GJet_pt_bsrt\", \"Take(GJet_pt, jet_deepjetsort)\")\\\n",
    "                .Define(\"GJet_eta_bsrt\", \"Take(GJet_eta, jet_deepjetsort)\")\\\n",
    "                .Define(\"GJet_phi_bsrt\", \"Take(GJet_phi, jet_deepjetsort)\")\\\n",
    "                .Define(\"GJet_P_bsrt\", \"GJet_pt_bsrt * ROOT::VecOps::sinh(GJet_eta_bsrt)\")\\\n",
    "                .Define(\"GJet_HT2M\", \"GJet_pt_bsrt.size() > 3 ? Sum(Take(GJet_pt_bsrt, (2 - GJet_pt_bsrt.size()))) : -0.1\")\\\n",
    "                .Define(\"GJet_HTNum\", \"GJet_pt_bsrt.size() > 3 ? Sum(Take(GJet_pt_bsrt, 2)) : -0.1\")\\\n",
    "                .Define(\"GJet_HTRat\", \"GJet_pt_bsrt.size() > 3 ? (GJet_HT2M / GJet_HT) : -0.1\")\\\n",
    "                .Define(\"GJet_dRbb\", \"GJet_pt_bsrt.size() > 3 ? ROOT::VecOps::DeltaR(GJet_eta_bsrt.at(0), GJet_eta_bsrt.at(1), GJet_phi_bsrt.at(0), GJet_phi_bsrt.at(1)) : -0.1\")\\\n",
    "                .Define(\"GJet_H\", \"Sum(GJet_P_bsrt)\")\\\n",
    "                .Define(\"GJet_H2M\", \"GJet_pt_bsrt.size() > 3 ? Sum(Take(GJet_P_bsrt, (2 - GJet_pt_bsrt.size()))) : -0.1\")\\\n",
    "                .Define(\"GJet_HTH\", \"GJet_HT/GJet_H\")\\\n",
    "                .Define(\"GJet_HTb\", \"Sum(GJet_pt[GJet_{0} > {1}])\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepJet\"][\"M\"]))\n",
    "    if debugInfo == True:\n",
    "        rdf = rdf\\\n",
    "                .Define(\"GJet_HT_matches\", \"GJet_HT == GJet_HTNum + GJet_HT2M\")\\\n",
    "                .Define(\"HT_Diff\", \"ESV_JetMETLogic_HT_selection - GJet_HT\")\\\n",
    "                .Define(\"GJet_ptALT\", \"Jet_pt[jet_maskALT]\")\\\n",
    "                .Define(\"GJet_etaALT\", \"Jet_eta[jet_maskALT]\")\\\n",
    "                .Define(\"GJet_phiALT\", \"Jet_phi[jet_maskALT]\")\\\n",
    "                .Define(\"GJet_massALT\", \"Jet_mass[jet_maskALT]\")\\\n",
    "                .Define(\"GJet_jetIdALT\", \"Jet_jetId[jet_maskALT]\")\\\n",
    "                .Define(\"DiffMaskVsALT\", \"GJet_ptALT.size() - GJet_pt.size()\")\\\n",
    "                .Define(\"DiffnJet\", \"nGJet - ESV_JetMETLogic_nJet_selection\")\\\n",
    "                .Define(\"Jet_dR_lep0\", \"GLepton_jetIdx_0 > -1 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_0), GLepton_eta.at(0), Jet_phi.at(GLepton_jetIdx_0), GLepton_phi.at(0)) : -0.01\")\\\n",
    "                .Define(\"Jet_dR_lep1\", \"GLepton_jetIdx_1 > -1 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_1), GLepton_eta.at(1), Jet_phi.at(GLepton_jetIdx_1), GLepton_phi.at(1)) : -0.01\")\\\n",
    "                .Define(\"GJet_btagDeepFlavB_jet0Med\", \"GJet_MediumDeepJet.size() > 0 ? Reverse(Sort(GJet_MediumDeepJet)).at(0) : -0.000000000001\")\\\n",
    "                .Define(\"GJet_btagDeepFlavB_jet1Med\", \"GJet_MediumDeepJet.size() > 1 ? Reverse(Sort(GJet_MediumDeepJet)).at(1) : -0.000000000001\")\\\n",
    "                .Define(\"DeepJetSorted\", \"GJet_btagDeepFlavB_sorted.size() > 1 ? (GJet_btagDeepFlavB_sorted.at(0) >= GJet_btagDeepFlavB_sorted.at(1)) : true\")\\\n",
    "                .Define(\"DeepJet0Minus1\", \"GJet_btagDeepFlavB_sorted.size() > 1 ? (GJet_btagDeepFlavB_sorted.at(0) - GJet_btagDeepFlavB_sorted.at(1)) : 0\")\\\n",
    "                .Define(\"MediumDeepJetSorted\", \"GJet_MediumDeepJet.size() > 1 ? (Reverse(Sort(GJet_MediumDeepJet)).at(0) >= Reverse(Sort(GJet_MediumDeepJet)).at(1)) : true\")\\\n",
    "                .Define(\"MediumDeepJet0Minus1\", \"GJet_MediumDeepJet.size() > 1 ? (Reverse(Sort(GJet_MediumDeepJet)).at(0) - Reverse(Sort(GJet_MediumDeepJet)).at(1)) : 0\")\n",
    "    return rdf\n",
    "    #Code taht doesn't work...\n",
    "    #Can see that the jets are in fact not sorted when calling Reverse(GJet_MediumDeepJet).at(0), for example, as the one .at(1) can sometimes not be smaller\n",
    "    #Looking at the definition makes it obvious, because Reverse is not short for \"ReverseSort\" but is literally just std::reverse. Must call (Arg)sort first...\n",
    "    #Definig a functor in the string like this doesn't work either:\n",
    "    #.Define(\"GJet_btagDeepB_jet0\", \"GJet_btagDeepB.size() > 0 ? Sort(GJet_btagDeepB, [](double x, double y) {return x > y;}).at(0) : -0.000000000001\")\\\n",
    "    #Cannot use ternary operator with RVec and double return types (Take(...) : -0.0000000001)\n",
    "    #.Define(\"GJet_btagDeepFlavB_jet0\", \"GJet_btagDeepFlavB.size() > 0 ? Take(Reverse(GJet_btagDeepFlavB), {0}) : -0.000000000001\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineEventVars(input_df):\n",
    "    rdf = input_df\\\n",
    "            .Define(\"JML_baseline_pass\", \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00001100011111111111))\\\n",
    "            .Define(\"JML_selection_pass\", \"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00001100011111111111))\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillHistos(input_df, input_name=None, wgtVar=\"wgt_SUMW\", histos1D_dict=None, histos2D_dict=None, histosNS_dict=None, \n",
    "               doMuons=False, doElectrons=False, doLeptons=False, doJets=False, doWeights=False, doEventVars=False, debugInfo=True):\n",
    "    \"\"\"Method to fill histograms given an input RDataFrame, input sample/dataset name, input histogram dictionaries.\n",
    "    Has several options of which histograms to fill, such as Leptons, Jets, Weights, EventVars, etc.\n",
    "    Types of histograms (1D, 2D, those which will not be stacked(NS - histosNS)) are filled by passing non-None\n",
    "    value to that histosXX_dict variable. Internally stored with structure separating the categories of histos,\n",
    "    with 'Muons,' 'Electrons,' 'Leptons,' 'Jets,' 'EventVars,' 'Weights' subcategories.\"\"\"\n",
    "    if doMuons == False and doElectrons == False and doLeptons == False\\\n",
    "                and doJets==False and doWeights==False and doEventVars==False:\n",
    "        raise RuntimeError(\"Must select something to plot:\"\\\n",
    "                               \"Set do{Muons,Electrons,Leptons,Jets,Weights,EventVars,etc} = True in init method\")\n",
    "    \n",
    "    pi = ROOT.TMath.Pi()\n",
    "    if doWeights == True:\n",
    "        if histosNS_dict != None:\n",
    "            if \"EventVars\" not in histosNS_dict:\n",
    "                histosNS_dict[\"EventVars\"] = {}\n",
    "            histosNS[name][lvl][\"EventVars\"][\"wgt_NUMW\"] = input_df.Histo1D(\"wgt_NUMW\")\n",
    "            histosNS[name][lvl][\"EventVars\"][wgtVar] = input_df.Histo1D(wgtVar)\n",
    "        if histos1D_dict != None:\n",
    "            if \"EventVars\" not in histos1D_dict:\n",
    "                histos1D_dict[\"EventVars\"] = {}\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_diff\"] = input_df.Histo1D((\"wgt_diff\", \n",
    "                                                                    \"(wgt_NUMW - wgt_SUMW)/wgt_SUMW\", \n",
    "                                                                    2000, -1, 1), \"wgt_diff\")\n",
    "    if doMuons == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Muons\" not in histos1D_dict: \n",
    "                histos1D_dict[\"Muons\"] = {}\n",
    "            histos1D_dict[\"Muons\"][\"idx\"] = input_df.Histo1D((\"idx_({})\".format(wgtVar), \"\", 5, 0, 5), \"Muon_idx\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"Gidx\"] = input_df.Histo1D((\"Gidx_({})\".format(wgtVar), \"\", 5, 0, 5), \"GMuon_idx\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"nMu\"] = input_df.Histo1D((\"nMuon_({})\".format(wgtVar), \"\", 5, 0, 5), \"nGMuon\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"nLooseMu\"] = input_df.Histo1D((\"nLooseMuon_({})\".format(wgtVar), \"\", 5, 0, 5), \"nLooseGMuon\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"nMediumMu\"] = input_df.Histo1D((\"nMediumMuon_({})\".format(wgtVar), \"\", 5, 0, 5), \"nMediumGMuon\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"pt\"] = input_df.Histo1D((\"Muon_pt_({})\".format(wgtVar), \"\", 100, 0, 500), \"GMuon_pt\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"eta\"] = input_df.Histo1D((\"Muon_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GMuon_eta\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"phi\"] = input_df.Histo1D((\"Muon_phi_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GMuon_phi\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"mass\"] = input_df.Histo1D((\"Muon_mass_({})\".format(wgtVar), \"\", 50, 0, 1), \"GMuon_mass\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"iso\"] = input_df.Histo1D((\"Muon_iso_({})\".format(wgtVar), \"\", 8, 0, 8), \"GMuon_pfIsoId\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"dz\"] = input_df.Histo1D((\"Muon_dz_({})\".format(wgtVar), \"\", 100, -0.01, 0.01), \"GMuon_dz\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"d0\"] = input_df.Histo1D((\"Muon_d0_({})\".format(wgtVar), \"\", 100, -0.01, 0.01), \"GMuon_d0\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"ip3d\"] = input_df.Histo1D((\"Muon_ip3d_({})\".format(wgtVar), \"\", 100, -0.01, 0.01), \"GMuon_ip3d\", wgtVar)\n",
    "        if histos2D_dict != None:\n",
    "            if \"Muons\" not in histos2D_dict:\n",
    "                histos2D_dict[\"Muons\"] = {}\n",
    "            histos2D_dict[\"Muons\"][\"eta_phi\"] = input_df.Histo2D((\"Muon_eta_phi_({})\".format(wgtVar), \"\",\n",
    "                                                                  104, -2.6, 2.6,\n",
    "                                                                  64, -pi, pi),\n",
    "                                                                 \"GMuon_eta\", \"GMuon_phi\", wgtVar)\n",
    "            histos2D_dict[\"Muons\"][\"dz_ip3d\"] = input_df.Histo2D((\"Muon_dz_ip3d_({})\".format(wgtVar), \"\",\n",
    "                                                                  100, -0.01, 0.01,\n",
    "                                                                  100, 0, 0.01),\n",
    "                                                                 \"GMuon_dz\", \"GMuon_ip3d\", wgtVar)\n",
    "    if doElectrons == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Electrons\" not in histos1D_dict: \n",
    "                histos1D_dict[\"Electrons\"] = {}\n",
    "            histos1D_dict[\"Electrons\"][\"nEl\"] = input_df.Histo1D((\"nElectron_({})\".format(wgtVar), \"\", 5, 0, 5), \"nGElectron\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"nLooseEl\"] = input_df.Histo1D((\"nLooseElectron_({})\".format(wgtVar), \"\", 5, 0, 5), \"nLooseGElectron\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"nMediumEl\"] = input_df.Histo1D((\"nMediumElectron_({})\".format(wgtVar), \"\", 5, 0, 5), \"nMediumGElectron\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"pt\"] = input_df.Histo1D((\"Electron_pt_({})\".format(wgtVar), \"\", 100, 0, 500), \"GElectron_pt\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"eta\"] = input_df.Histo1D((\"Electron_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GElectron_eta\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"phi\"] = input_df.Histo1D((\"Electron_phi_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GElectron_phi\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"mass\"] = input_df.Histo1D((\"Electron_mass_({})\".format(wgtVar), \"\", 50, 0, 1), \"GElectron_mass\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"dz\"] = input_df.Histo1D((\"Electron_dz_({})\".format(wgtVar), \"\", 100, -0.01, 0.01), \"GElectron_dz\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"d0\"] = input_df.Histo1D((\"Electron_d0_({})\".format(wgtVar), \"\", 100, 0, 0.01), \"GElectron_d0\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"ip3d\"] = input_df.Histo1D((\"Electron_ip3d_({})\".format(wgtVar), \"\", 100, 0, 0.01), \"GElectron_ip3d\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"cutBased\"] = input_df.Histo1D((\"Electron_cutBased_({})\".format(wgtVar), \"\", 5, 0, 5), \"GElectron_cutBased\", wgtVar)\n",
    "        if histos2D_dict != None:\n",
    "            if \"Electrons\" not in histos2D_dict: \n",
    "                histos2D_dict[\"Electrons\"] = {}\n",
    "            histos2D_dict[\"Electrons\"][\"eta_phi\"] = input_df.Histo2D((\"Electron_eta_phi_({})\".format(wgtVar), \"\",\n",
    "                                                                      104, -2.6, 2.6,\n",
    "                                                                      64, -pi, pi),\n",
    "                                                                     \"GElectron_eta\", \"GElectron_phi\", wgtVar)\n",
    "            histos2D_dict[\"Electrons\"][\"dz_ip3d\"] = input_df.Histo2D((\"Electron_dz_ip3d_({})\".format(wgtVar), \"\",\n",
    "                                                                      100, -0.01, 0.01,\n",
    "                                                                      100, 0, 0.01),\n",
    "                                                                     \"GElectron_dz\", \"GElectron_ip3d\", wgtVar)\n",
    "    if doLeptons == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Leptons\" not in histos1D_dict: \n",
    "                histos1D_dict[\"Leptons\"] = {}\n",
    "            histos1D_dict[\"Leptons\"][\"pt_lep0\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_pt_lep0_({})\".format(wgtVar), \"\", 100, 0, 500),\"GLepton_pt_lep0\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"pt_lep1\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_pt_lep1_({})\".format(wgtVar), \"\", 100, 0, 500),\"GLepton_pt_lep1\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"eta\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6),\"GLepton_eta\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"phi\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_phi_({})\".format(wgtVar), \"\", 64, -pi, pi),\"GLepton_phi\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"nLepton\"] = input_df\\\n",
    "                    .Histo1D((\"nLepton_({})\".format(wgtVar), \"\", 5, 0, 5), \"nGLepton\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"pdgId\"] = input_df\\\n",
    "                    .Histo1D((\"Lepton_pdgId_({})\".format(wgtVar), \"\", 32, -16, 16), \"GLepton_pdgId\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"jetIdx\"] = input_df\\\n",
    "                    .Histo1D((\"Lepton_jetIdx_({})\".format(wgtVar), \"\", 20, 0, 20), \"GLepton_jetIdx\", wgtVar)\n",
    "    if doJets == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Jets\" not in histos1D_dict:\n",
    "                histos1D_dict[\"Jets\"] = {}\n",
    "            histos1D_dict[\"Jets\"][\"pt\"] = input_df.Histo1D((\"Jet_pt_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_pt\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"eta\"] = input_df.Histo1D((\"Jet_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GJet_eta\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"phi\"] = input_df.Histo1D((\"Jet_phi_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GJet_phi\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"mass\"] = input_df.Histo1D((\"Jet_mass_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_mass\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"jetId\"] = input_df.Histo1D((\"Jet_jetId_({})\".format(wgtVar), \"\", 8, 0, 8), \"GJet_jetId\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepB_jet0\"] = input_df.Histo1D((\"Jet_btagDeepB_jet0_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepB_jet0\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepB_jet1\"] = input_df.Histo1D((\"Jet_btagDeepB_jet1_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepB_jet1\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepJet_jet0\"] = input_df.Histo1D((\"Jet_btagDeepJetB_jet0_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepFlavB_sorted_jet0\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepJet_jet1\"] = input_df.Histo1D((\"Jet_btagDeepJetB_jet1_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepFlavB_sorted_jet1\", wgtVar)\n",
    "            #histos1D_dict[\"Jets\"][\"nMediumCSVv2\"] = input_df.Histo1D((\"nJet_MediumCSVv2_({})\".format(wgtVar), \"\", 10, 0, 10), \"nGJet_MediumCSVv2\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"nMediumDeepCSV\"] = input_df.Histo1D((\"nJet_MediumDeepCSV_({})\".format(wgtVar), \"\", 10, 0, 10), \"nGJet_MediumDeepCSV\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"nMediumDeepJet\"] = input_df.Histo1D((\"nJet_MediumDeepJet_({})\".format(wgtVar), \"\", 10, 0, 10), \"nGJet_MediumDeepJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"nJet\"] = input_df.Histo1D((\"nJet_({})\".format(wgtVar), \"\", 15, 0, 15), \"nGJet\", wgtVar)\n",
    "            if debugInfo == True:\n",
    "                histos1D_dict[\"Jets\"][\"DiffMaskVsALT\"] = input_df.Histo1D((\"DiffMaskVsALT\", \"\", 10, -10, 10), \"DiffMaskVsALT\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"DiffnJet\"] = input_df.Histo1D((\"DiffnJet\", \"\", 10, -10, 10), \"DiffnJet\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"Jet_dR_lep0\"] = input_df.Histo1D((\"Jet_dR_lep0_({})\".format(wgtVar), \"\", 40, 0, 0.8), \"Jet_dR_lep0\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"Jet_dR_lep1\"] = input_df.Histo1D((\"Jet_dR_lep1_({})\".format(wgtVar), \"\", 40, 0, 0.8), \"Jet_dR_lep1\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"DeepJetSorted\"] = input_df.Histo1D(\"DeepJetSorted\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"DeepJet0Minus1\"] = input_df.Histo1D((\"DeepJet0Minus1\", \"\", 100, -1, 1), \"DeepJet0Minus1\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"MediumDeepJetSorted\"] = input_df.Histo1D(\"MediumDeepJetSorted\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"MediumDeepJet0Minus1\"] = input_df.Histo1D((\"MediumDeepJet0Minus1\", \"\", 100, -1, 1), \"MediumDeepJet0Minus1\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"btagDeepJet_jet0Med\"] = input_df.Histo1D((\"Jet_btagDeepJetB_jet0Med_({})\".format(wgtVar), \"\", 102, -0.02, 1), \"GJet_btagDeepFlavB_jet0Med\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"btagDeepJet_jet1Med\"] = input_df.Histo1D((\"Jet_btagDeepJetB_jet1Med_({})\".format(wgtVar), \"\", 102, -0.02, 1), \"GJet_btagDeepFlavB_jet1Med\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"nJetNUMW\"] = input_df.Histo1D((\"nJet_NUMW\", \"\", 15, 0, 15), \"nGJet\", \"wgt_NUMW_V2\")\n",
    "                #histos1D_dict[\"Jets\"][\"nJetSUMW_PU\"] = input_df.Histo1D((\"nJet_SUMW_PU\", \"\", 15, 0, 15), \"nGJet\", \"wgt_SUMW_PU\")\n",
    "                #histos1D_dict[\"Jets\"][\"nJetSUMW_LSF\"] = input_df.Histo1D((\"nJet_SUMW_LSF\", \"\", 15, 0, 15), \"nGJet\", \"wgt_SUMW_LSF\")\n",
    "                #histos1D_dict[\"Jets\"][\"ptALT\"] = input_df.Histo1D((\"Jet_ptALT_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_ptALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"etaALT\"] = input_df.Histo1D((\"Jet_etaALT_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GJet_etaALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"phiALT\"] = input_df.Histo1D((\"Jet_phiALT_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GJet_phiALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"massALT\"] = input_df.Histo1D((\"Jet_massALT_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_massALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"jetIdALT\"] = input_df.Histo1D((\"Jet_jetIdALT_({})\".format(wgtVar), \"\", 8, 0, 8), \"GJet_jetIdALT\", wgtVar)\n",
    "        if histos2D_dict != None:\n",
    "            if \"Jets\" not in histos2D_dict:\n",
    "                histos2D_dict[\"Jets\"] = {}\n",
    "            histos2D_dict[\"Jets\"][\"eta_phi\"] = input_df.Histo2D((\"Jet_eta_phi_({})\".format(wgtVar), \"\",\n",
    "                                                                 104, -2.6, 2.6,\n",
    "                                                                 64, -pi, pi),\n",
    "                                                                \"GJet_eta\", \"GJet_phi\", wgtVar)\n",
    "    if doEventVars == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"EventVars\" not in histos1D_dict:\n",
    "                histos1D_dict[\"EventVars\"] = {}\n",
    "            #histos1D_dict[\"EventVars\"][\"JML_baseline\"] = input_df.Histo1D((\"JML_baseline_({})\".format(wgtVar), \"\", 2,0,2), \"JML_baseline_pass\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"JML_selection\"] = input_df.Histo1D((\"JML_selection_({})\".format(wgtVar), \"\", 2,0,2), \"JML_selection_pass\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HT_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT_baseline_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_HT_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"H_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_H_baseline_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_H_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HT2M_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT2M_baseline_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HT2M_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"H2M_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_H2M_baseline_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_H2M_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTb_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTb_baseline_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HTb_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTH_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTH_baseline_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTH_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTRat_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTRat_baseline_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTRat_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"dRbb_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_dRbb_baseline_({})\".format(wgtVar), \"\", 64,0,2*pi), \"ESV_JetMETLogic_dRbb_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"DiLepMass_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_DiLepMass_baseline_({})\".format(wgtVar), \"\", 100,0,500), \"ESV_JetMETLogic_DiLepMass_baseline\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HT_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT_selection_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_HT_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"H_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_H_selection_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_H_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HT2M_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT2M_selection_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HT2M_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"H2M_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_H2M_selection_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_H2M_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTb_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTb_selection_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HTb_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTH_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTH_selection_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTH_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTRat_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTRat_selection_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTRat_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dRbb_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_dRbb_selection_({})\".format(wgtVar), \"\", 64,0,2*pi), \"ESV_JetMETLogic_dRbb_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"DiLepMass_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_DiLepMass_selection_({})\".format(wgtVar), \"\", 100,0,500), \"ESV_JetMETLogic_DiLepMass_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HT\"] = input_df.Histo1D((\"HT_({})\".format(wgtVar), \"\", 100,400,1400), \"GJet_HT\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"H\"] = input_df.Histo1D((\"H_({})\".format(wgtVar), \"\", 100,400,1400), \"GJet_H\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HT2M\"] = input_df.Histo1D((\"HT2M_({})\".format(wgtVar), \"\", 100,400,900), \"GJet_HT2M\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"H2M\"] = input_df.Histo1D((\"H2M_({})\".format(wgtVar), \"\", 100,400,900), \"GJet_H2M\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTb\"] = input_df.Histo1D((\"HTb_({})\".format(wgtVar), \"\", 100,400,900), \"GJet_HTb\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTH\"] = input_df.Histo1D((\"HTH_({})\".format(wgtVar), \"\", 100,0,1), \"GJet_HTH\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTRat\"] = input_df.Histo1D((\"HTRat_({})\".format(wgtVar), \"\", 100,0,1), \"GJet_HTRat\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dRbb\"] = input_df.Histo1D((\"dRbb_({})\".format(wgtVar), \"\", 64,0,2*pi), \"GJet_dRbb\", wgtVar)\n",
    "            if debugInfo == True:\n",
    "                histos1D_dict[\"EventVars\"][\"GJet_HT_Match\"] = input_df.Histo1D((\"GJet_HT_Match_({})\".format(wgtVar), \"\", 2,0,2), \"GJet_HT_matches\", wgtVar)\n",
    "                histos1D_dict[\"EventVars\"][\"HT_Diff\"] = input_df.Histo1D((\"HT_Diff_({})\".format(wgtVar), \"\", 200,-250,250), \"HT_Diff\", wgtVar)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jet bit dictionary, for reference\n",
    "JMLpassbits = {'PV_minNDoF':                            0b00000000000000000001,\n",
    "                 'PV_maxAbsZ':                            0b00000000000000000010,\n",
    "                 'PV_maxRho':                             0b00000000000000000100,\n",
    "                 'MET_globalSuperTightHalo2016Filter':    0b00000000000000001000,\n",
    "                 'MET_goodVertices':                      0b00000000000000010000,\n",
    "                 'MET_HBHENoiseFilter':                   0b00000000000000100000,\n",
    "                 'MET_HBHENoiseIsoFilter':                0b00000000000001000000,\n",
    "                 'MET_EcalDeadCellTriggerPrimitiveFilter':0b00000000000010000000,\n",
    "                 'MET_BadPFMuonFilter':                   0b00000000000100000000,\n",
    "                 'MET_ecalBadCalibFilterV2':              0b00000000001000000000,\n",
    "                 'MET_pt':                                0b00000000010000000000,\n",
    "                 'unused1':                               0b00000000100000000000, #N\n",
    "                 'Lepton_ZWindow':                        0b00000001000000000000, #N\n",
    "                 'Jet_nJet25':                            0b00000010000000000000, #N\n",
    "                 'Jet_nJet20':                            0b00000100000000000000,\n",
    "                 'HT':                                    0b00001000000000000000,\n",
    "                 'Jet_nBJet_2DCSV':                       0b00010000000000000000, #N\n",
    "                 'Jet_nBJet_2DJet':                       0b00100000000000000000, #N\n",
    "                 'unused2':                               0b01000000000000000000, #N\n",
    "                 'unused3':                               0b10000000000000000000, #N\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##################################################\n",
    "### CHOOSE SAMPLE DICT AND CHANNEL TO ANALYZE ####\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    "#Focus on limited set of events at a time\n",
    "levels_of_interest = set([\"ElMu_selection\"])\n",
    "#levels_of_interest = set([\"selection\", \"ElMu_selection\", \"ElEl_selection\", \"MuMu_selection\", \"Mu_selection\", \"El_selection\"])\n",
    "#levels_of_interest = set([\"baseline\", \"MuMu_baseline\", \"ElEl_baseline\", \"selection\", \"MuMu_selection\", \"ElMu_selection\"])\n",
    "#levels_of_interest = set([\"baseline\", \"MuMu_selection\", \"ElMu_selection\"])\n",
    "\n",
    "#Choose the sample dictionary to run\n",
    "theSampleDict = microbooker #tttt, ttbar-DL unfiltered, DY, one single top sample\n",
    "#theSampleDict = minibooker #tttt, all ttbar, both single top, DY\n",
    "#theSampleDict = booker #All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating selection and baseline bits\")\n",
    "b = {}\n",
    "b[\"ElMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) > 0\".format(Chan[\"ElMu_baseline\"])\n",
    "b[\"MuMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"], \n",
    "                                                                                                                                Chan[\"MuMu_baseline\"])\n",
    "b[\"ElEl_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"], \n",
    "                                                                                                                                Chan[\"ElEl_baseline\"])\n",
    "b[\"Mu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"], Chan[\"Mu_baseline\"])\n",
    "b[\"El_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + \n",
    "                                                                                                                    Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"], Chan[\"El_baseline\"])\n",
    "b[\"selection\"] = \"ESV_TriggerAndLeptonLogic_selection > 0\"\n",
    "b[\"ElMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) > 0\".format(Chan[\"ElMu_selection\"])\n",
    "b[\"MuMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"], Chan[\"MuMu_selection\"])\n",
    "b[\"ElEl_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"], Chan[\"ElEl_selection\"])\n",
    "b[\"Mu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"], Chan[\"Mu_selection\"])\n",
    "b[\"El_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"]\n",
    "                                                                            + Chan[\"Mu_selection\"], Chan[\"El_selection\"]) \n",
    "b[\"ESV_JetMETLogic_baseline\"] = \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00001100011111111111)\n",
    "#b[\"ESV_JetMETLogic_selection\"] = \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00001100011111111111) #FIXME, this isn't right!\n",
    "b[\"ESV_JetMETLogic_selection\"] = \"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00001100011111111111)\n",
    "b[\"ESV_JetMETLogic_default\"] = \"(ESV_JetMETLogic_baseline & {}) > 0\".format(0b11111111111111111111)\n",
    "#print(b[\"ESV_JetMETLogic_selection\"])\n",
    "\n",
    "\n",
    "\n",
    "filtered = {}\n",
    "for name, vals in theSampleDict.items():\n",
    "    if name == \"tttt_orig\": continue\n",
    "    print(\"Booking - {}\".format(name))\n",
    "    filtered[name] = {}\n",
    "    for lvl in levels_of_interest:\n",
    "        if \"baseline\" in lvl:\n",
    "            JMLOG = \"ESV_JetMETLogic_baseline\"\n",
    "        elif \"selection\" in lvl:\n",
    "            JMLOG = \"ESV_JetMETLogic_selection\"\n",
    "        else:\n",
    "            JMLOG = \"ESV_JetMETLogic_default\"\n",
    "        if lvl == \"baseline\":\n",
    "            filtered[name][lvl] = RDF(\"Events\", vals[\"source\"]).Filter(b[JMLOG], JMLOG)#.Cache()\n",
    "        else:\n",
    "            filtered[name][lvl] = RDF(\"Events\", vals[\"source\"]).Filter(b[lvl], lvl).Filter(b[JMLOG], JMLOG)#.Cache()\n",
    "        #Cache() seemingly has an issue with the depth/breadth of full NanoAOD file. Perhaps one with fewer branches would work\n",
    "        #filtered[name][lvl] = filtered[name][lvl].Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = {}\n",
    "counts = {}\n",
    "histos1D = {}\n",
    "histos1D_PU = {}\n",
    "histos2D = {}\n",
    "histosNS = {} #unstacked histograms\n",
    "the_df = {}\n",
    "print(\"Starting loop for booking\")\n",
    "for name, vals in theSampleDict.items():\n",
    "    if name == \"tttt_orig\": continue\n",
    "    #if name not in [\"tttt\", \"ElMu_F\"]: continue\n",
    "    print(\"Booking - {}\".format(name))\n",
    "    counts[name] = {}\n",
    "    histos1D[name] = {}\n",
    "    histos1D_PU[name] = {}\n",
    "    histos2D[name] = {}\n",
    "    histosNS[name] = {}\n",
    "    the_df[name] = {}\n",
    "    #counts[name][\"baseline\"] = filtered[name].Count() #Unnecessary with baseline in levels of interest?\n",
    "    for lvl in levels_of_interest:\n",
    "        the_df[name][lvl] = defineLeptons(filtered[name][lvl], \n",
    "                                            input_lvl_filter=lvl, \n",
    "                                            channel=\"MuMu\", \n",
    "                                            isData=vals[\"isData\"], \n",
    "                                            useBackupChannel=False)\n",
    "        if vals[\"isData\"] == False:\n",
    "            the_df[name][lvl] = defineWeights(the_df[name][lvl],\n",
    "                                            crossSection=vals[\"crossSection\"], \n",
    "                                            sumWeights=vals[\"sumWeights\"], \n",
    "                                            lumi=lumi[era],\n",
    "                                            nEvents=vals[\"nEvents\"], \n",
    "                                            nEventsPositive=vals[\"nEventsPositive\"], \n",
    "                                            nEventsNegative=vals[\"nEventsNegative\"],\n",
    "                                            channel=\"MuMu\", \n",
    "                                            isData=vals[\"isData\"], \n",
    "                                            verbose=True,)\n",
    "        else:\n",
    "            the_df[name][lvl] = defineWeights(the_df[name][lvl],\n",
    "                                             isData=True,\n",
    "                                             verbose=True)\n",
    "        the_df[name][lvl] = defineJets(the_df[name][lvl],\n",
    "                                       era=\"2017\",\n",
    "                                      )\n",
    "        the_df[name][lvl] = defineEventVars(the_df[name][lvl])\n",
    "        the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet > 3\", \"nJet\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet_MediumDeepCSV > 1\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet_MediumDeepJet > 1\", \"nMedDeepJet\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"METFixEE2017_pt > 50\", \"MET > 50\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"ESV_JetMETLogic_HT_selection > 500\", \"HT_slctn > 500\")\n",
    "        counts[name][lvl] = the_df[name][lvl].Count()\n",
    "        histos1D[name][lvl] = {}\n",
    "        histos1D_PU[name][lvl] = {}\n",
    "        histosNS[name][lvl] = {}\n",
    "        histos2D[name][lvl] = {}\n",
    "#        fillHistos(the_df[name][lvl], wgtVar=\"wgt_SUMW_PU\", histos1D_dict=histos1D[name][lvl], \n",
    "#                   histos2D_dict=histos2D[name][lvl], histosNS_dict=histosNS[name][lvl],\n",
    "#                   doMuons=True, doElectrons=True, doLeptons=True, \n",
    "#                   doJets=True, doWeights=True, doEventVars=True)\n",
    "        fillHistos(the_df[name][lvl], wgtVar=\"wgt_SUMW_PU\", histos1D_dict=histos1D[name][lvl], \n",
    "                   histos2D_dict=histos2D[name][lvl], histosNS_dict=histosNS[name][lvl],\n",
    "                   doMuons=False, doElectrons=False, doLeptons=False, \n",
    "                   doJets=False, doWeights=False, doEventVars=True)\n",
    "#        fillHistos(the_df[name][lvl], wgtVar=\"wgt_SUMW_PU\", histos1D_dict=histos1D_PU[name][lvl], \n",
    "#                   histos2D_dict=histos2D[name][lvl], histosNS_dict=histosNS[name][lvl],\n",
    "#                   doMuons=True, doElectrons=True, doLeptons=True, \n",
    "#                   doJets=True, doWeights=True, doEventVars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Warning: if filtered[name][lvl] RDFs are not reset, then calling define* on them will cause the error\"\\\n",
    "      \"with 'program state reset'\")\n",
    "loopcounter = 0\n",
    "start = time.clock()\n",
    "for name, cnt in counts.items():\n",
    "    loopcounter += 1\n",
    "    print(\"==========={}/{}\\n{}\".format(loopcounter, len(counts), name))\n",
    "    if \"baseline\" in cnt:\n",
    "        print(\"Baseline = \" + str(cnt[\"baseline\"].GetValue()))\n",
    "    else:\n",
    "        print(\"Baseline\")\n",
    "    if \"ElMu_baseline\" in cnt:\n",
    "        print(\"\\tElMu = {}\".format(cnt[\"ElMu_baseline\"].GetValue()),end='')\n",
    "    if \"MuMu_baseline\" in cnt:\n",
    "        print(\"\\tMuMu = {}\".format(cnt[\"MuMu_baseline\"].GetValue()),end='')\n",
    "    if \"ElEl_baseline\" in cnt:\n",
    "        print(\"\\tElEl = {}\".format(cnt[\"ElEl_baseline\"].GetValue()),end='')\n",
    "    if \"Mu_baseline\" in cnt:\n",
    "        print(\"\\tMu = {}\".format(cnt[\"Mu_baseline\"].GetValue()),end='')\n",
    "    if \"El_baseline\" in cnt:\n",
    "        print(\"\\tEl = {}\".format(cnt[\"El_baseline\"].GetValue()),end='')\n",
    "    print(\"\")\n",
    "    if \"ElMu_baseline\" in cnt and \"ElEl_baseline\" in cnt and \"MuMu_baseline\" in cnt\\\n",
    "            and \"Mu_baseline\" in cnt and \"El_baseline\" in cnt:\n",
    "        print(\"\\nTotal = {}\".format(cnt[\"ElMu_baseline\"].GetValue() + cnt[\"MuMu_baseline\"].GetValue() + cnt[\"ElEl_baseline\"].GetValue() + cnt[\"Mu_baseline\"].GetValue() + cnt[\"El_baseline\"].GetValue()))\n",
    "    if \"selection\" in cnt:\n",
    "        print(\"Selection = \" + str(cnt[\"selection\"].GetValue()))\n",
    "    else: \n",
    "        print(\"Selection\")\n",
    "    if \"ElMu_selection\" in cnt:\n",
    "        print(\"\\tElMu = {}\".format(cnt[\"ElMu_selection\"].GetValue()),end='')\n",
    "    if \"MuMu_selection\" in cnt:\n",
    "        print(\"\\tMuMu = {}\".format(cnt[\"MuMu_selection\"].GetValue()),end='')\n",
    "    if \"ElEl_selection\" in cnt:\n",
    "        print(\"\\tElEl = {}\".format(cnt[\"ElEl_selection\"].GetValue()),end='')\n",
    "    if \"Mu_selection\" in cnt:\n",
    "        print(\"\\tMu = {}\".format(cnt[\"Mu_selection\"].GetValue()),end='')\n",
    "    if \"El_selection\" in cnt:\n",
    "        print(\"\\tEl = {}\".format(cnt[\"El_selection\"].GetValue()),end='')\n",
    "    print(\"\")  \n",
    "    if \"ElMu_selection\" in cnt and \"ElEl_selection\" in cnt and \"MuMu_selection\" in cnt\\\n",
    "            and \"Mu_selection\" in cnt and \"El_selection\" in cnt:\n",
    "        print(\"\\nTotal = {}\".format(cnt[\"ElMu_selection\"].GetValue() + cnt[\"MuMu_selection\"].GetValue() + cnt[\"ElEl_selection\"].GetValue() + cnt[\"Mu_selection\"].GetValue() + cnt[\"El_selection\"].GetValue()))\n",
    "finish = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Took {}s to process\".format(finish - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacks = {}\n",
    "stacksource = {} #Create sortable lists to fill stacks from\n",
    "stacksource_data = {} #create separte list to append all the data to, so that they can be conbined into one hist file and added to the stacksoure at the end\n",
    "for level, obj_dict in histos1D['tttt'].items():\n",
    "    if level not in levels_of_interest: continue\n",
    "    stacks[level] = {}\n",
    "    stacksource[level] = {}\n",
    "    stacksource_data[level] = {}\n",
    "    for obj_name, obj_val in obj_dict.items():\n",
    "        stacks[level][obj_name] = {}\n",
    "        stacksource[level][obj_name] = {}\n",
    "        stacksource_data[level][obj_name] = {}\n",
    "        for hname, hist in obj_val.items():\n",
    "            stacks[level][obj_name][hname] = []\n",
    "            stacks[level][obj_name][hname].append(ROOT.THStack(\"s_{}_{}_{}\".format(level, obj_name, hname), \"{}_{}_{}\".format(level, obj_name, hname)))\n",
    "            stacksource[level][obj_name][hname] = []\n",
    "            stacksource_data[level][obj_name][hname] = []\n",
    "for name, levels_dict in histos1D.items():\n",
    "    #if \"DY\" not in name and \"t\" not in name: continue\n",
    "    #if theSampleDict[name][\"isData\"] == True: continue\n",
    "    print(name, end='')\n",
    "    #print(theSampleDict[name].keys())\n",
    "    print(\" - c=\" + str(theSampleDict[name][\"color\"]))\n",
    "    for level, obj_dict in levels_dict.items():\n",
    "        if level not in levels_of_interest: continue\n",
    "        print(\"\\t\" + level)\n",
    "        for obj_name, obj_val in obj_dict.items():\n",
    "            print(\"\\t\\t\" + obj_name)\n",
    "            for hname, hist in obj_val.items():\n",
    "                print(\"\\t\\t\\t\" + hname)\n",
    "                #help(hist)\n",
    "                hptr = hist.GetPtr().Clone()\n",
    "                hptr.SetFillColor(theSampleDict[name][\"color\"])\n",
    "                hptr.SetLineColor(theSampleDict[name][\"color\"])\n",
    "                #stacks[level][obj_name][hname].Add(hptr)\n",
    "                #stacksource[level][obj_name][hname].append((hptr, hptr.GetIntegral()))\n",
    "                #Integral fails sometimes, use sum of weights...\n",
    "                if theSampleDict[name][\"isData\"] == False:\n",
    "                    stacksource[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "                else:\n",
    "                    stacksource_data[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "print()\n",
    "#Now cycle through and sort each list, once it contains all hists from every source (outermost loop - name - above)\n",
    "print(stacksource_data)\n",
    "for level, obj_dict in histos1D['tttt'].items():\n",
    "    if level not in levels_of_interest: continue\n",
    "    for obj_name, obj_val in obj_dict.items():\n",
    "        for hname, hist in obj_val.items():\n",
    "            stacksource[level][obj_name][hname].sort(key=lambda b: b[1], reverse=False)\n",
    "            tmp = None\n",
    "            for hi, h_data in enumerate(stacksource_data[level][obj_name][hname]):\n",
    "                \n",
    "                print(\"hi = {}\".format(hi))\n",
    "                if hi == 0:\n",
    "                    #take first histo\n",
    "                    tmp = h_data[0]\n",
    "                else:\n",
    "                    #hadd the other histos\n",
    "                    tmp = tmp + h_data[0]\n",
    "            if tmp != None:\n",
    "                tmp.SetMarkerStyle(0)\n",
    "                tmp.SetLineColor(ROOT.kBlack)\n",
    "                tmp.SetFillColor(ROOT.kWhite)\n",
    "                stacks[level][obj_name][hname].append(tmp)\n",
    "                \n",
    "            for hptrTup in stacksource[level][obj_name][hname]:\n",
    "                #add to the THStack in the first position of the tuple\n",
    "                stacks[level][obj_name][hname][0].Add(hptrTup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "leg = ROOT.TLegend(0.75,0.85, 0.6, 0.75)\n",
    "#leg.SetFillColor(0)\n",
    "#leg.SetBorderSize(0)\n",
    "leg.SetTextSize(0.03)\n",
    "\n",
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        #For data first\n",
    "        if len(stack) > 1:\n",
    "            stack[1].Draw(\"PE1\")\n",
    "            stack[0].Draw(\"HIST SAME\")\n",
    "        else:\n",
    "            stack[0].Draw(\"HIST\")\n",
    "        if len(stack) > 1:\n",
    "            stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        #stack[0].Draw(\"HIST S\")\n",
    "        #stack[1].Draw(\"PE1 SAME\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks_PU = {}\n",
    "stacksource_PU = {} #Create sortable lists to fill stacks from\n",
    "stacksource_data_PU = {} #create separte list to append all the data to, so that they can be conbined into one hist file and added to the stacksoure at the end\n",
    "for level, obj_dict in histos1D_PU['tttt'].items():\n",
    "    if level not in levels_of_interest: continue\n",
    "    stacks_PU[level] = {}\n",
    "    stacksource_PU[level] = {}\n",
    "    stacksource_data_PU[level] = {}\n",
    "    for obj_name, obj_val in obj_dict.items():\n",
    "        stacks_PU[level][obj_name] = {}\n",
    "        stacksource_PU[level][obj_name] = {}\n",
    "        stacksource_data_PU[level][obj_name] = {}\n",
    "        for hname, hist in obj_val.items():\n",
    "            stacks_PU[level][obj_name][hname] = []\n",
    "            stacks_PU[level][obj_name][hname].append(ROOT.THStack(\"s_{}_{}_{}\".format(level, obj_name, hname), \"{}_{}_{}\".format(level, obj_name, hname)))\n",
    "            stacksource_PU[level][obj_name][hname] = []\n",
    "            stacksource_data_PU[level][obj_name][hname] = []\n",
    "for name, levels_dict in histos1D_PU.items():\n",
    "    #if \"DY\" not in name and \"t\" not in name: continue\n",
    "    #if theSampleDict[name][\"isData\"] == True: continue\n",
    "    print(name, end='')\n",
    "    #print(theSampleDict[name].keys())\n",
    "    print(\" - c=\" + str(theSampleDict[name][\"color\"]))\n",
    "    for level, obj_dict in levels_dict.items():\n",
    "        if level not in levels_of_interest: continue\n",
    "        print(\"\\t\" + level)\n",
    "        for obj_name, obj_val in obj_dict.items():\n",
    "            print(\"\\t\\t\" + obj_name)\n",
    "            for hname, hist in obj_val.items():\n",
    "                print(\"\\t\\t\\t\" + hname)\n",
    "                #help(hist)\n",
    "                hptr = hist.GetPtr().Clone()\n",
    "                hptr.SetFillColor(theSampleDict[name][\"color\"])\n",
    "                hptr.SetLineColor(theSampleDict[name][\"color\"])\n",
    "                #stacks[level][obj_name][hname].Add(hptr)\n",
    "                #stacksource[level][obj_name][hname].append((hptr, hptr.GetIntegral()))\n",
    "                #Integral fails sometimes, use sum of weights...\n",
    "                if theSampleDict[name][\"isData\"] == False:\n",
    "                    stacksource_PU[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "                else:\n",
    "                    stacksource_data_PU[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "print()\n",
    "#Now cycle through and sort each list, once it contains all hists from every source (outermost loop - name - above)\n",
    "for level, obj_dict in histos1D_PU['tttt'].items():\n",
    "    if level not in levels_of_interest: continue\n",
    "    for obj_name, obj_val in obj_dict.items():\n",
    "        for hname, hist in obj_val.items():\n",
    "            stacksource_PU[level][obj_name][hname].sort(key=lambda b: b[1], reverse=False)\n",
    "            tmp = None\n",
    "            for hi, h_data in enumerate(stacksource_data_PU[level][obj_name][hname]):\n",
    "                print(\"hi = {}\".format(hi))\n",
    "                if hi == 0:\n",
    "                    #take first histo\n",
    "                    tmp = h_data[0]\n",
    "                else:\n",
    "                    #hadd the other histos\n",
    "                    tmp = tmp + h_data[0]\n",
    "            if tmp != None:\n",
    "                tmp.SetMarkerStyle(0)\n",
    "                tmp.SetLineColor(ROOT.kBlack)\n",
    "                tmp.SetFillColor(ROOT.kWhite)\n",
    "                stacks_PU[level][obj_name][hname].append(tmp)\n",
    "                \n",
    "            for hptrTup in stacksource_PU[level][obj_name][hname]:\n",
    "                #add to the THStack in the first position of the tuple\n",
    "                stacks_PU[level][obj_name][hname][0].Add(hptrTup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "leg = ROOT.TLegend(0.75,0.85, 0.6, 0.75)\n",
    "#leg.SetFillColor(0)\n",
    "#leg.SetBorderSize(0)\n",
    "leg.SetTextSize(0.03)\n",
    "\n",
    "for obj_name, obj_dict in stacks_PU[\"ElMu_selection\"].items():\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        #For data first\n",
    "        #stack[1].Draw(\"PE1\")\n",
    "        #stack[0].Draw(\"HIST SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        #FIXME - not drawing data stack[1].Draw(\"PE1 SAME\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From example: https://root.cern.ch/doc/master/df103__NanoAODHiggsAnalysis_8py_source.html\n",
    "\n",
    "#def plot(sig, bkg, data, x_label, filename):\n",
    "#     \"\"\"\n",
    "#     Plot invariant mass for signal and background processes from simulated\n",
    "#     events overlay the measured data.\n",
    "#     \"\"\"\n",
    "#     # Canvas and general style options\n",
    "#     ROOT.gStyle.SetOptStat(0)\n",
    "#     ROOT.gStyle.SetTextFont(42)\n",
    "#     d = ROOT.TCanvas(\"d\", \"\", 800, 700)\n",
    "#     d.SetLeftMargin(0.15)\n",
    "# \n",
    "#     # Get signal and background histograms and stack them to show Higgs signal\n",
    "#     # on top of the background process\n",
    "#     h_bkg = bkg\n",
    "#     h_cmb = sig.Clone()\n",
    "# \n",
    "#     h_cmb.Add(h_bkg)\n",
    "#     h_cmb.SetTitle(\"\")\n",
    "#     h_cmb.GetXaxis().SetTitle(x_label)\n",
    "#     h_cmb.GetXaxis().SetTitleSize(0.04)\n",
    "#     h_cmb.GetYaxis().SetTitle(\"N_{Events}\")\n",
    "#     h_cmb.GetYaxis().SetTitleSize(0.04)\n",
    "#     h_cmb.SetLineColor(ROOT.kRed)\n",
    "#     h_cmb.SetLineWidth(2)\n",
    "#     h_cmb.SetMaximum(18)\n",
    "#     h_bkg.SetLineWidth(2)\n",
    "#     h_bkg.SetFillStyle(1001)\n",
    "#     h_bkg.SetLineColor(ROOT.kBlack)\n",
    "#     h_bkg.SetFillColor(ROOT.kAzure - 9)\n",
    "# \n",
    "#     # Get histogram of data points\n",
    "#     h_data = data\n",
    "#     h_data.SetLineWidth(1)\n",
    "#     h_data.SetMarkerStyle(20)\n",
    "#     h_data.SetMarkerSize(1.0)\n",
    "#     h_data.SetMarkerColor(ROOT.kBlack)\n",
    "#     h_data.SetLineColor(ROOT.kBlack)\n",
    "# \n",
    "#     # Draw histograms\n",
    "#     h_cmb.DrawCopy(\"HIST\")\n",
    "#     h_bkg.DrawCopy(\"HIST SAME\")\n",
    "#     h_data.DrawCopy(\"PE1 SAME\")\n",
    "# \n",
    "#     # Add legend\n",
    "#     legend = ROOT.TLegend(0.62, 0.70, 0.82, 0.88)\n",
    "#     legend.SetFillColor(0)\n",
    "#     legend.SetBorderSize(0)\n",
    "#     legend.SetTextSize(0.03)\n",
    "#     legend.AddEntry(h_data, \"Data\", \"PE1\")\n",
    "#     legend.AddEntry(h_bkg, \"ZZ\", \"f\")\n",
    "#     legend.AddEntry(h_cmb, \"m_{H} = 125 GeV\", \"f\")\n",
    "#     legend.Draw()\n",
    "# \n",
    "#     # Add header\n",
    "#     cms_label = ROOT.TLatex()\n",
    "#     cms_label.SetTextSize(0.04)\n",
    "#     cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Open Data}\")\n",
    "#     header = ROOT.TLatex()\n",
    "#     header.SetTextSize(0.03)\n",
    "#     header.DrawLatexNDC(0.63, 0.92, \"#sqrt{s} = 8 TeV, L_{int} = 11.6 fb^{-1}\")\n",
    "# \n",
    "#     # Save plot\n",
    "#     d.SaveAs(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gg1 = ROOT.ROOT.RDF.SaveGraph(the_df['tttt']['ElMu_selection'], './mydot.dot')\n",
    "#!dot -Tsvg mydot.dot -o mydot.svg\n",
    "#listOfImageNames = ['./mydot.svg',\n",
    "#                    ]\n",
    "#\n",
    "#for imageName in listOfImageNames:\n",
    "#    display(SVG(filename=imageName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
