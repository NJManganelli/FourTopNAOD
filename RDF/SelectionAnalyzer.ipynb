{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz --user\n",
    "#!echo $PYTHONPATH\n",
    "#!ls -ltr /eos/user/n/nmangane/.local/lib/python2.7/site-packages/\n",
    "#!export PATH=/eos/user/n/nmangane/.local/lib/python2.7/site-packages/:$PATH\n",
    "!ls -ltr | grep .root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os, time, sys\n",
    "import ROOT\n",
    "import collections\n",
    "from IPython.display import Image, display, SVG\n",
    "#import graphviz\n",
    "\n",
    "useSpark = False #Doesn't seem to work with gcc8 at least...\n",
    "if useSpark:\n",
    "    import PyRDF\n",
    "    PyRDF.use(\"spark\", {'npartitions': '8'}) #was 32 in example\n",
    "    RDF = PyRDF.RDataFrame\n",
    "else:\n",
    "    ROOT.ROOT.EnableImplicitMT()\n",
    "    RS = ROOT.ROOT\n",
    "    RDF = RS.RDataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterstart = time.time() #.clock() gives cpu time, not what I want for this measure (especially multicore)\n",
    "with open(\"2017_booker.py\", \"r\") as f:\n",
    "    for line in f:\n",
    "        #print(line, end=\"\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME: Need filter efficiency calculated for single lepton generator filtered sample. First approximation will be from MCCM (0.15) but as seen before, it's not ideal. \n",
    "#May need to recalculate using genWeight/sumWeights instead of sign(genWeight)/(nPositiveEvents - nNegativeEvents), confirm if there's any difference.\n",
    "lumi = {\"2017\": 41.53,\n",
    "        \"2018\": 1}\n",
    "era = \"2017\"\n",
    "leg_dict = {\"tttt\": ROOT.kAzure-2,\n",
    "            \"ttbar\": ROOT.kRed,\n",
    "            \"singletop\": ROOT.kYellow,\n",
    "            \"ttH\": ROOT.kMagenta,\n",
    "            \"ttVJets\": ROOT.kViolet,\n",
    "            \"ttultrarare\": ROOT.kGreen,\n",
    "            \"DY\": ROOT.kCyan,\n",
    "            \"Data\": ROOT.kBlack,\n",
    "            \"QCD\": ROOT.kPink,\n",
    "           }\n",
    "microbookerV2 = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttt-*_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttt-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt-2_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tttt/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-*_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-2_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-3_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-4_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-5_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-6_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-7_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-8_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-9_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-10_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-11_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-12_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-13_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-14_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_DL/$SYSTEMATIC\",\n",
    "        \"stitch\": {\"mode\": \"Flag\",\n",
    "                   \"source\": \"Nominal\",\n",
    "                   \"channel\": \"DL\"\n",
    "                  },\n",
    "    },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_SL/$SYSTEMATIC\",\n",
    "        \"stitch\": {\"mode\": \"Flag\",\n",
    "                   \"source\": \"Nominal\",\n",
    "                   \"channel\": \"SL\"\n",
    "                  },\n",
    "    },\n",
    "\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tW_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tW_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ST_tW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ST_tbarW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7745276,\n",
    "        \"nEventsPositive\": 7715654,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 270762750.172525,\n",
    "        \"sumWeights2\": 9611964941.797768,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tbarW_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tbarW_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ST_tbarW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"DYJets_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 49125561,\n",
    "        \"nEventsPositive\": 49103859,\n",
    "        \"nEventsNegative\": 21702,\n",
    "        \"sumWeights\": 49082157.000000,\n",
    "        \"sumWeights2\": 49125561.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 5075.6,\n",
    "        \"color\": leg_dict[\"DY\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-*_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-1_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-2_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-3_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-4_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-5_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-6_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-7_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/DYJets_DL/$SYSTEMATIC\",\n",
    "    },\n",
    "}\n",
    "tt_data_V2 = {\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-*_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-2_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-3_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-4_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-5_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-6_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-7_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-8_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-9_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-10_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-11_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-12_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-13_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-14_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_DL/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_SL/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ElMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"BCDEF\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465 + 15595214 + 9164365 + 19043421 + 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_*_2017.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_*_2017.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ElMu/$SYSTEMATIC\",\n",
    "    },    \n",
    "}\n",
    "bookerV2_MC = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttt-*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/tttt-*_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/tttt-*_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/tttt-*_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttt-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt-2_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tttt/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"doFilter\": True,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/tt_DL-NOM-*_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/tt_DL-NOM-*_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/tt_DL-NOM-*_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-2_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-3_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-4_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-5_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-6_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-7_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-8_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-9_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-10_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-11_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-12_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-13_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-14_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_DL/$SYSTEMATIC\",\n",
    "        \"stitch\": {\"mode\": \"Flag\",\n",
    "                   \"source\": \"Nominal\",\n",
    "                   \"channel\": \"DL\"\n",
    "                  },\n",
    "    },\n",
    "    \"tt_DL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8510388,\n",
    "        \"nEventsPositive\": 8467543,\n",
    "        \"nEventsNegative\": 42845,\n",
    "        \"sumWeights\": 612101836.284397,\n",
    "        \"sumWeights2\": 44925503249.097206,\n",
    "        \"isSignal\": False,\n",
    "        \"doFilter\": True,\n",
    "        \"crossSection\": 1.4815,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-GF-*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/tt_DL-GF-*_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/tt_DL-GF-*_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/tt_DL-GF-*_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-GF-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-GF-2_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-GF-3_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-GF-4_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_DL-GF/$SYSTEMATIC\",\n",
    "        \"stitch\": {\"mode\": \"Flag\",\n",
    "                   \"source\": \"Filtered\",\n",
    "                   \"channel\": \"DL\"\n",
    "                  },\n",
    "    },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"doFilter\": True,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/tt_SL-NOM_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/tt_SL-NOM_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/tt_SL-NOM_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_SL/$SYSTEMATIC\",\n",
    "        \"stitch\": {\"mode\": \"Flag\",\n",
    "                   \"source\": \"Nominal\",\n",
    "                   \"channel\": \"SL\"\n",
    "                  },\n",
    "    },\n",
    "    \"tt_SL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8836856,\n",
    "        \"nEventsPositive\": 8794464,\n",
    "        \"nEventsNegative\": 42392,\n",
    "        \"sumWeights\": 2653328498.476976,\n",
    "        \"sumWeights2\": 812201885978.209229,\n",
    "        \"isSignal\": False,\n",
    "        \"doFilter\": True,\n",
    "        \"crossSection\": 12.4071,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-GF_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/tt_SL-GF_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/tt_SL-GF_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/tt_SL-GF_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-GF_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_SL-GF/$SYSTEMATIC\",\n",
    "        \"stitch\": {\"mode\": \"Flag\",\n",
    "                   \"source\": \"Filtered\",\n",
    "                   \"channel\": \"SL\"\n",
    "                  },\n",
    "    },\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tW_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ST_tW_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ST_tW_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ST_tW_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tW_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ST_tW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ST_tbarW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7745276,\n",
    "        \"nEventsPositive\": 7715654,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 270762750.172525,\n",
    "        \"sumWeights2\": 9611964941.797768,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tbarW_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ST_tbarW_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ST_tbarW_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ST_tbarW_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tbarW_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ST_tbarW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"DYJets_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 49125561,\n",
    "        \"nEventsPositive\": 49103859,\n",
    "        \"nEventsNegative\": 21702,\n",
    "        \"sumWeights\": 49082157.000000,\n",
    "        \"sumWeights2\": 49125561.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 5075.6,\n",
    "        \"color\": leg_dict[\"DY\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/DYJets_DL-*_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/DYJets_DL-*_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/DYJets_DL-*_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-1_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-2_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-3_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-4_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-5_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-6_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-7_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/DYJets_DL/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8000000,\n",
    "        \"nEventsPositive\": 7916867,\n",
    "        \"nEventsNegative\": 83133,\n",
    "        \"sumWeights\": 4216319.315884,\n",
    "        \"sumWeights2\": 2317497.816608,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.2934,\n",
    "        \"color\": leg_dict[\"ttH\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttH_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ttH_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ttH_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ttH_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttH_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttH/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttWJets\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 9425384,\n",
    "        \"nEventsPositive\": 9404856,\n",
    "        \"nEventsNegative\": 20528,\n",
    "        \"sumWeights\": 9384328.000000,\n",
    "        \"sumWeights2\": 9425384.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.611,\n",
    "        \"color\": leg_dict[\"ttVJets\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWJets_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ttWJets_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ttWJets_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ttWJets_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWJets_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttWJets/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttZJets\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8536618,\n",
    "        \"nEventsPositive\": 8527846,\n",
    "        \"nEventsNegative\": 8772,\n",
    "        \"sumWeights\": 8519074.000000,\n",
    "        \"sumWeights2\": 8536618.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.783,\n",
    "        \"color\": leg_dict[\"ttVJets\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZJets_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ttZJets_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ttZJets_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ttZJets_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZJets_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttZJets/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttWH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199491,\n",
    "        \"nEventsNegative\": 509,\n",
    "        \"sumWeights\": 198839.680865,\n",
    "        \"sumWeights2\": 199704.039588,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.001572,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWH_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ttWH_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ttWH_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ttWH_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWH_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttWH/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttWW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 962000,\n",
    "        \"nEventsPositive\": 962000,\n",
    "        \"nEventsNegative\": 0,\n",
    "        \"sumWeights\": 962000.000000,\n",
    "        \"sumWeights2\": 962000.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.007882,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWW_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ttWW_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ttWW_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ttWW_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWW_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttWW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttWZ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199379,\n",
    "        \"nEventsNegative\": 621,\n",
    "        \"sumWeights\": 198625.183551,\n",
    "        \"sumWeights2\": 199708.972601,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.002974,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWZ_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ttWZ_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ttWZ_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ttWZ_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWZ_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttWZ/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttZZ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199686,\n",
    "        \"nEventsNegative\": 314,\n",
    "        \"sumWeights\": 199286.628891,\n",
    "        \"sumWeights2\": 199816.306332,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.001572,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZZ_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ttZZ_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ttZZ_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ttZZ_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZZ_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttZZ/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttZH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199643,\n",
    "        \"nEventsNegative\": 357,\n",
    "        \"sumWeights\": 199192.234990,\n",
    "        \"sumWeights2\": 199794.753976,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.01253,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZH_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ttZH_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ttZH_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ttZH_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZH_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttZH/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttHH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 194817,\n",
    "        \"nEventsPositive\": 194516,\n",
    "        \"nEventsNegative\": 301,\n",
    "        \"sumWeights\": 194116.909912,\n",
    "        \"sumWeights2\": 194611.090542,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.0007408,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttHH_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/ttHH_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/ttHH_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/ttHH_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttHH_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttHH/$SYSTEMATIC\",\n",
    "    },    \n",
    "    \"tttW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199852,\n",
    "        \"nEventsNegative\": 148,\n",
    "        \"sumWeights\": 199552.187377,\n",
    "        \"sumWeights2\": 199697.648421,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.007882,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttW_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/tttW_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/tttW_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/tttW_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttW_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tttW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tttJ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199273,\n",
    "        \"nEventsNegative\": 727,\n",
    "        \"sumWeights\": 198394.878491,\n",
    "        \"sumWeights2\": 199663.384954,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.0004741,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttJ_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/tttJ_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/tttJ_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/tttJ_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttJ_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tttJ/$SYSTEMATIC\",\n",
    "    },\n",
    "}\n",
    "bookerV2_ElMu = {\n",
    "    \"ElMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"BCDEF\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465 + 15595214 + 9164365 + 19043421 + 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/data_ElMu_*_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/data_ElMu_*_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/data_ElMu_*_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_B_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_C_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_D_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_E_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_F_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ElMu/NOMINAL\",\n",
    "    },\n",
    "}\n",
    "bookerV2_MuMu = {\n",
    "    \"MuMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"BCDEF\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 14501767 + 49636525 + 23075733 + 51589091 + 79756560,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/data_MuMu_*_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/data_MuMu_*_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/data_MuMu_*_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_B_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_C_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_D_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_E_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_F_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/MuMu/NOMINAL\",\n",
    "        },\n",
    "}\n",
    "bookerV2_ElEl = {\n",
    "    \"ElEl\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 58088760 + 65181125 + 25911432 + 56233597 + 74307066,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/data_ElEl_*_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/data_ElEl_*_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/data_ElEl_*_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_B_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_C_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_D_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_E_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_F_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ElEl/NOMINAL\",\n",
    "        },\n",
    "}\n",
    "cutoutV2_ToBeFixed = {\n",
    "    \"Mu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"BCDEF\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136300266 + 165652756 + 70361660 + 154630534 + 242135500,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_Mu_*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/data_Mu_*_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/data_Mu_*_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/data_Mu_*_2017_v2*.root\",\n",
    "                  },\n",
    "        },\n",
    "    \"El\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"BCDEF\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 60537490 + 136637888 + 51526710 + 102121689 + 128467223,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_El_*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/data_El_*_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/data_El_*_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/data_El_*_2017_v2*.root\",\n",
    "                  },\n",
    "        },\n",
    "    \"QCD_HT200\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 59200263,\n",
    "        \"nEventsPositive\": 59166789,\n",
    "        \"nEventsNegative\": 32544,\n",
    "        \"sumWeights\": 59133315.000000,\n",
    "        \"sumWeights2\": 59200263.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1712000.0,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT200_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/QCD_HT200_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/QCD_HT200_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/QCD_HT200_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT200_2017_v2.root\",],\n",
    "    },\n",
    "    \"QCD_HT300\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 59569132,\n",
    "        \"nEventsPositive\": 59514373,\n",
    "        \"nEventsNegative\": 54759,\n",
    "        \"sumWeights\": 59459614.000000,\n",
    "        \"sumWeights2\": 59569132.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 347700.0,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT300_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/QCD_HT300_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/QCD_HT300_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/QCD_HT300_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT300_2017_v2.root\",],\n",
    "    },   \n",
    "    \"QCD_HT500\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 56207744,\n",
    "        \"nEventsPositive\": 56124381,\n",
    "        \"nEventsNegative\": 83363,\n",
    "        \"sumWeights\": 56041018.000000,\n",
    "        \"sumWeights2\": 56207744.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 32100.0,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT500_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/QCD_HT500_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/QCD_HT500_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/QCD_HT500_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT500_2017_v2.root\",],\n",
    "    },\n",
    "    \"QCD_HT700\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 46840955,\n",
    "        \"nEventsPositive\": 46739970,\n",
    "        \"nEventsNegative\": 100985,\n",
    "        \"sumWeights\": 46638985.000000,\n",
    "        \"sumWeights2\": 46840955.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 6831.0,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT700_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/QCD_HT700_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/QCD_HT700_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/QCD_HT700_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT700_2017_v2.root\",],\n",
    "    },\n",
    "    \"QCD_HT1000\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 16882838,\n",
    "        \"nEventsPositive\": 16826800,\n",
    "        \"nEventsNegative\": 56038,\n",
    "        \"sumWeights\": 16770762.000000,\n",
    "        \"sumWeights2\": 16882838.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1207.0,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT1000_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/QCD_HT1000_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/QCD_HT1000_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/QCD_HT1000_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT1000_2017_v2.root\",],\n",
    "    },\n",
    "    \"QCD_HT1500\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 11634434,\n",
    "        \"nEventsPositive\": 11571519,\n",
    "        \"nEventsNegative\": 62915,\n",
    "        \"sumWeights\": 11508604.000000,\n",
    "        \"sumWeights2\": 11634434.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 119.9,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT1500_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/QCD_HT1500_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/QCD_HT1500_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/QCD_HT1500_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT1500_2017_v2.root\",],\n",
    "    },\n",
    "    \"QCD_HT2000\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 5941306,\n",
    "        \"nEventsPositive\": 5883436,\n",
    "        \"nEventsNegative\": 57870,\n",
    "        \"sumWeights\": 5825566.000000,\n",
    "        \"sumWeights2\": 5941306.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 25.24,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT2000_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/QCD_HT2000_2017_v2*.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/QCD_HT2000_2017_v2*.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/QCD_HT2000_2017_v2*.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT2000_2017_v2.root\",],\n",
    "    },\n",
    "    \"ElMu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_B*_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_B_2017.root\",],\n",
    "        },\n",
    "    \"ElMu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 15595214, \n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_C*_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_C_2017.root\",],\n",
    "        },\n",
    "    \"ElMu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 9164365,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_D*_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_D_2017.root\",],\n",
    "        },\n",
    "    \"ElMu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 19043421,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_E*_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_E_2017.root\",],\n",
    "        },\n",
    "    \"ElMu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_F*_2017_v2.root\",},\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_F_2017.root\",],\n",
    "        },\n",
    "    \"MuMu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 14501767,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_B*_2017_v2.root\",},\n",
    "        },\n",
    "    \"MuMu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 49636525,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_C*_2017_v2.root\",},\n",
    "        },\n",
    "    \"MuMu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 23075733,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_D*_2017_v2.root\",},\n",
    "        },\n",
    "    \"MuMu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 51589091,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_E*_2017_v2.root\",},\n",
    "        },\n",
    "    \"MuMu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 79756560,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_MuMu_F*_2017_v2.root\",},\n",
    "        },\n",
    "    \"ElEl_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 58088760,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_B*_2017_v2.root\",},\n",
    "        },\n",
    "    \"ElEl_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 65181125,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_C*_2017_v2.root\",},\n",
    "        },\n",
    "    \"ElEl_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 25911432,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_D*_2017_v2.root\",},\n",
    "        },\n",
    "    \"ElEl_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 56233597,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_E*_2017_v2.root\",},\n",
    "        },\n",
    "    \"ElEl_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 74307066,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElEl_F*_2017_v2.root\",},\n",
    "        },\n",
    "    \"Mu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136300266,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_Mu_B*_2017_v2.root\",},\n",
    "        },\n",
    "    \"Mu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 165652756,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_Mu_C*_2017_v2.root\",},\n",
    "        },\n",
    "    \"Mu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 70361660,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_Mu_D*_2017_v2.root\",},\n",
    "        },\n",
    "    \"Mu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 154630534,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_Mu_E*_2017_v2.root\",},\n",
    "        },\n",
    "    \"Mu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 242135500,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_Mu_F*_2017_v2.root\",},\n",
    "        },\n",
    "    \"El_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 60537490,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_El_B*_2017_v2.root\",},\n",
    "        },\n",
    "    \"El_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136637888,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_El_C*_2017_v2.root\",},\n",
    "        },\n",
    "    \"El_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 51526710,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_El_D*_2017_v2.root\",},\n",
    "        },\n",
    "    \"El_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 102121689,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_El_E*_2017_v2.root\",},\n",
    "        },\n",
    "    \"El_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 128467223,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_El_F*_2017_v2.root\",},\n",
    "    },\n",
    "}\n",
    "bookerV2UNSTITCHED = {\n",
    "    \"tt_SL-UNSTITCHED\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"doFilter\": True,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/tt_SL-NOM_2017_v2.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/tt_SL-NOM_2017_v2.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/tt_SL-NOM_2017_v2.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_SL/$SYSTEMATIC\",\n",
    "    },  \n",
    "    \"tt_DL-UNSTITCHED\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"doFilter\": True,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"LJMLogic\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_selection/tt_DL-NOM-*_2017_v2.root\",\n",
    "                   \"LJMLogic/MuMu_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_selection/tt_DL-NOM-*_2017_v2.root\",\n",
    "                   \"LJMLogic/ElEl_selection\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_selection/tt_DL-NOM-*_2017_v2.root\",\n",
    "                  },\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-2_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-3_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-4_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-5_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-6_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-7_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-8_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-9_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-10_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-11_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-12_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-13_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-14_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_DL/$SYSTEMATIC\",\n",
    "    },\n",
    "}\n",
    "ttbooker = {\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017_PUFix.root\",},\n",
    "        },\n",
    "}\n",
    "ttttbooker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017_PUFix.root\",},\n",
    "        },\n",
    "}\n",
    "microbooker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tW_2017_PUFix.root\",},\n",
    "        },\n",
    "}\n",
    "theOriginal = {\n",
    "    \"tttt_orig\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt-orig_2.root\",},\n",
    "        },\n",
    "}\n",
    "pyrdfbooker = {\n",
    "    \"tt_DL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8510388,\n",
    "        \"nEventsPositive\": 8467543,\n",
    "        \"nEventsNegative\": 42845,\n",
    "        \"sumWeights\": 612101836.284397,\n",
    "        \"sumWeights2\": 44925503249.097206,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1.4705,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL-GF-*_2017_PUFix.root\",},\n",
    "        },\n",
    "}\n",
    "booker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tt_SL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8836856,\n",
    "        \"nEventsPositive\": 8794464,\n",
    "        \"nEventsNegative\": 42392,\n",
    "        \"sumWeights\": 2653328498.476976,\n",
    "        \"sumWeights2\": 812201885978.209229,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 6,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL-GF_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tt_DL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8510388,\n",
    "        \"nEventsPositive\": 8467543,\n",
    "        \"nEventsNegative\": 42845,\n",
    "        \"sumWeights\": 612101836.284397,\n",
    "        \"sumWeights2\": 44925503249.097206,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1.4705,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL-GF-*_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tW_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ST_tbarW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7745276,\n",
    "        \"nEventsPositive\": 7715654,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 270762750.172525,\n",
    "        \"sumWeights2\": 9611964941.797768,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tbarW_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ttH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8000000,\n",
    "        \"nEventsPositive\": 7916867,\n",
    "        \"nEventsNegative\": 83133,\n",
    "        \"sumWeights\": 4216319.315884,\n",
    "        \"sumWeights2\": 2317497.816608,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.2934,\n",
    "        \"color\": leg_dict[\"ttH\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttH_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ttWJets\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 9425384,\n",
    "        \"nEventsPositive\": 9404856,\n",
    "        \"nEventsNegative\": 20528,\n",
    "        \"sumWeights\": 9384328.000000,\n",
    "        \"sumWeights2\": 9425384.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.611,\n",
    "        \"color\": leg_dict[\"ttVJets\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWJets_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ttZJets\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8536618,\n",
    "        \"nEventsPositive\": 8527846,\n",
    "        \"nEventsNegative\": 8772,\n",
    "        \"sumWeights\": 8519074.000000,\n",
    "        \"sumWeights2\": 8536618.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.783,\n",
    "        \"color\": leg_dict[\"ttVJets\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttZJets_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ttWH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199491,\n",
    "        \"nEventsNegative\": 509,\n",
    "        \"sumWeights\": 198839.680865,\n",
    "        \"sumWeights2\": 199704.039588,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.001572,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWH_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ttWW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 962000,\n",
    "        \"nEventsPositive\": 962000,\n",
    "        \"nEventsNegative\": 0,\n",
    "        \"sumWeights\": 962000.000000,\n",
    "        \"sumWeights2\": 962000.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.007882,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWW_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ttWZ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199379,\n",
    "        \"nEventsNegative\": 621,\n",
    "        \"sumWeights\": 198625.183551,\n",
    "        \"sumWeights2\": 199708.972601,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.002974,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWZ_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ttZZ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199686,\n",
    "        \"nEventsNegative\": 314,\n",
    "        \"sumWeights\": 199286.628891,\n",
    "        \"sumWeights2\": 199816.306332,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.001572,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttZZ_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ttZH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199643,\n",
    "        \"nEventsNegative\": 357,\n",
    "        \"sumWeights\": 199192.234990,\n",
    "        \"sumWeights2\": 199794.753976,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.01253,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttZH_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ttHH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 194817,\n",
    "        \"nEventsPositive\": 194516,\n",
    "        \"nEventsNegative\": 301,\n",
    "        \"sumWeights\": 194116.909912,\n",
    "        \"sumWeights2\": 194611.090542,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.0007408,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttHH_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tttW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199852,\n",
    "        \"nEventsNegative\": 148,\n",
    "        \"sumWeights\": 199552.187377,\n",
    "        \"sumWeights2\": 199697.648421,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.007882,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttW_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tttJ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199273,\n",
    "        \"nEventsNegative\": 727,\n",
    "        \"sumWeights\": 198394.878491,\n",
    "        \"sumWeights2\": 199663.384954,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.0004741,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttJ_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"DYJets_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 49125561,\n",
    "        \"nEventsPositive\": 49103859,\n",
    "        \"nEventsNegative\": 21702,\n",
    "        \"sumWeights\": 49082157.000000,\n",
    "        \"sumWeights2\": 49125561.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 5075.6,\n",
    "        \"color\": leg_dict[\"DY\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/DYJets_DL_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ElMu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_B_2017.root\",},\n",
    "        },\n",
    "    \"ElMu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 15595214,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_C_2017.root\",},\n",
    "        },\n",
    "    \"ElMu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 9164365,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_D_2017.root\",},\n",
    "        },\n",
    "    \"ElMu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 19043421,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_E_2017.root\",},\n",
    "        },\n",
    "    \"ElMu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_F_2017.root\",},\n",
    "        },\n",
    "}\n",
    "cutout = {\n",
    "    \"MuMu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 14501767,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_B_2017.root\",},\n",
    "        },\n",
    "    \"MuMu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 49636525,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_C_2017.root\",},\n",
    "        },\n",
    "    \"MuMu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 23075733,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_D_2017.root\",},\n",
    "        },\n",
    "    \"MuMu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 51589091,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_E_2017.root\",},\n",
    "        },\n",
    "    \"MuMu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 79756560,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_F_2017.root\",},\n",
    "        },\n",
    "    \"ElEl_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 58088760,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_B_2017.root\",},\n",
    "        },\n",
    "    \"ElEl_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 65181125,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_C_2017.root\",},\n",
    "        },\n",
    "    \"ElEl_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 25911432,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_D_2017.root\",},\n",
    "        },\n",
    "    \"ElEl_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 56233597,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_E_2017.root\",},\n",
    "        },\n",
    "    \"ElEl_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 74307066,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_F_2017.root\",},\n",
    "        },\n",
    "    \"Mu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136300266,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_B_2017.root\",},\n",
    "        },\n",
    "    \"Mu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 165652756,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_C_2017.root\",},\n",
    "        },\n",
    "    \"Mu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 70361660,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_D_2017.root\",},\n",
    "        },\n",
    "    \"Mu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 154630534,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_E_2017.root\",},\n",
    "        },\n",
    "    \"Mu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 242135500,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_F_2017.root\",},\n",
    "        },\n",
    "    \"El_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 60537490,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_B_2017.root\",},\n",
    "        },\n",
    "    \"El_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136637888,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_C_2017.root\",},\n",
    "        },\n",
    "    \"El_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 51526710,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_D_2017.root\",},\n",
    "        },\n",
    "    \"El_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 102121689,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_E_2017.root\",},\n",
    "        },\n",
    "    \"El_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 128467223,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_F_2017.root\",},\n",
    "        },\n",
    "    }\n",
    "minibooker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tt_SL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8836856,\n",
    "        \"nEventsPositive\": 8794464,\n",
    "        \"nEventsNegative\": 42392,\n",
    "        \"sumWeights\": 2653328498.476976,\n",
    "        \"sumWeights2\": 812201885978.209229,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 6,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL-GF_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tt_DL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8510388,\n",
    "        \"nEventsPositive\": 8467543,\n",
    "        \"nEventsNegative\": 42845,\n",
    "        \"sumWeights\": 612101836.284397,\n",
    "        \"sumWeights2\": 44925503249.097206,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1.4705,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL-GF-*_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tW_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"ST_tbarW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7745276,\n",
    "        \"nEventsPositive\": 7715654,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 270762750.172525,\n",
    "        \"sumWeights2\": 9611964941.797768,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tbarW_2017_PUFix.root\",},\n",
    "        },\n",
    "\n",
    "    \"DYJets_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 49125561,\n",
    "        \"nEventsPositive\": 49103859,\n",
    "        \"nEventsNegative\": 21702,\n",
    "        \"sumWeights\": 49082157.000000,\n",
    "        \"sumWeights2\": 49125561.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 5075.6,\n",
    "        \"color\": leg_dict[\"DY\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/DYJets_DL_2017_PUFix.root\",},\n",
    "        },\n",
    "    \"MuMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 14501767 + 49636525 + 23075733 + 51589091 + 79756560,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_*_2017.root\",},\n",
    "        },\n",
    "    \"ElEl\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 58088760 + 65181125 + 25911432 + 56233597 + 74307066,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_*_2017.root\",},\n",
    "        },\n",
    "    \"ElMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465 + 15595214 + 9164365 + 19043421 + 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_*_2017.root\",},\n",
    "        },\n",
    "    \"Mu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136300266 + 165652756 + 70361660 + 154630534 + 242135500,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_*_2017.root\",},\n",
    "        },\n",
    "    \"El\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 60537490 + 136637888 + 51526710 + 102121689 + 128467223,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": {\"Unknown\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_*_2017.root\",},\n",
    "        },\n",
    "    }\n",
    "\n",
    "#Set up channel bits for selection and baseline. Separation not necessary in this stage, but convenient for loops\n",
    "Chan = {}\n",
    "Chan[\"ElMu_selection\"] = 24576\n",
    "Chan[\"MuMu_selection\"] = 6144\n",
    "Chan[\"ElEl_selection\"] = 512\n",
    "Chan[\"Mu_selection\"] = 128\n",
    "Chan[\"El_selection\"] = 64\n",
    "Chan[\"selection\"] = Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"] + Chan[\"Mu_selection\"] + Chan[\"El_selection\"]\n",
    "Chan[\"ElMu_baseline\"] = 24576\n",
    "Chan[\"MuMu_baseline\"] = 6144\n",
    "Chan[\"ElEl_baseline\"] = 512\n",
    "Chan[\"Mu_baseline\"] = 128\n",
    "Chan[\"El_baseline\"] = 64\n",
    "Chan[\"baseline\"] = Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"] + Chan[\"El_baseline\"]\n",
    "\n",
    "\n",
    "#samples[\"tt_DL-GF\"] = {}\n",
    "#samples[\"tt_DL-GF\"][\"path\"] = base + \"crab_tt_DL-GF_2017/results/tree*.root\"\n",
    "#booker[\"tttt\"]['nEvents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transverseMassCode = '''auto MT2 = {m1}*{m1} + {m2}*{m2} + 2*(sqrt({m1}*{m1} + {pt1}*{pt1})*sqrt({m2}*{m2} + {pt2}*{pt2}) - {pt1}*{pt2}*cos({phi1} - {phi2}));\n",
    "                         return sqrt(MT2);'''\n",
    "b = transverseMassCode.format(m1 = \"GMuon_mass\", m2 = \"0\",\n",
    "                                                                  pt1 = \"GMuon_pt\",\n",
    "                                                                 pt2 = \"METFixEE2017_pt\", \n",
    "                                                                 phi1 = \"GMuon_phi\", phi2 = \"METFixEE2017_phi\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineLeptons(input_df, input_lvl_filter=None, isData=True, useBackupChannel=False):\n",
    "    \"\"\"Function to take in a dataframe and return one with new columns defined,\n",
    "    plus event filtering based on the criteria defined inside the function\"\"\"\n",
    "        \n",
    "    #Set up channel bits for selection and baseline. Separation not necessary in this stage, but convenient for loops\n",
    "    Chan = {}\n",
    "    Chan[\"ElMu_selection\"] = 24576\n",
    "    Chan[\"MuMu_selection\"] = 6144\n",
    "    Chan[\"ElEl_selection\"] = 512\n",
    "    Chan[\"Mu_selection\"] = 128\n",
    "    Chan[\"El_selection\"] = 64\n",
    "    Chan[\"selection\"] = Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"] + Chan[\"Mu_selection\"] + Chan[\"El_selection\"]\n",
    "    Chan[\"ElMu_baseline\"] = 24576\n",
    "    Chan[\"MuMu_baseline\"] = 6144\n",
    "    Chan[\"ElEl_baseline\"] = 512\n",
    "    Chan[\"Mu_baseline\"] = 128\n",
    "    Chan[\"El_baseline\"] = 64\n",
    "    Chan[\"baseline\"] = Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"] + Chan[\"El_baseline\"]\n",
    "    b = {}\n",
    "    b[\"baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + \n",
    "                                                                            Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"] + Chan[\"El_baseline\"])\n",
    "    \n",
    "    b[\"ElMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) > 0\".format(Chan[\"ElMu_baseline\"])\n",
    "    b[\"MuMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"], \n",
    "                                                                                                                                Chan[\"MuMu_baseline\"])\n",
    "    b[\"ElEl_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"], \n",
    "                                                                                                                                Chan[\"ElEl_baseline\"])\n",
    "    b[\"Mu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"], Chan[\"Mu_baseline\"])\n",
    "    b[\"El_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + \n",
    "                                                                                                                    Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"], Chan[\"El_baseline\"])\n",
    "    b[\"selection\"] = \"ESV_TriggerAndLeptonLogic_selection > 0\"\n",
    "    b[\"ElMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) > 0\".format(Chan[\"ElMu_selection\"])\n",
    "    b[\"MuMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"], Chan[\"MuMu_selection\"])\n",
    "    b[\"ElEl_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"], Chan[\"ElEl_selection\"])\n",
    "    b[\"Mu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"], Chan[\"Mu_selection\"])\n",
    "    b[\"El_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"]\n",
    "                                                                                                                                 + Chan[\"Mu_selection\"], Chan[\"El_selection\"])\n",
    "    if input_lvl_filter == None:\n",
    "        rdf_input = input_df\\\n",
    "                .Define(\"mu_mask\", \"Muon_pt > 0\").Define(\"e_mask\", \"Electron_pt > 0\")\n",
    "    else:\n",
    "        if \"baseline\" in input_lvl_filter:\n",
    "            lvl_type = \"baseline\"\n",
    "        elif \"selection\" in input_lvl_filter:\n",
    "            lvl_type = \"selection\"\n",
    "        else:\n",
    "            raise RuntimeError(\"No such level permissable: must contain 'selection' or 'baseline'\")\n",
    "        rdf_input = input_df.Filter(b[input_lvl_filter], input_lvl_filter)\n",
    "        rdf = rdf_input\n",
    "        rdf = rdf.Define(\"mu_mask\", \"(Muon_OSV_{0} & {1}) > 0\".format(lvl_type, Chan[input_lvl_filter]))\n",
    "        rdf = rdf.Define(\"e_mask\", \"(Electron_OSV_{0} & {1}) > 0\".format(lvl_type, Chan[input_lvl_filter]))\n",
    "    indexDefineCode = '''ROOT::VecOps::RVec<int> i({0}.size());\n",
    "                     std::iota(i.begin(), i.end(), 0);\n",
    "                     return i;'''\n",
    "    transverseMassCode = '''auto MT2 = {m1}*{m1} + {m2}*{m2} + 2*(sqrt({m1}*{m1} + {pt1}*{pt1})*sqrt({m2}*{m2} + {pt2}*{pt2}) - {pt1}*{pt2}*cos(ROOT::VecOps::DeltaPhi({phi1}, {phi2})));\n",
    "                         return sqrt(MT2);'''\n",
    "    transverseMassCodeChannelSafe = '''\n",
    "                         if( {pt1}.size() != {pt2}.size()){{ROOT::VecOps::RVec<float> v; v.push_back(-9999); return v;}}\n",
    "                         else {{auto MT2 = {m1}*{m1} + {m2}*{m2} + 2*(sqrt({m1}*{m1} + {pt1}*{pt1})*sqrt({m2}*{m2} + {pt2}*{pt2}) - {pt1}*{pt2}*cos(ROOT::VecOps::DeltaPhi({phi1}, {phi2})));\n",
    "                         return sqrt(MT2);\n",
    "                         }}'''\n",
    "    transverseMassCodeChecker = '''auto V1 = ROOT::Math::PtEtaPhiMVector({pt1}, {eta1}, {phi1}, {m1});\n",
    "                                auto V2 = ROOT::Math::PtEtaPhiMVector({pt2}, {eta2}, {phi2}, {m2});\n",
    "                                auto V = V1 + V2;\n",
    "                                return V.Mt();'''\n",
    "    transverseMassLightCode = '''auto MT2 = 2*{pt1}*{pt2}*(1 - cos(ROOT::VecOps::DeltaPhi({phi1}, {phi2})));\n",
    "                              return sqrt(MT2);'''\n",
    "    rdf = rdf.Define(\"Muon_idx\", indexDefineCode.format(\"mu_mask\"))\n",
    "    rdf = rdf.Define(\"GMuon_idx\", \"Muon_idx[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_pfIsoId\", \"Muon_pfIsoId[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_looseId\", \"Muon_looseId[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_pt\", \"Muon_pt[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_eta\", \"Muon_eta[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_phi\", \"Muon_phi[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_mass\", \"Muon_mass[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_charge\", \"Muon_charge[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_dz\", \"Muon_dz[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_dxy\", \"Muon_dxy[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_d0\", \"sqrt(Muon_dz*Muon_dz + Muon_dxy*Muon_dxy)[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_ip3d\", \"Muon_ip3d[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_pfRelIso03_all\", \"Muon_pfRelIso03_all[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_pfRelIso03_chg\", \"Muon_pfRelIso03_chg[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_pfRelIso04_all\", \"Muon_pfRelIso04_all[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_jetIdx\", \"Muon_jetIdx[mu_mask]\")\n",
    "    rdf = rdf.Define(\"MTofMETandMu\", transverseMassCode.format(m1 = \"GMuon_mass\", m2 = \"0\",\n",
    "                                                                  pt1 = \"GMuon_pt\",\n",
    "                                                                 pt2 = \"METFixEE2017_pt\", \n",
    "                                                                 phi1 = \"GMuon_phi\", phi2 = \"METFixEE2017_phi\"))\n",
    "    rdf = rdf.Define(\"MTMasslessCheck\", transverseMassLightCode.format(pt1 = \"GMuon_pt.at(0)\", pt2 = \"METFixEE2017_pt\", \n",
    "                                                                            phi1 = \"GMuon_phi.at(0)\", phi2 = \"METFixEE2017_phi\"))\n",
    "    rdf = rdf.Define(\"MTCrossCheck\", transverseMassCodeChecker.format(m1 = \"GMuon_mass.at(0)\", m2 = \"0\",\n",
    "                                                                         eta1 = \"GMuon_eta.at(0)\", eta2 = \"0\",\n",
    "                                                                         pt1 = \"GMuon_pt.at(0)\", pt2 = \"METFixEE2017_pt\", \n",
    "                                                                         phi1 = \"GMuon_phi.at(0)\", phi2 = \"METFixEE2017_phi\"))\n",
    "    rdf = rdf.Define(\"MTCrossCheckDifference\", \"abs(MTofMETandMu - MTCrossCheck)/MTCrossCheck\")\n",
    "    rdf = rdf.Define(\"MTCrossCheckMasslessDifference\", \"abs(MTMasslessCheck - MTofMETandMu)/MTMasslessCheck\")\n",
    "    rdf = rdf.Define(\"nGMuon\", \"GMuon_pt.size()\")\n",
    "    rdf = rdf.Define(\"nLooseGMuon\", \"Muon_looseId[mu_mask && Muon_looseId == true].size()\")\n",
    "    rdf = rdf.Define(\"nMediumGMuon\", \"Muon_mediumId[mu_mask && Muon_mediumId == true].size()\")\n",
    "    rdf = rdf.Define(\"nTightGMuon\", \"Muon_tightId[mu_mask && Muon_tightId == true].size()\")\n",
    "    rdf = rdf.Define(\"GMuon_InvariantMass\", \"nGMuon == 2 ? InvariantMass(GMuon_pt, GMuon_eta, GMuon_phi, GMuon_mass) : -0.1\")\n",
    "    rdf = rdf.Define(\"Electron_idx\", indexDefineCode.format(\"e_mask\"))\n",
    "    rdf = rdf.Define(\"GElectron_idx\", \"Electron_idx[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_cutBased\", \"Electron_cutBased[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_pt\", \"Electron_pt[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_eta\", \"Electron_eta[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_phi\", \"Electron_phi[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_mass\", \"Electron_mass[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_charge\", \"Electron_charge[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_dz\", \"Electron_dz[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_dxy\", \"Electron_dxy[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_d0\", \"sqrt(Electron_dz*Electron_dz + Electron_dxy*Electron_dxy)[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_ip3d\", \"Electron_ip3d[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_pfRelIso03_all\", \"Electron_pfRelIso03_all[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_pfRelIso03_chg\", \"Electron_pfRelIso03_chg[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_jetIdx\", \"Electron_jetIdx[e_mask]\")\n",
    "    rdf = rdf.Define(\"MTofMETandEl\", transverseMassCode.format(m1 = \"GElectron_mass\", m2 = \"0\",\n",
    "                                                                  pt1 = \"GElectron_pt\",\n",
    "                                                                 pt2 = \"METFixEE2017_pt\", \n",
    "                                                                 phi1 = \"GElectron_phi\", phi2 = \"METFixEE2017_phi\"))\n",
    "    \n",
    "    #rdf = rdf.Define(\"MTofElandMu\", transverseMassCode.format(m1 = \"GElectron_mass\", m2 = \"GMuon_mass\",\n",
    "    rdf = rdf.Define(\"MTofElandMu\", transverseMassCodeChannelSafe.format(m1 = \"GElectron_mass\", m2 = \"GMuon_mass\", \n",
    "                                                                  pt1 = \"GElectron_pt\",\n",
    "                                                                 pt2 = \"GMuon_pt\", \n",
    "                                                                 phi1 = \"GElectron_phi\", phi2 = \"GMuon_phi\"))\n",
    "    ##FIXME: This code above is broken for some reason, doesn't like it... why?\n",
    "    rdf = rdf.Define(\"nGElectron\", \"GElectron_pt.size()\")\n",
    "    rdf = rdf.Define(\"nLooseGElectron\", \"Sum(GElectron_cutBased >= 2)\")\n",
    "    rdf = rdf.Define(\"nMediumGElectron\", \"Sum(GElectron_cutBased >= 3)\")\n",
    "    rdf = rdf.Define(\"nTightGElectron\", \"Sum(GElectron_cutBased >= 4)\")\n",
    "    rdf = rdf.Define(\"nLooseGLepton\", \"nLooseGMuon + nLooseGElectron\")\n",
    "    rdf = rdf.Define(\"nMediumGLepton\", \"nMediumGMuon + nMediumGElectron\")\n",
    "    rdf = rdf.Define(\"nTightGLepton\", \"nTightGMuon + nTightGElectron\")\n",
    "    rdf = rdf.Define(\"GElectron_InvariantMass\", \"nGElectron == 2 ? InvariantMass(GElectron_pt, GElectron_eta, GElectron_phi, GElectron_mass) : -0.1\")\n",
    "    rdf = rdf.Define(\"GLepton_argsort\", \"Reverse(Argsort(Concatenate(Muon_pt[mu_mask], Electron_pt[e_mask])))\")\n",
    "    rdf = rdf.Define(\"GLepton_pt\", \"Take(Concatenate(Muon_pt[mu_mask], Electron_pt[e_mask]), GLepton_argsort)\")\n",
    "    rdf = rdf.Define(\"GLepton_eta\", \"Take(Concatenate(Muon_eta[mu_mask], Electron_eta[e_mask]), GLepton_argsort)\")\n",
    "    rdf = rdf.Define(\"GLepton_phi\", \"Take(Concatenate(Muon_phi[mu_mask], Electron_phi[e_mask]), GLepton_argsort)\")\n",
    "    rdf = rdf.Define(\"GLepton_jetIdx\", \"Take(Concatenate(Muon_jetIdx[mu_mask], Electron_jetIdx[e_mask]), GLepton_argsort)\")\n",
    "    rdf = rdf.Define(\"GLepton_pdgId\", \"Take(Concatenate(Muon_pdgId[mu_mask], Electron_pdgId[e_mask]), GLepton_argsort)\")\n",
    "    rdf = rdf.Define(\"GLepton_dRll\", \"GLepton_pt.size() > 1 ? ROOT::VecOps::DeltaR(GLepton_eta.at(0), GLepton_eta.at(1), GLepton_phi.at(0), GLepton_phi.at(1)) : -0.1\")\n",
    "    rdf = rdf.Define(\"GLepton_dPhill\", \"GLepton_pt.size() > 1 ? ROOT::VecOps::DeltaPhi(GLepton_phi.at(0), GLepton_phi.at(1)) : -999\")\n",
    "    rdf = rdf.Define(\"GLepton_dEtall\", \"GLepton_pt.size() > 1 ? abs(GLepton_eta.at(0) - GLepton_eta.at(1)) : -999\")\n",
    "    rdf = rdf.Define(\"nGLepton\", \"GLepton_pt.size()\")\n",
    "    rdf = rdf.Define(\"GLepton_pt_LeadLep\", \"GLepton_pt.size() > 0 ? GLepton_pt.at(0) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GLepton_pt_SubleadLep\", \"GLepton_pt.size() > 1 ? GLepton_pt.at(1) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GLepton_eta_LeadLep\", \"GLepton_eta.size() > 0 ? GLepton_eta.at(0) : -9999\")\n",
    "    rdf = rdf.Define(\"GLepton_eta_SubleadLep\", \"GLepton_eta.size() > 1 ? GLepton_eta.at(1) : -0.9999\")\n",
    "    rdf = rdf.Define(\"GLepton_jetIdx_0\", \"GLepton_jetIdx.size() > 0 ? GLepton_jetIdx.at(0) : -1\")\n",
    "    rdf = rdf.Define(\"GLepton_jetIdx_1\", \"GLepton_jetIdx.size() > 1 ? GLepton_jetIdx.at(1) : -1\")\n",
    "    if isData == False:\n",
    "        rdf = rdf.Define(\"GMuon_SF_ID_nom\", \"Muon_SF_ID_nom[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GMuon_SF_ID_stat\", \"Muon_SF_ID_stat[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GMuon_SF_ID_syst\", \"Muon_SF_ID_syst[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GMuon_SF_ISO_nom\", \"Muon_SF_ISO_nom[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GMuon_SF_ISO_stat\", \"Muon_SF_ISO_stat[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GMuon_SF_ISO_syst\", \"Muon_SF_ISO_syst[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GElectron_SF_EFF_nom\", \"Electron_SF_EFF_nom[e_mask]\")\n",
    "        rdf = rdf.Define(\"GElectron_SF_EFF_unc\", \"Electron_SF_EFF_unc[e_mask]\")\n",
    "        rdf = rdf.Define(\"GElectron_SF_ID_nom\", \"Electron_SF_ID_nom[e_mask]\")\n",
    "        rdf = rdf.Define(\"GElectron_SF_ID_unc\", \"Electron_SF_ID_unc[e_mask]\")\n",
    "        rdf = rdf.Define(\"GLepton_SF_nom\", \"Take(Concatenate(Muon_SF_ID_nom[mu_mask]*Muon_SF_ISO_nom[mu_mask], Electron_SF_ID_nom[e_mask]*Electron_SF_EFF_nom[e_mask]), GLepton_argsort)\")\n",
    "#    else:\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ID_nom\", \"1\")\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ID_stat\", \"0\")\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ID_syst\", \"0\")\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ISO_nom\", \"1\")\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ISO_stat\", \"0\")\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ISO_syst\", \"0\")\n",
    "#        rdf = rdf.Define(\"GElectron_SF_EFF_nom\", \"1\")\n",
    "#        rdf = rdf.Define(\"GElectron_SF_EFF_unc\", \"0\")\n",
    "#        rdf = rdf.Define(\"GElectron_SF_ID_nom\", \"1\")\n",
    "#        rdf = rdf.Define(\"GElectron_SF_ID_unc\", \"0\")\n",
    "#        rdf = rdf.Define(\"GLepton_SF_nom\", \"Take(Concatenate(Muon_SF_ID_nom[mu_mask]*Muon_SF_ISO_nom[mu_mask], Electron_SF_ID_nom[e_mask]*Electron_SF_EFF_nom[e_mask]), GLepton_argsort)\")\n",
    "    \n",
    "                \n",
    "    #Things that don't work...\n",
    "    #NOPE doesn't work .Define(\"nLooseGMuon\", \"Sum(Muon_looseId[mu_mask])\")\\\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineWeights(input_df, crossSection=0, sumWeights=-1, lumi=0,\n",
    "                  nEvents=-1, nEventsPositive=2, nEventsNegative=1,\n",
    "                  isData=True, verbose=False):\n",
    "    \n",
    "    mc_def = collections.OrderedDict()\n",
    "    data_def = collections.OrderedDict()\n",
    "    mc_def[\"wgt_NUMW\"] = \"({xs:s} * {lumi:s} * 1000 * genWeight) / (abs(genWeight) * ( {nevtp:s} - {nevtn:s} ) )\"\\\n",
    "            .format(xs=str(crossSection), lumi=str(lumi), nevt=str(nEvents),\n",
    "                    nevtp=str(nEventsPositive), nevtn=str(nEventsNegative))\n",
    "    mc_def[\"wgt_SUMW\"] = \"({xs:s} * {lumi:s} * 1000 * genWeight) / {sumw:s}\"\\\n",
    "            .format(xs=str(crossSection), lumi=str(lumi), sumw=str(sumWeights))\n",
    "    mc_def[\"wgt_LSF\"] = \"(GLepton_SF_nom.size() > 1 ? GLepton_SF_nom.at(0) * GLepton_SF_nom.at(1) : GLepton_SF_nom.at(0))\"\n",
    "    mc_def[\"wgt_SUMW_PU\"] = \"wgt_SUMW * puWeight\"\n",
    "    mc_def[\"wgt_SUMW_LSF\"] = \"wgt_SUMW * wgt_LSF\"\n",
    "    mc_def[\"wgt_SUMW_L1PF\"] = \"wgt_SUMW * L1PreFiringWeight_Nom\"\n",
    "    mc_def[\"wgt_SUMW_PU_LSF\"] = \"wgt_SUMW * puWeight * wgt_LSF\"\n",
    "    mc_def[\"wgt_SUMW_PU_LSF_L1PF\"] = \"wgt_SUMW * puWeight * wgt_LSF * L1PreFiringWeight_Nom\"\n",
    "    mc_def[\"wgt_SUMW_LSF_L1PF\"] = \"wgt_SUMW * wgt_LSF * L1PreFiringWeight_Nom\"\n",
    "    mc_def[\"wgt_NUMW_LSF_L1PF\"] = \"wgt_NUMW * wgt_LSF * L1PreFiringWeight_Nom\"\n",
    "    #mc_def[\"wgt_SUMW_PU_LSF\"] = \"wgt_SUMW * puWeight * GLepton_SF_nom.at(0) * GLepton_SF_nom.at(1)\"\n",
    "    mc_def[\"SPL_SP\"] = \"wgt_SUMW_PU_LSF/wgt_SUMW_PU\"\n",
    "    mc_def[\"wgt_diff\"] = \"abs(wgt_NUMW - wgt_SUMW)/max(abs(wgt_SUMW), abs(wgt_NUMW))\"\n",
    "    for k in mc_def.keys():\n",
    "        data_def[k] = \"1\"\n",
    "    if verbose == True:\n",
    "        print(\"===data and mc weight definitions===\")\n",
    "        print(data_def)\n",
    "        print(mc_def)\n",
    "        \n",
    "    rdf = input_df\n",
    "    if isData:\n",
    "        for k, v in data_def.items():\n",
    "            rdf = rdf.Define(k, v)\n",
    "    else:\n",
    "        for k, v in mc_def.items():\n",
    "            rdf = rdf.Define(k, v)\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineJets(input_df, era=\"2017\", doAK8Jets=False, debugInfo = True, nJetsToHisto=10, useDeepCSV=True):\n",
    "    \"\"\"Function to take in a dataframe and return one with new columns defined,\n",
    "    plus event filtering based on the criteria defined inside the function\"\"\"\n",
    "    indexDefineCode = '''ROOT::VecOps::RVec<int> i({0}.size());\n",
    "                     std::iota(i.begin(), i.end(), 0);\n",
    "                     return i;'''\n",
    "    bTagWorkingPointDict = {\n",
    "        '2016':{\n",
    "            'DeepCSV':{'L': 0.2217, 'M': 0.6321, 'T': 0.8953, 'Var': 'btagDeepB'},\n",
    "            'DeepJet':{ 'L': 0.0614, 'M': 0.3093, 'T': 0.7221, 'Var': 'btagDeepFlavB'}\n",
    "        },\n",
    "        '2017':{\n",
    "            'CSVv2':{'L': 0.5803, 'M': 0.8838, 'T': 0.9693, 'Var': 'btagCSVV2'},\n",
    "            'DeepCSV':{'L': 0.1522, 'M': 0.4941, 'T': 0.8001, 'Var': 'btagDeepB'},\n",
    "            'DeepJet':{'L': 0.0521, 'M': 0.3033, 'T': 0.7489, 'Var': 'btagDeepFlavB'}\n",
    "        },\n",
    "        '2018':{\n",
    "            'DeepCSV':{'L': 0.1241, 'M': 0.4184, 'T': 0.7527, 'Var': 'btagDeepB'},\n",
    "            'DeepJet':{'L': 0.0494, 'M': 0.2770, 'T': 0.7264, 'Var': 'btagDeepFlavB'}\n",
    "        }\n",
    "    }\n",
    "    print(\"FIXMEFIXME: Setting Jet_pt min to 30GeV! Must fix!\")\n",
    "    rdf = input_df\n",
    "    rdf = rdf.Define(\"jet_maskALT\", \"(Jet_OSV_baseline & {0}) > {0}\".format(23))\n",
    "    rdf = rdf.Define(\"jet_submask\", \"(Jet_pt >= 30 && abs(Jet_eta) <= 2.5 && Jet_jetId > 2)\")\n",
    "    rdf = rdf.Define(\"Jet_idx\", indexDefineCode.format(\"Jet_pt\"))\n",
    "    rdf = rdf.Define(\"jet_mask\", \"(jet_submask && Jet_idx != GLepton_jetIdx_0 && Jet_idx != GLepton_jetIdx_1)\")\n",
    "    rdf = rdf.Define(\"jet_ptsort\", \"Reverse(Argsort(Jet_pt[jet_mask]))\")\n",
    "    rdf = rdf.Define(\"jet_deepcsvsort\", \"Reverse(Argsort(Jet_{0}[jet_mask]))\".format(bTagWorkingPointDict[era][\"DeepCSV\"][\"Var\"]))\n",
    "    rdf = rdf.Define(\"jet_deepjetsort\", \"Reverse(Argsort(Jet_{0}[jet_mask]))\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"]))\n",
    "    rdf = rdf.Define(\"GJet_idx\", \"Jet_idx[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_pt\", \"Jet_pt[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_eta\", \"Jet_eta[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_phi\", \"Jet_phi[jet_mask]\")\n",
    "    for x in xrange(nJetsToHisto):\n",
    "        rdf = rdf.Define(\"GJet_pt_jet{}\".format(x+1), \"GJet_pt.size() > {} ? GJet_pt.at({}) : -9999\".format(x, x))\n",
    "        rdf = rdf.Define(\"GJet_eta_jet{}\".format(x+1), \"GJet_eta.size() > {} ? GJet_phi.at({}) : -9999\".format(x, x))\n",
    "        rdf = rdf.Define(\"GJet_phi_jet{}\".format(x+1), \"GJet_phi.size() > {} ? GJet_phi.at({}) : -9999\".format(x, x))\n",
    "    rdf = rdf.Define(\"GJet_mass\", \"Jet_mass[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_jetId\", \"Jet_jetId[jet_mask]\")\n",
    "    rdf = rdf.Define(\"nGJet\", \"GJet_pt.size()\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepB\", \"Jet_btagDeepB[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepB_LeadtagJet\", \"GJet_btagDeepB.size() > 0 ? Reverse(Sort(GJet_btagDeepB)).at(0) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepB_SubleadtagJet\", \"GJet_btagDeepB.size() > 1 ? Reverse(Sort(GJet_btagDeepB)).at(1) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepFlavB\", \"Jet_btagDeepFlavB[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepFlavB_sorted\", \"Take(Jet_btagDeepFlavB[jet_mask], jet_deepjetsort)\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepFlavB_sorted_LeadtagJet\", \"GJet_btagDeepFlavB_sorted.size() > 0 ? GJet_btagDeepFlavB_sorted.at(0) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepFlavB_sorted_SubleadtagJet\", \"GJet_btagDeepFlavB_sorted.size() > 1 ? GJet_btagDeepFlavB_sorted.at(1) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GJet_LooseDeepCSV\", \"GJet_{0}[GJet_{0} > {1}]\".format(bTagWorkingPointDict[era][\"DeepCSV\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepCSV\"][\"L\"]))\n",
    "    rdf = rdf.Define(\"GJet_MediumDeepCSV\", \"GJet_{0}[GJet_{0} > {1}]\".format(bTagWorkingPointDict[era][\"DeepCSV\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepCSV\"][\"M\"]))\n",
    "    rdf = rdf.Define(\"GJet_TightDeepCSV\", \"GJet_{0}[GJet_{0} > {1}]\".format(bTagWorkingPointDict[era][\"DeepCSV\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepCSV\"][\"T\"]))\n",
    "    rdf = rdf.Define(\"nGJet_LooseDeepCSV\", \"GJet_LooseDeepCSV.size()\")\n",
    "    rdf = rdf.Define(\"nGJet_MediumDeepCSV\", \"GJet_MediumDeepCSV.size()\")\n",
    "    rdf = rdf.Define(\"nGJet_TightDeepCSV\", \"GJet_TightDeepCSV.size()\")\n",
    "    rdf = rdf.Define(\"GJet_LooseDeepJet\", \"GJet_{0}[GJet_{0} > {1}]\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepJet\"][\"L\"]))\n",
    "    rdf = rdf.Define(\"GJet_MediumDeepJet\", \"GJet_{0}[GJet_{0} > {1}]\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepJet\"][\"M\"]))\n",
    "    rdf = rdf.Define(\"GJet_TightDeepJet\", \"GJet_{0}[GJet_{0} > {1}]\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepJet\"][\"T\"]))\n",
    "    rdf = rdf.Define(\"nGJet_LooseDeepJet\", \"GJet_LooseDeepJet.size()\")\n",
    "    rdf = rdf.Define(\"nGJet_MediumDeepJet\", \"GJet_MediumDeepJet.size()\")\n",
    "    rdf = rdf.Define(\"nGJet_TightDeepJet\", \"GJet_TightDeepJet.size()\")\n",
    "    #These might be more efficiently calculated with my own custom code, instead of this... well, lets try for the sake of experimentation\n",
    "    #HT is just the sum of good jet pts\n",
    "    # HT2M is the sum of jet pt's for all but the two highest-b-tagged jets (2016 analysis requires 4+ jets to define this quantity), so here Take() is used twice.\n",
    "    # The first call acquires the good jet pt's sorted by b-tagging, the senond Take() gets the last n-2 elements, thereby excluding the two highest b-tagged jet's pt\n",
    "    # HTRat = HT(two highest b-tagged) / HT, so it's useful to define this similarly to HT2M (and crosscheck that HTNum + HT2M = HT!)\n",
    "    # H and H2M are defined similarly for the overall momentum magnitude...\n",
    "    # P = pt/sin(theta) = pt * (1/sin(theta)) = pt * cosh(eta)\n",
    "    rdf = rdf.Define(\"GJet_HT\", \"Sum(GJet_pt)\")\n",
    "    if useDeepCSV:\n",
    "        rdf = rdf.Define(\"GJet_pt_bsrt\", \"Take(GJet_pt, jet_deepcsvsort)\")\n",
    "        rdf = rdf.Define(\"GJet_eta_bsrt\", \"Take(GJet_eta, jet_deepcsvsort)\")\n",
    "        rdf = rdf.Define(\"GJet_phi_bsrt\", \"Take(GJet_phi, jet_deepcsvsort)\")\n",
    "    else:\n",
    "        rdf = rdf.Define(\"GJet_pt_bsrt\", \"Take(GJet_pt, jet_deepjetsort)\")\n",
    "        rdf = rdf.Define(\"GJet_eta_bsrt\", \"Take(GJet_eta, jet_deepjetsort)\")\n",
    "        rdf = rdf.Define(\"GJet_phi_bsrt\", \"Take(GJet_phi, jet_deepjetsort)\")\n",
    "    rdf = rdf.Define(\"GJet_P_bsrt\", \"GJet_pt_bsrt * ROOT::VecOps::cosh(GJet_eta_bsrt)\")\n",
    "    rdf = rdf.Define(\"GJet_HT2M\", \"GJet_pt_bsrt.size() > 2 ? Sum(Take(GJet_pt_bsrt, (2 - GJet_pt_bsrt.size()))) : -0.1\")\n",
    "    rdf = rdf.Define(\"GJet_HTNum\", \"GJet_pt_bsrt.size() > 2 ? Sum(Take(GJet_pt_bsrt, 2)) : -0.1\")\n",
    "    rdf = rdf.Define(\"GJet_HTRat\", \"GJet_pt_bsrt.size() > 2 ? (GJet_HT2M / GJet_HT) : -0.1\")\n",
    "    rdf = rdf.Define(\"GJet_dRbb\", \"GJet_pt_bsrt.size() > 2 ? ROOT::VecOps::DeltaR(GJet_eta_bsrt.at(0), GJet_eta_bsrt.at(1), GJet_phi_bsrt.at(0), GJet_phi_bsrt.at(1)) : -0.1\")\n",
    "    rdf = rdf.Define(\"GJet_dPhibb\", \"GJet_pt_bsrt.size() > 2 ? ROOT::VecOps::DeltaPhi(GJet_phi_bsrt.at(0), GJet_phi_bsrt.at(1)) : -999\")\n",
    "    rdf = rdf.Define(\"GJet_dEtabb\", \"GJet_pt_bsrt.size() > 2 ? abs(GJet_eta_bsrt.at(0) - GJet_eta_bsrt.at(1)) : -999\")\n",
    "    rdf = rdf.Define(\"GJet_H\", \"Sum(GJet_P_bsrt)\")\n",
    "    rdf = rdf.Define(\"GJet_H2M\", \"GJet_pt_bsrt.size() > 2 ? Sum(Take(GJet_P_bsrt, (2 - GJet_pt_bsrt.size()))) : -0.1\")\n",
    "    rdf = rdf.Define(\"GJet_HTH\", \"GJet_HT/GJet_H\")\n",
    "    rdf = rdf.Define(\"GJet_HTb\", \"Sum(GJet_pt[GJet_{0} > {1}])\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepJet\"][\"M\"]))\n",
    "    if debugInfo == True:\n",
    "        rdf = rdf.Define(\"GJet_ptALT\", \"Jet_pt[jet_maskALT]\")\n",
    "        rdf = rdf.Define(\"GJet_etaALT\", \"Jet_eta[jet_maskALT]\")\n",
    "        rdf = rdf.Define(\"GJet_phiALT\", \"Jet_phi[jet_maskALT]\")\n",
    "        rdf = rdf.Define(\"GJet_massALT\", \"Jet_mass[jet_maskALT]\")\n",
    "        rdf = rdf.Define(\"GJet_jetIdALT\", \"Jet_jetId[jet_maskALT]\")\n",
    "        rdf = rdf.Define(\"DiffMaskVsALT\", \"GJet_ptALT.size() - GJet_pt.size()\")\n",
    "        rdf = rdf.Define(\"DiffnJet\", \"nGJet - ESV_JetMETLogic_nJet_selection\")\n",
    "        rdf = rdf.Define(\"dR_Jet_Mu_leading\", \"GLepton_jetIdx_0 > -1 && abs(GLepton_pdgId.at(0)) == 13 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_0), GLepton_eta.at(0), Jet_phi.at(GLepton_jetIdx_0), GLepton_phi.at(0)) : -0.01\")\n",
    "        rdf = rdf.Define(\"dR_Jet_Mu_sublead\", \"GLepton_jetIdx_1 > -1 && abs(GLepton_pdgId.at(1)) == 13 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_1), GLepton_eta.at(1), Jet_phi.at(GLepton_jetIdx_1), GLepton_phi.at(1)) : -0.01\")\n",
    "        rdf = rdf.Define(\"dR_Jet_El_leading\", \"GLepton_jetIdx_0 > -1 && abs(GLepton_pdgId.at(1)) == 11 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_0), GLepton_eta.at(0), Jet_phi.at(GLepton_jetIdx_0), GLepton_phi.at(0)) : -0.01\")\n",
    "        rdf = rdf.Define(\"dR_Jet_El_sublead\", \"GLepton_jetIdx_1 > -1 && abs(GLepton_pdgId.at(1)) == 11 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_1), GLepton_eta.at(1), Jet_phi.at(GLepton_jetIdx_1), GLepton_phi.at(1)) : -0.01\")\n",
    "        #rdf = rdf.Define(\"dR_Jet_lep0\", \"GLepton_jetIdx_0 > -1 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_0), GLepton_eta.at(0), Jet_phi.at(GLepton_jetIdx_0), GLepton_phi.at(0)) : -0.01\")\n",
    "        #rdf = rdf.Define(\"dR_Jet_lep1\", \"GLepton_jetIdx_1 > -1 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_1), GLepton_eta.at(1), Jet_phi.at(GLepton_jetIdx_1), GLepton_phi.at(1)) : -0.01\")\n",
    "        rdf = rdf.Define(\"GJet_btagDeepFlavB_jet0Med\", \"GJet_MediumDeepJet.size() > 0 ? Reverse(Sort(GJet_MediumDeepJet)).at(0) : -0.000000000001\")\n",
    "        rdf = rdf.Define(\"GJet_btagDeepFlavB_jet1Med\", \"GJet_MediumDeepJet.size() > 1 ? Reverse(Sort(GJet_MediumDeepJet)).at(1) : -0.000000000001\")\n",
    "        rdf = rdf.Define(\"DeepJetSorted\", \"GJet_btagDeepFlavB_sorted.size() > 1 ? (GJet_btagDeepFlavB_sorted.at(0) >= GJet_btagDeepFlavB_sorted.at(1)) : true\")\n",
    "        rdf = rdf.Define(\"DeepJet0Minus1\", \"GJet_btagDeepFlavB_sorted.size() > 1 ? (GJet_btagDeepFlavB_sorted.at(0) - GJet_btagDeepFlavB_sorted.at(1)) : 0\")\n",
    "        rdf = rdf.Define(\"MediumDeepJetSorted\", \"GJet_MediumDeepJet.size() > 1 ? (Reverse(Sort(GJet_MediumDeepJet)).at(0) >= Reverse(Sort(GJet_MediumDeepJet)).at(1)) : true\")\n",
    "        rdf = rdf.Define(\"MediumDeepJet0Minus1\", \"GJet_MediumDeepJet.size() > 1 ? (Reverse(Sort(GJet_MediumDeepJet)).at(0) - Reverse(Sort(GJet_MediumDeepJet)).at(1)) : 0\")\n",
    "    return rdf\n",
    "    #Code taht doesn't work...\n",
    "    #Can see that the jets are in fact not sorted when calling Reverse(GJet_MediumDeepJet).at(0), for example, as the one .at(1) can sometimes not be smaller\n",
    "    #Looking at the definition makes it obvious, because Reverse is not short for \"ReverseSort\" but is literally just std::reverse. Must call (Arg)sort first...\n",
    "    #Definig a functor in the string like this doesn't work either:\n",
    "    #.Define(\"GJet_btagDeepB_jet0\", \"GJet_btagDeepB.size() > 0 ? Sort(GJet_btagDeepB, [](double x, double y) {return x > y;}).at(0) : -0.000000000001\")\\\n",
    "    #Cannot use ternary operator with RVec and double return types (Take(...) : -0.0000000001)\n",
    "    #.Define(\"GJet_btagDeepFlavB_jet0\", \"GJet_btagDeepFlavB.size() > 0 ? Take(Reverse(GJet_btagDeepFlavB), {0}) : -0.000000000001\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MET_corrections(input_df, uncormet_pt_branch = \"METFixEE2017_pt\", uncormet_phi_branch = \"METFixEE2017_phi\", \n",
    "                    run_branch = \"run\", year = \"2017\", isMC = False, npv_branch = \"\"):\n",
    "    MET_CorrXY_Code = '''\n",
    "enum TheRunEra{y2016B,y2016C,y2016D,y2016E,y2016F,y2016G,y2016H,y2017B,y2017C,y2017D,y2017E,y2017F,y2018A,y2018B,y2018C,y2018D,y2016MC,y2017MC,y2018MC};\n",
    "\n",
    "std::pair<double,double> METXYCorr_Met_MetPhi(double uncormet, double uncormet_phi, int runnb, int year, bool isMC, int npv){\n",
    "\n",
    "  std::pair<double,double>  TheXYCorr_Met_MetPhi(uncormet,uncormet_phi);\n",
    "  \n",
    "  if(npv>100) npv=100;\n",
    "  int runera =-1;\n",
    "  bool usemetv2 =false;\n",
    "  if(isMC && year == 2016) runera = y2016MC;\n",
    "  else if(isMC && year == 2017) {runera = y2017MC; usemetv2 =true;}\n",
    "  else if(isMC && year == 2018) runera = y2018MC;\n",
    "  \n",
    "  else if(!isMC && runnb >=272007 &&runnb<=275376  ) runera = y2016B;\n",
    "  else if(!isMC && runnb >=275657 &&runnb<=276283  ) runera = y2016C;\n",
    "  else if(!isMC && runnb >=276315 &&runnb<=276811  ) runera = y2016D;\n",
    "  else if(!isMC && runnb >=276831 &&runnb<=277420  ) runera = y2016E;\n",
    "  else if(!isMC && runnb >=277772 &&runnb<=278808  ) runera = y2016F;\n",
    "  else if(!isMC && runnb >=278820 &&runnb<=280385  ) runera = y2016G;\n",
    "  else if(!isMC && runnb >=280919 &&runnb<=284044  ) runera = y2016H;\n",
    "  \n",
    "  else if(!isMC && runnb >=297020 &&runnb<=299329 ){ runera = y2017B; usemetv2 =true;}\n",
    "  else if(!isMC && runnb >=299337 &&runnb<=302029 ){ runera = y2017C; usemetv2 =true;}\n",
    "  else if(!isMC && runnb >=302030 &&runnb<=303434 ){ runera = y2017D; usemetv2 =true;}\n",
    "  else if(!isMC && runnb >=303435 &&runnb<=304826 ){ runera = y2017E; usemetv2 =true;}\n",
    "  else if(!isMC && runnb >=304911 &&runnb<=306462 ){ runera = y2017F; usemetv2 =true;}\n",
    "  \n",
    "  else if(!isMC && runnb >=315252 &&runnb<=316995 ) runera = y2018A;\n",
    "  else if(!isMC && runnb >=316998 &&runnb<=319312 ) runera = y2018B;\n",
    "  else if(!isMC && runnb >=319313 &&runnb<=320393 ) runera = y2018C;\n",
    "  else if(!isMC && runnb >=320394 &&runnb<=325273 ) runera = y2018D;\n",
    "\n",
    "  else {\n",
    "    //Couldn't find data/MC era => no correction applied\n",
    "    return TheXYCorr_Met_MetPhi;\n",
    "  }\n",
    "  \n",
    "  double METxcorr(0.),METycorr(0.);\n",
    "\n",
    "  if(!usemetv2){//Current recommendation for 2016 and 2018\n",
    "    if(runera==y2016B) METxcorr = -(-0.0478335*npv -0.108032);\n",
    "    if(runera==y2016B) METycorr = -(0.125148*npv +0.355672);\n",
    "    if(runera==y2016C) METxcorr = -(-0.0916985*npv +0.393247);\n",
    "    if(runera==y2016C) METycorr = -(0.151445*npv +0.114491);\n",
    "    if(runera==y2016D) METxcorr = -(-0.0581169*npv +0.567316);\n",
    "    if(runera==y2016D) METycorr = -(0.147549*npv +0.403088);\n",
    "    if(runera==y2016E) METxcorr = -(-0.065622*npv +0.536856);\n",
    "    if(runera==y2016E) METycorr = -(0.188532*npv +0.495346);\n",
    "    if(runera==y2016F) METxcorr = -(-0.0313322*npv +0.39866);\n",
    "    if(runera==y2016F) METycorr = -(0.16081*npv +0.960177);\n",
    "    if(runera==y2016G) METxcorr = -(0.040803*npv -0.290384);\n",
    "    if(runera==y2016G) METycorr = -(0.0961935*npv +0.666096);\n",
    "    if(runera==y2016H) METxcorr = -(0.0330868*npv -0.209534);\n",
    "    if(runera==y2016H) METycorr = -(0.141513*npv +0.816732);\n",
    "    if(runera==y2017B) METxcorr = -(-0.259456*npv +1.95372);\n",
    "    if(runera==y2017B) METycorr = -(0.353928*npv -2.46685);\n",
    "    if(runera==y2017C) METxcorr = -(-0.232763*npv +1.08318);\n",
    "    if(runera==y2017C) METycorr = -(0.257719*npv -1.1745);\n",
    "    if(runera==y2017D) METxcorr = -(-0.238067*npv +1.80541);\n",
    "    if(runera==y2017D) METycorr = -(0.235989*npv -1.44354);\n",
    "    if(runera==y2017E) METxcorr = -(-0.212352*npv +1.851);\n",
    "    if(runera==y2017E) METycorr = -(0.157759*npv -0.478139);\n",
    "    if(runera==y2017F) METxcorr = -(-0.232733*npv +2.24134);\n",
    "    if(runera==y2017F) METycorr = -(0.213341*npv +0.684588);\n",
    "    if(runera==y2018A) METxcorr = -(0.362865*npv -1.94505);\n",
    "    if(runera==y2018A) METycorr = -(0.0709085*npv -0.307365);\n",
    "    if(runera==y2018B) METxcorr = -(0.492083*npv -2.93552);\n",
    "    if(runera==y2018B) METycorr = -(0.17874*npv -0.786844);\n",
    "    if(runera==y2018C) METxcorr = -(0.521349*npv -1.44544);\n",
    "    if(runera==y2018C) METycorr = -(0.118956*npv -1.96434);\n",
    "    if(runera==y2018D) METxcorr = -(0.531151*npv -1.37568);\n",
    "    if(runera==y2018D) METycorr = -(0.0884639*npv -1.57089);\n",
    "    if(runera==y2016MC) METxcorr = -(-0.195191*npv -0.170948);\n",
    "    if(runera==y2016MC) METycorr = -(-0.0311891*npv +0.787627);\n",
    "    if(runera==y2017MC) METxcorr = -(-0.217714*npv +0.493361);\n",
    "    if(runera==y2017MC) METycorr = -(0.177058*npv -0.336648);\n",
    "    if(runera==y2018MC) METxcorr = -(0.296713*npv -0.141506);\n",
    "    if(runera==y2018MC) METycorr = -(0.115685*npv +0.0128193);\n",
    "  }\n",
    "  else {//these are the corrections for v2 MET recipe (currently recommended for 2017)\n",
    "    if(runera==y2016B) METxcorr = -(-0.0374977*npv +0.00488262);\n",
    "    if(runera==y2016B) METycorr = -(0.107373*npv +-0.00732239);\n",
    "    if(runera==y2016C) METxcorr = -(-0.0832562*npv +0.550742);\n",
    "    if(runera==y2016C) METycorr = -(0.142469*npv +-0.153718);\n",
    "    if(runera==y2016D) METxcorr = -(-0.0400931*npv +0.753734);\n",
    "    if(runera==y2016D) METycorr = -(0.127154*npv +0.0175228);\n",
    "    if(runera==y2016E) METxcorr = -(-0.0409231*npv +0.755128);\n",
    "    if(runera==y2016E) METycorr = -(0.168407*npv +0.126755);\n",
    "    if(runera==y2016F) METxcorr = -(-0.0161259*npv +0.516919);\n",
    "    if(runera==y2016F) METycorr = -(0.141176*npv +0.544062);\n",
    "    if(runera==y2016G) METxcorr = -(0.0583851*npv +-0.0987447);\n",
    "    if(runera==y2016G) METycorr = -(0.0641427*npv +0.319112);\n",
    "    if(runera==y2016H) METxcorr = -(0.0706267*npv +-0.13118);\n",
    "    if(runera==y2016H) METycorr = -(0.127481*npv +0.370786);\n",
    "    if(runera==y2017B) METxcorr = -(-0.19563*npv +1.51859);\n",
    "    if(runera==y2017B) METycorr = -(0.306987*npv +-1.84713);\n",
    "    if(runera==y2017C) METxcorr = -(-0.161661*npv +0.589933);\n",
    "    if(runera==y2017C) METycorr = -(0.233569*npv +-0.995546);\n",
    "    if(runera==y2017D) METxcorr = -(-0.180911*npv +1.23553);\n",
    "    if(runera==y2017D) METycorr = -(0.240155*npv +-1.27449);\n",
    "    if(runera==y2017E) METxcorr = -(-0.149494*npv +0.901305);\n",
    "    if(runera==y2017E) METycorr = -(0.178212*npv +-0.535537);\n",
    "    if(runera==y2017F) METxcorr = -(-0.165154*npv +1.02018);\n",
    "    if(runera==y2017F) METycorr = -(0.253794*npv +0.75776);\n",
    "    if(runera==y2018A) METxcorr = -(0.362642*npv +-1.55094);\n",
    "    if(runera==y2018A) METycorr = -(0.0737842*npv +-0.677209);\n",
    "    if(runera==y2018B) METxcorr = -(0.485614*npv +-2.45706);\n",
    "    if(runera==y2018B) METycorr = -(0.181619*npv +-1.00636);\n",
    "    if(runera==y2018C) METxcorr = -(0.503638*npv +-1.01281);\n",
    "    if(runera==y2018C) METycorr = -(0.147811*npv +-1.48941);\n",
    "    if(runera==y2018D) METxcorr = -(0.520265*npv +-1.20322);\n",
    "    if(runera==y2018D) METycorr = -(0.143919*npv +-0.979328);\n",
    "    if(runera==y2016MC) METxcorr = -(-0.159469*npv +-0.407022);\n",
    "    if(runera==y2016MC) METycorr = -(-0.0405812*npv +0.570415);\n",
    "    if(runera==y2017MC) METxcorr = -(-0.182569*npv +0.276542);\n",
    "    if(runera==y2017MC) METycorr = -(0.155652*npv +-0.417633);\n",
    "    if(runera==y2018MC) METxcorr = -(0.299448*npv +-0.13866);\n",
    "    if(runera==y2018MC) METycorr = -(0.118785*npv +0.0889588);\n",
    "  }\n",
    "\n",
    "  double CorrectedMET_x = uncormet *cos( uncormet_phi)+METxcorr;\n",
    "  double CorrectedMET_y = uncormet *sin( uncormet_phi)+METycorr;\n",
    "\n",
    "  double CorrectedMET = sqrt(CorrectedMET_x*CorrectedMET_x+CorrectedMET_y*CorrectedMET_y);\n",
    "  double CorrectedMETPhi;\n",
    "  if(CorrectedMET_x==0 && CorrectedMET_y>0) CorrectedMETPhi = TMath::Pi();\n",
    "  else if(CorrectedMET_x==0 && CorrectedMET_y<0 )CorrectedMETPhi = -TMath::Pi();\n",
    "  else if(CorrectedMET_x >0) CorrectedMETPhi = TMath::ATan(CorrectedMET_y/CorrectedMET_x);\n",
    "  else if(CorrectedMET_x <0&& CorrectedMET_y>0) CorrectedMETPhi = TMath::ATan(CorrectedMET_y/CorrectedMET_x) + TMath::Pi();\n",
    "  else if(CorrectedMET_x <0&& CorrectedMET_y<0) CorrectedMETPhi = TMath::ATan(CorrectedMET_y/CorrectedMET_x) - TMath::Pi();\n",
    "  else CorrectedMETPhi =0;\n",
    "\n",
    "  TheXYCorr_Met_MetPhi.first= CorrectedMET;\n",
    "  TheXYCorr_Met_MetPhi.second= CorrectedMETPhi;\n",
    "  return TheXYCorr_Met_MetPhi;\n",
    "\n",
    "}\n",
    "'''\n",
    "    #rdf = input_df\n",
    "    #rdf = rdf.Define()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutPVandMETFilters(input_df, level, isData=False):\n",
    "    rdf = input_df\n",
    "    if \"selection\" in level:\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000000000000001), \"PV NDoF > 4\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000000000000010), \"PV |z| < 24.0\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000000000000100), \"PV rho < 2\")\n",
    "        if isData == True:\n",
    "            rdf = rdf.Filter(\"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000000000001000), \"MET globalSuperTightHalo2016Filter\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000000000010000), \"MET goodVertices\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000000000100000), \"MET HBHENoiseFilter\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000000001000000), \"MET HBHENoiseIsoFilter\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000000010000000), \"MET EcalDeadCellTriggerPrimitiveFilter\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000000100000000), \"MET BadPFMuonFilter\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000001000000000), \"MET ecalBadCalibFilterV2\")\n",
    "    elif \"baseline\" in level:\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000000000000001), \"PV NDoF > 4\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000000000000010), \"PV |z| < 24.0\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000000000000100), \"PV rho < 2\")\n",
    "        if isData == True:\n",
    "            rdf = rdf.Filter(\"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000000000001000), \"MET globalSuperTightHalo2016Filter\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000000000010000), \"MET goodVertices\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000000000100000), \"MET HBHENoiseFilter\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000000001000000), \"MET HBHENoiseIsoFilter\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000000010000000), \"MET EcalDeadCellTriggerPrimitiveFilter\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000000100000000), \"MET BadPFMuonFilter\")\n",
    "        rdf = rdf.Filter(\"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000001000000000), \"MET ecalBadCalibFilterV2\")\n",
    "    return rdf\n",
    "    \n",
    "def defineEventVars(input_df):\n",
    "    rdf = input_df\n",
    "    #rdf = rdf.Define(\"JML_baseline_pass\", \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00001100011111111111))#Cut on MET pt, nJet, HT\n",
    "    rdf = rdf.Define(\"JML_baseline_pass\", \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000001111111111))#Only PV and MET filters required to pass\n",
    "    #rdf = rdf.Define(\"JML_selection_pass\", \"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00001100011111111111))#Cut on MET pt, nJet, HT\n",
    "    rdf = rdf.Define(\"JML_selection_pass\", \"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000001111111111))#Only PV and MET filters required to pass\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillHistos(input_df, input_name=None, wgtVar=\"wgt_SUMW\", isData = True, histos1D_dict=None, histos2D_dict=None, histosNS_dict=None, \n",
    "               doMuons=False, doElectrons=False, doLeptons=False, doJets=False, doWeights=False, doEventVars=False, \n",
    "               makeMountains=False, debugInfo=True, nJetsToHisto=10, useDeepCSV=False):\n",
    "    \"\"\"Method to fill histograms given an input RDataFrame, input sample/dataset name, input histogram dictionaries.\n",
    "    Has several options of which histograms to fill, such as Leptons, Jets, Weights, EventVars, etc.\n",
    "    Types of histograms (1D, 2D, those which will not be stacked(NS - histosNS)) are filled by passing non-None\n",
    "    value to that histosXX_dict variable. Internally stored with structure separating the categories of histos,\n",
    "    with 'Muons,' 'Electrons,' 'Leptons,' 'Jets,' 'EventVars,' 'Weights' subcategories.\"\"\"\n",
    "    if doMuons == False and doElectrons == False and doLeptons == False\\\n",
    "                and doJets == False and doWeights == False and doEventVars == False\\\n",
    "                and makeMountains == False:\n",
    "        raise RuntimeError(\"Must select something to plot:\"\\\n",
    "                               \"Set do{Muons,Electrons,Leptons,Jets,Weights,EventVars,etc} = True in init method\")\n",
    "    \n",
    "    pi = ROOT.TMath.Pi()\n",
    "    if doWeights == True:\n",
    "        if histosNS_dict != None:\n",
    "            if \"EventVars\" not in histosNS_dict:\n",
    "                histosNS_dict[\"EventVars\"] = {}\n",
    "            histosNS[name][lvl][\"EventVars\"][\"wgt_NUMW\"] = input_df.Histo1D(\"wgt_NUMW\")\n",
    "            histosNS[name][lvl][\"EventVars\"][wgtVar] = input_df.Histo1D(wgtVar)\n",
    "        if histos1D_dict != None:\n",
    "            if \"EventVars\" not in histos1D_dict:\n",
    "                histos1D_dict[\"EventVars\"] = {}\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_diff\"] = input_df.Histo1D((\"wgt_diff\", \"(wgt_NUMW - wgt_SUMW)/wgt_SUMW\", 2000, -1, 1), \"wgt_diff\", \"1\")\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_PU\"] = input_df.Histo1D((\"wgt_PU\", \"\", 2000, 0, 5), \"puWeight\", \"wgt_SUMW\")\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_LSF\"] = input_df.Histo1D((\"wgt_LSF\", \"\", 2000, 0, 5), \"wgt_LSF\", \"wgt_SUMW\")\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_L1PF\"] = input_df.Histo1D((\"wgt_L1PF\", \"\", 2000, 0, 5), \"L1PreFiringWeight_Nom\", \"wgt_SUMW\")\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_PU_LSF_L1PF\"] = input_df.Histo1D((\"wgt_PU_LSF_L1PF\", \"\", 2000, 0, 5), \"wgt_PU_LSF_L1PF\", \"wgt_SUMW\")\n",
    "    if doMuons == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Muons\" not in histos1D_dict: \n",
    "                histos1D_dict[\"Muons\"] = {}\n",
    "            histos1D_dict[\"Muons\"][\"idx\"] = input_df.Histo1D((\"idx_({})\".format(wgtVar), \"\", 5, 0, 5), \"Muon_idx\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"Gidx\"] = input_df.Histo1D((\"Gidx_({})\".format(wgtVar), \"\", 5, 0, 5), \"GMuon_idx\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"nMu\"] = input_df.Histo1D((\"nMuon_({})\".format(wgtVar), \"\", 5, 0, 5), \"nGMuon\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"nLooseMu\"] = input_df.Histo1D((\"nLooseMuon_({})\".format(wgtVar), \"\", 5, 0, 5), \"nLooseGMuon\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"nMediumMu\"] = input_df.Histo1D((\"nMediumMuon_({})\".format(wgtVar), \"\", 5, 0, 5), \"nMediumGMuon\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"pt\"] = input_df.Histo1D((\"Muon_pt_({})\".format(wgtVar), \"\", 100, 0, 500), \"GMuon_pt\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"eta\"] = input_df.Histo1D((\"Muon_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GMuon_eta\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"phi\"] = input_df.Histo1D((\"Muon_phi_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GMuon_phi\", wgtVar)\n",
    "            #histos1D_dict[\"Muons\"][\"mass\"] = input_df.Histo1D((\"Muon_mass_({})\".format(wgtVar), \"\", 50, 0, 1), \"GMuon_mass\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"iso\"] = input_df.Histo1D((\"Muon_iso_({})\".format(wgtVar), \"\", 8, 0, 8), \"GMuon_pfIsoId\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"dz\"] = input_df.Histo1D((\"Muon_dz_({})\".format(wgtVar), \"\", 100, -0.01, 0.01), \"GMuon_dz\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"dxy\"] = input_df.Histo1D((\"Muon_dxy_({})\".format(wgtVar), \"\", 100, -0.1, 0.1), \"GMuon_dxy\", wgtVar)\n",
    "            #histos1D_dict[\"Muons\"][\"d0\"] = input_df.Histo1D((\"Muon_d0_({})\".format(wgtVar), \"\", 100, -0.01, 0.01), \"GMuon_d0\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"ip3d\"] = input_df.Histo1D((\"Muon_ip3d_({})\".format(wgtVar), \"\", 100, 0, 0.01), \"GMuon_ip3d\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"pfRelIso03_all\"] = input_df.Histo1D((\"Muon_pfRelIso03_all_({})\".format(wgtVar), \"\", 100, 0, 0.2), \"GMuon_pfRelIso03_all\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"pfRelIso03_chg\"] = input_df.Histo1D((\"Muon_pfRelIso03_chg_({})\".format(wgtVar), \"\", 100, 0, 0.2), \"GMuon_pfRelIso03_chg\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"pfRelIso04_all\"] = input_df.Histo1D((\"Muon_pfRelIso04_all_({})\".format(wgtVar), \"\", 100, 0, 0.2), \"GMuon_pfRelIso04_all\", wgtVar)\n",
    "        if histos2D_dict != None:\n",
    "            if \"Muons\" not in histos2D_dict:\n",
    "                histos2D_dict[\"Muons\"] = {}\n",
    "            histos2D_dict[\"Muons\"][\"eta_phi\"] = input_df.Histo2D((\"Muon_eta_phi_({})\".format(wgtVar), \"\",\n",
    "                                                                  104, -2.6, 2.6,\n",
    "                                                                  64, -pi, pi),\n",
    "                                                                 \"GMuon_eta\", \"GMuon_phi\", wgtVar)\n",
    "            histos2D_dict[\"Muons\"][\"dz_ip3d\"] = input_df.Histo2D((\"Muon_dz_ip3d_({})\".format(wgtVar), \"\",\n",
    "                                                                  100, -0.01, 0.01,\n",
    "                                                                  100, 0, 0.01),\n",
    "                                                                 \"GMuon_dz\", \"GMuon_ip3d\", wgtVar)\n",
    "    if doElectrons == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Electrons\" not in histos1D_dict: \n",
    "                histos1D_dict[\"Electrons\"] = {}\n",
    "            histos1D_dict[\"Electrons\"][\"nEl\"] = input_df.Histo1D((\"nElectron_({})\".format(wgtVar), \"\", 5, 0, 5), \"nGElectron\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"nLooseEl\"] = input_df.Histo1D((\"nLooseElectron_({})\".format(wgtVar), \"\", 5, 0, 5), \"nLooseGElectron\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"nMediumEl\"] = input_df.Histo1D((\"nMediumElectron_({})\".format(wgtVar), \"\", 5, 0, 5), \"nMediumGElectron\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"pt\"] = input_df.Histo1D((\"Electron_pt_({})\".format(wgtVar), \"\", 100, 0, 500), \"GElectron_pt\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"eta\"] = input_df.Histo1D((\"Electron_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GElectron_eta\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"phi\"] = input_df.Histo1D((\"Electron_phi_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GElectron_phi\", wgtVar)\n",
    "            #histos1D_dict[\"Electrons\"][\"mass\"] = input_df.Histo1D((\"Electron_mass_({})\".format(wgtVar), \"\", 50, 0, 1), \"GElectron_mass\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"dz\"] = input_df.Histo1D((\"Electron_dz_({})\".format(wgtVar), \"\", 100, -0.01, 0.01), \"GElectron_dz\", wgtVar)\n",
    "            #histos1D_dict[\"Electrons\"][\"d0\"] = input_df.Histo1D((\"Electron_d0_({})\".format(wgtVar), \"\", 100, 0, 0.01), \"GElectron_d0\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"ip3d\"] = input_df.Histo1D((\"Electron_ip3d_({})\".format(wgtVar), \"\", 100, 0, 0.01), \"GElectron_ip3d\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"pfRelIso03_all\"] = input_df.Histo1D((\"Electron_pfRelIso03_all_({})\".format(wgtVar), \"\", 100, 0, 0.2), \"GElectron_pfRelIso03_all\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"pfRelIso03_chg\"] = input_df.Histo1D((\"Electron_pfRelIso03_chg_({})\".format(wgtVar), \"\", 100, 0, 0.2), \"GElectron_pfRelIso03_chg\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"cutBased\"] = input_df.Histo1D((\"Electron_cutBased_({})\".format(wgtVar), \"\", 5, 0, 5), \"GElectron_cutBased\", wgtVar)\n",
    "        if histos2D_dict != None:\n",
    "            if \"Electrons\" not in histos2D_dict: \n",
    "                histos2D_dict[\"Electrons\"] = {}\n",
    "            histos2D_dict[\"Electrons\"][\"eta_phi\"] = input_df.Histo2D((\"Electron_eta_phi_({})\".format(wgtVar), \"\",\n",
    "                                                                      104, -2.6, 2.6,\n",
    "                                                                      64, -pi, pi),\n",
    "                                                                     \"GElectron_eta\", \"GElectron_phi\", wgtVar)\n",
    "            histos2D_dict[\"Electrons\"][\"dz_ip3d\"] = input_df.Histo2D((\"Electron_dz_ip3d_({})\".format(wgtVar), \"\",\n",
    "                                                                      100, -0.01, 0.01,\n",
    "                                                                      100, 0, 0.01),\n",
    "                                                                     \"GElectron_dz\", \"GElectron_ip3d\", wgtVar)\n",
    "    if doLeptons == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Leptons\" not in histos1D_dict: \n",
    "                histos1D_dict[\"Leptons\"] = {}\n",
    "            histos1D_dict[\"Leptons\"][\"pt_LeadLep\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_pt_LeadLep_({})\".format(wgtVar), \"\", 100, 0, 500),\"GLepton_pt_LeadLep\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"pt_SubleadLep\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_pt_SubleadLep_({})\".format(wgtVar), \"\", 100, 0, 500),\"GLepton_pt_SubleadLep\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"eta\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6),\"GLepton_eta\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"phi\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_phi_({})\".format(wgtVar), \"\", 64, -pi, pi),\"GLepton_phi\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"nLepton\"] = input_df\\\n",
    "                    .Histo1D((\"nLepton_({})\".format(wgtVar), \"\", 5, 0, 5), \"nGLepton\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"pdgId\"] = input_df\\\n",
    "                    .Histo1D((\"Lepton_pdgId_({})\".format(wgtVar), \"\", 32, -16, 16), \"GLepton_pdgId\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"jetIdx\"] = input_df\\\n",
    "                    .Histo1D((\"Lepton_jetIdx_({})\".format(wgtVar), \"\", 20, 0, 20), \"GLepton_jetIdx\", wgtVar)\n",
    "            #histos1D_dict[\"Leptons\"][\"LepSF\"] = input_df\\\n",
    "            #        .Histo1D((\"Lepton_SF_({})\".format(\"wgt_SUMW_PU:HARDCODED\"), \"\", 100, 0.93, 1.03), \"GLepton_SF_nom\", \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"LSF\"] = input_df\\\n",
    "            #        .Histo1D((\"LSF_({})\".format(\"wgt_SUMW_PU:HARDCODED\"), \"\", 200, 0.80, 1.1), \"wgt_LSF\", \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"SPL_SP\"] = input_df\\\n",
    "            #        .Histo1D((\"SPL_SP_({})\".format(\"wgt_SUMW_PU:HARDCODED\"), \"\", 200, 0.80, 1.1), \"SPL_SP\", \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"LepSF\"] = input_df.Histo1D(\"GLepton_SF_nom\")#, \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"LSF\"] = input_df.Histo1D(\"wgt_LSF\")#, \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"SPL_SP\"] = input_df.Histo1D(\"SPL_SP\")#, \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"SUMW_PU\"] = input_df.Histo1D(\"wgt_SUMW_PU\")#, \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"SUMW_PU_LSF\"] = input_df.Histo1D(\"wgt_SUMW_PU_LSF\")#, \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"PU\"] = input_df.Histo1D(\"puWeight\")#, \"wgt_SUMW_PU\")\n",
    "    if doJets == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Jets\" not in histos1D_dict:\n",
    "                histos1D_dict[\"Jets\"] = {}\n",
    "            histos1D_dict[\"Jets\"][\"pt\"] = input_df.Histo1D((\"Jet_pt_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_pt\", wgtVar)\n",
    "            for x in xrange(nJetsToHisto):\n",
    "                histos1D_dict[\"Jets\"][\"pt_jet{}\".format(x+1)] = input_df.Histo1D((\"Jet_pt_jet{}({})\".format(x+1, wgtVar), \"\", 100, 0, 500), \"GJet_pt_jet{}\".format(x+1), wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"eta_jet{}\".format(x+1)] = input_df.Histo1D((\"Jet_eta_jet{}({})\".format(x+1, wgtVar), \"\", 104, -2.6, 2.6), \"GJet_eta_jet{}\".format(x+1), wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"phi_jet{}\".format(x+1)] = input_df.Histo1D((\"Jet_phi_jet{}({})\".format(x+1, wgtVar), \"\", 64, -pi, pi), \"GJet_phi_jet{}\".format(x+1), wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"eta\"] = input_df.Histo1D((\"Jet_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GJet_eta\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"phi\"] = input_df.Histo1D((\"Jet_phi_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GJet_phi\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"mass\"] = input_df.Histo1D((\"Jet_mass_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_mass\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"jetId\"] = input_df.Histo1D((\"Jet_jetId_({})\".format(wgtVar), \"\", 8, 0, 8), \"GJet_jetId\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepB_LeadtagJet\"] = input_df.Histo1D((\"Jet_btagDeepB_LeadtagJet_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepB_LeadtagJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepB_SubleadtagJet\"] = input_df.Histo1D((\"Jet_btagDeepB_SubleadtagJet_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepB_SubleadtagJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepJet_LeadtagJet\"] = input_df.Histo1D((\"Jet_btagDeepJetB_LeadtagJet_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepFlavB_sorted_LeadtagJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepJet_SubleadtagJet\"] = input_df.Histo1D((\"Jet_btagDeepJetB_SubleadtagJet_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepFlavB_sorted_SubleadtagJet\", wgtVar)\n",
    "            #histos1D_dict[\"Jets\"][\"nMediumCSVv2\"] = input_df.Histo1D((\"nJet_MediumCSVv2_({})\".format(wgtVar), \"\", 10, 0, 10), \"nGJet_MediumCSVv2\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"nMediumDeepCSV\"] = input_df.Histo1D((\"nJet_MediumDeepCSV_({})\".format(wgtVar), \"\", 10, 0, 10), \"nGJet_MediumDeepCSV\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"nMediumDeepJet\"] = input_df.Histo1D((\"nJet_MediumDeepJet_({})\".format(wgtVar), \"\", 10, 0, 10), \"nGJet_MediumDeepJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"nJet\"] = input_df.Histo1D((\"nJet_({})\".format(wgtVar), \"\", 15, 0, 15), \"nGJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"dR_Jet_Mu_leading\"] = input_df.Histo1D((\"dR_Jet_Mu_leading_({})\".format(wgtVar), \"dR(Jet, #mu_{leading}); dR; Events)\", 40, 0, 0.8), \"dR_Jet_Mu_leading\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"dR_Jet_Mu_sublead\"] = input_df.Histo1D((\"dR_Jet_Mu_sublead_({})\".format(wgtVar), \"dR(Jet, #mu_{subleading}); dR; Events)\", 40, 0, 0.8), \"dR_Jet_Mu_sublead\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"dR_Jet_El_leading\"] = input_df.Histo1D((\"dR_Jet_El_leading_({})\".format(wgtVar), \"dR(Jet, #e_{leading}); dR; Events)\", 40, 0, 0.8), \"dR_Jet_El_leading\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"dR_Jet_El_sublead\"] = input_df.Histo1D((\"dR_Jet_El_sublead_({})\".format(wgtVar), \"dR(Jet, #e_{subleading}); dR; Events)\", 40, 0, 0.8), \"dR_Jet_El_sublead\", wgtVar)\n",
    "            \n",
    "            if debugInfo == True:\n",
    "                #histos1D_dict[\"Jets\"][\"DiffMaskVsALT\"] = input_df.Histo1D((\"DiffMaskVsALT\", \"\", 10, -10, 10), \"DiffMaskVsALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"DiffnJet\"] = input_df.Histo1D((\"DiffnJet\", \"\", 10, -10, 10), \"DiffnJet\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"DeepJetSorted\"] = input_df.Histo1D(\"DeepJetSorted\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"DeepJetLeadtagMinusSubleadtag\"] = input_df.Histo1D((\"DeepJetLeadtagMinusSubleadtag\", \"DeepJet(Leadtag - Subleadtag);;Events\", 100, -1, 1), \"DeepJet0Minus1\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"MediumDeepJetSorted\"] = input_df.Histo1D(\"MediumDeepJetSorted\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"MediumDeepJet0Minus1\"] = input_df.Histo1D((\"MediumDeepJet0Minus1\", \"\", 100, -1, 1), \"MediumDeepJet0Minus1\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"btagDeepJet_jet0Med\"] = input_df.Histo1D((\"Jet_btagDeepJetB_jet0Med_({})\".format(wgtVar), \"\", 102, -0.02, 1), \"GJet_btagDeepFlavB_jet0Med\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"btagDeepJet_jet1Med\"] = input_df.Histo1D((\"Jet_btagDeepJetB_jet1Med_({})\".format(wgtVar), \"\", 102, -0.02, 1), \"GJet_btagDeepFlavB_jet1Med\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"nJetNUMW\"] = input_df.Histo1D((\"nJet_NUMW\", \"\", 15, 0, 15), \"nGJet\", \"wgt_NUMW_V2\")\n",
    "                #histos1D_dict[\"Jets\"][\"nJetSUMW_PU\"] = input_df.Histo1D((\"nJet_SUMW_PU\", \"\", 15, 0, 15), \"nGJet\", \"wgt_SUMW_PU\")\n",
    "                #histos1D_dict[\"Jets\"][\"nJetSUMW_LSF\"] = input_df.Histo1D((\"nJet_SUMW_LSF\", \"\", 15, 0, 15), \"nGJet\", \"wgt_SUMW_LSF\")\n",
    "                #histos1D_dict[\"Jets\"][\"ptALT\"] = input_df.Histo1D((\"Jet_ptALT_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_ptALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"etaALT\"] = input_df.Histo1D((\"Jet_etaALT_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GJet_etaALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"phiALT\"] = input_df.Histo1D((\"Jet_phiALT_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GJet_phiALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"massALT\"] = input_df.Histo1D((\"Jet_massALT_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_massALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"jetIdALT\"] = input_df.Histo1D((\"Jet_jetIdALT_({})\".format(wgtVar), \"\", 8, 0, 8), \"GJet_jetIdALT\", wgtVar)\n",
    "        \n",
    "        if histos2D_dict != None:\n",
    "            if \"Jets\" not in histos2D_dict:\n",
    "                histos2D_dict[\"Jets\"] = {}\n",
    "            histos2D_dict[\"Jets\"][\"eta_phi\"] = input_df.Histo2D((\"Jet_eta_phi_({})\".format(wgtVar), \"\",\n",
    "                                                                 104, -2.6, 2.6,\n",
    "                                                                 64, -pi, pi),\n",
    "                                                                \"GJet_eta\", \"GJet_phi\", wgtVar)\n",
    "    if doEventVars == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"EventVars\" not in histos1D_dict:\n",
    "                histos1D_dict[\"EventVars\"] = {}\n",
    "            #histos1D_dict[\"EventVars\"][\"JML_baseline\"] = input_df.Histo1D((\"JML_baseline_({})\".format(wgtVar), \"\", 2,0,2), \"JML_baseline_pass\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"JML_selection\"] = input_df.Histo1D((\"JML_selection_({})\".format(wgtVar), \"\", 2,0,2), \"JML_selection_pass\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HT_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT_baseline_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_HT_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"H_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_H_baseline_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_H_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HT2M_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT2M_baseline_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HT2M_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"H2M_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_H2M_baseline_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_H2M_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTb_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTb_baseline_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HTb_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTH_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTH_baseline_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTH_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTRat_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTRat_baseline_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTRat_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"dRbb_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_dRbb_baseline_({})\".format(wgtVar), \"\", 64,0,2*pi), \"ESV_JetMETLogic_dRbb_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"DiLepMass_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_DiLepMass_baseline_({})\".format(wgtVar), \"\", 100,0,500), \"ESV_JetMETLogic_DiLepMass_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HT_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT_selection_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_HT_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"H_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_H_selection_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_H_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HT2M_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT2M_selection_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HT2M_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"H2M_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_H2M_selection_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_H2M_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTb_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTb_selection_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HTb_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTH_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTH_selection_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTH_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTRat_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTRat_selection_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTRat_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"dRbb_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_dRbb_selection_({})\".format(wgtVar), \"\", 64,0,2*pi), \"ESV_JetMETLogic_dRbb_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"DiLepMass_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_DiLepMass_selection_({})\".format(wgtVar), \"\", 100,0,500), \"ESV_JetMETLogic_DiLepMass_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"MET_pt\"] = input_df.Histo1D((\"MET_pt_({})\".format(wgtVar), \"\", 100,30,1030), \"METFixEE2017_pt\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"MET_phi\"] = input_df.Histo1D((\"MET_phi_({})\".format(wgtVar), \"\", 100,-pi,pi), \"METFixEE2017_phi\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HT\"] = input_df.Histo1D((\"HT_({})\".format(wgtVar), \"\", 130,400,1700), \"GJet_HT\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"H\"] = input_df.Histo1D((\"H_({})\".format(wgtVar), \"\", 160,400,2000), \"GJet_H\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HT2M\"] = input_df.Histo1D((\"HT2M_({})\".format(wgtVar), \"\", 100,0,1000), \"GJet_HT2M\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"H2M\"] = input_df.Histo1D((\"H2M_({})\".format(wgtVar), \"\", 150,0,1500), \"GJet_H2M\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTb\"] = input_df.Histo1D((\"HTb_({})\".format(wgtVar), \"\", 100,0,1000), \"GJet_HTb\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTH\"] = input_df.Histo1D((\"HTH_({})\".format(wgtVar), \"\", 100,0,1), \"GJet_HTH\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTRat\"] = input_df.Histo1D((\"HTRat_({})\".format(wgtVar), \"\", 100,0,1), \"GJet_HTRat\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dRbb\"] = input_df.Histo1D((\"dRbb_({})\".format(wgtVar), \"\", 64,0,2*pi), \"GJet_dRbb\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dPhibb\"] = input_df.Histo1D((\"dPhibb_({})\".format(wgtVar), \"\", 64,-pi,pi), \"GJet_dPhibb\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dEtabb\"] = input_df.Histo1D((\"dEtabb_({})\".format(wgtVar), \"\", 50,0,5), \"GJet_dEtabb\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dRll\"] = input_df.Histo1D((\"dRll_({})\".format(wgtVar), \"\", 64,0,2*pi), \"GLepton_dRll\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dPhill\"] = input_df.Histo1D((\"dPhill_({})\".format(wgtVar), \"\", 64,-pi,pi), \"GLepton_dPhill\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dEtall\"] = input_df.Histo1D((\"dEtall_({})\".format(wgtVar), \"\", 50,0,5), \"GLepton_dEtall\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"MTofMETandEl\"] = input_df.Histo1D((\"MTofMETandEl_({})\".format(wgtVar), \"\", 100, 0, 200), \"MTofMETandEl\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"MTofMETandMu\"] = input_df.Histo1D((\"MTofMETandMu_({})\".format(wgtVar), \"\", 100, 0, 200), \"MTofMETandMu\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"MTofElandMu\"] = input_df.Histo1D((\"MTofElandMu_({})\".format(wgtVar), \"\", 100, 0, 200), \"MTofElandMu\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"MTMasslessCheck\"] = input_df.Histo1D((\"MTMasslessCheck_({})\".format(wgtVar), \"\", 100, 0, 200), \"MTMasslessCheck\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"MTCrossCheck\"] = input_df.Histo1D((\"MTCrossCheck_({})\".format(wgtVar), \"\", 100, 0, 200), \"MTCrossCheck\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"MTCrossCheckDifference\"] = input_df.Histo1D((\"MTCrossCheckDifference_({})\".format(wgtVar), \"\", 100, 0, 10), \"MTCrossCheckDifference\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"MTCrossCheckMasslessDifference\"] = input_df.Histo1D((\"MTCrossCheckMasslessDifference_({})\".format(wgtVar), \"\", 100, 0, 0.02), \"MTCrossCheckMasslessDifference\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"PV_npvsGood\"] = input_df.Histo1D((\"PV_npvsGood_({})\".format(wgtVar), \"\", 100, 0, 100), \"PV_npvsGood\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"PV_npvs\"] = input_df.Histo1D((\"PV_npvs_({})\".format(wgtVar), \"\", 150, 0, 150), \"PV_npvs\", wgtVar)\n",
    "            if isData == False:\n",
    "                histos1D_dict[\"EventVars\"][\"Pileup_nTrueInt\"] = input_df.Histo1D((\"Pileup_TrueInt_({})\".format(wgtVar), \";Pileup_TrueInt;Events\", 150, 0, 150), \"Pileup_nTrueInt\", wgtVar)\n",
    "                histos1D_dict[\"EventVars\"][\"Pileup_nTrueInt_XS\"] = input_df.Histo1D((\"Pileup_TrueInt_({})\".format(\"wgt_SUMW\"), \";Pileup_TrueInt;Events\", 150, 0, 150), \"Pileup_nTrueInt\", \"wgt_SUMW\")\n",
    "                histos1D_dict[\"EventVars\"][\"Pileup_nPU_XS\"] = input_df.Histo1D((\"Pileup_nPU_({})\".format(\"wgt_SUMW\"), \";Pileup_nPU;Events\", 150, 0, 150), \"Pileup_nPU\", \"wgt_SUMW\")\n",
    "                histos1D_dict[\"EventVars\"][\"Pileup_nPU\"] = input_df.Histo1D((\"Pileup_nPU_({})\".format(wgtVar), \";Pileup_nPU;Events\", 150, 0, 150), \"Pileup_nPU\", wgtVar)\n",
    "            \n",
    "        if histos2D_dict != None:\n",
    "            if \"EventVars\" not in histos2D_dict:\n",
    "                histos2D_dict[\"EventVars\"] = {}\n",
    "            if isData == False:\n",
    "                histos2D_dict[\"EventVars\"][\"npvsGood_vs_nTrueInt\"] = input_df.Histo2D((\"npvsGood_vs_nTrueInt_({})\".format(wgtVar), \";nTrueInt;npvsGood\", 150, 0, 150, 150, 0, 150), \"Pileup_nTrueInt\", \"PV_npvsGood\", wgtVar)\n",
    "                histos2D_dict[\"EventVars\"][\"npvsGood_vs_nPU\"] = input_df.Histo2D((\"npvsGood_vs_nPU_({})\".format(wgtVar), \";nPU;npvsGood\", 150, 0, 150, 150, 0, 150), \"Pileup_nPU\", \"PV_npvsGood\", wgtVar)\n",
    "                histos2D_dict[\"EventVars\"][\"npvs_vs_nTrueInt\"] = input_df.Histo2D((\"npvs_vs_nTrueInt_({})\".format(wgtVar), \";nTrueInt;npvs\", 150, 0, 150, 150, 0, 150), \"Pileup_nTrueInt\", \"PV_npvs\", wgtVar)\n",
    "                histos2D_dict[\"EventVars\"][\"npvs_vs_nPU\"] = input_df.Histo2D((\"npvs_vs_nPU_({})\".format(wgtVar), \";nPU;npvs\", 150, 0, 150, 150, 0, 150), \"Pileup_nPU\", \"PV_npvs\", wgtVar)\n",
    "            \n",
    "            if debugInfo == True:\n",
    "                #histos1D_dict[\"EventVars\"][\"GJet_HT_Match\"] = input_df.Histo1D((\"GJet_HT_Match_({})\".format(wgtVar), \"\", 2,0,2), \"GJet_HT_matches\", wgtVar)\n",
    "                pass\n",
    "            \n",
    "    if makeMountains == True:\n",
    "        if useDeepCSV == True:\n",
    "            tagger = \"CSV\"\n",
    "        else:\n",
    "            tagger = \"Jet\"\n",
    "        theCats = collections.OrderedDict()\n",
    "        theCats[\"Inclusive\"] = \"nGJet >= 4\"\n",
    "        theCats[\"nJet4\"] = \"nGJet == 4\"\n",
    "        theCats[\"nJet5\"] = \"nGJet == 5\"\n",
    "        theCats[\"blind_nJet6\"] = \"nGJet == 6\"\n",
    "        theCats[\"blind_nJet7\"] = \"nGJet == 7\"\n",
    "        theCats[\"blind_nJet8+\"] = \"nGJet >= 8\"\n",
    "        #theCats[\"nMediumDeepCSV0\"] = \"nGJet_MediumDeepCSV == 0\"\n",
    "        #theCats[\"nMediumDeepCSV1\"] = \"nGJet_MediumDeepCSV == 1\"\n",
    "        theCats[\"nMediumDeep{}0\".format(tagger)] = \"nGJet_MediumDeep{} == 0\".format(tagger)\n",
    "        theCats[\"nMediumDeep{}1\".format(tagger)] = \"nGJet_MediumDeep{} == 1\".format(tagger)\n",
    "        theCats[\"nMediumDeep{}2\".format(tagger)] = \"nGJet_MediumDeep{} == 2\".format(tagger)\n",
    "        \n",
    "        theCats[\"nMediumDeep{}0_nJet4\".format(tagger)] = \"nGJet_MediumDeep{} == 0 && nGJet == 4\".format(tagger)\n",
    "        theCats[\"nMediumDeep{}1_nJet4\".format(tagger)] = \"nGJet_MediumDeep{} == 1 && nGJet == 4\".format(tagger)\n",
    "        theCats[\"nMediumDeep{}2_nJet4\".format(tagger)] = \"nGJet_MediumDeep{} == 2 && nGJet == 4\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}3_nJet4\".format(tagger)] = \"nGJet_MediumDeep{} == 3 && nGJet == 4\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}4+_nJet4\".format(tagger)] = \"nGJet_MediumDeep{} >= 4 && nGJet == 4\".format(tagger)\n",
    "        \n",
    "        theCats[\"nMediumDeep{}0_nJet5\".format(tagger)] = \"nGJet_MediumDeep{} == 0 && nGJet == 5\".format(tagger)\n",
    "        theCats[\"nMediumDeep{}1_nJet5\".format(tagger)] = \"nGJet_MediumDeep{} == 1 && nGJet == 5\".format(tagger)\n",
    "        theCats[\"nMediumDeep{}2_nJet5\".format(tagger)] = \"nGJet_MediumDeep{} == 2 && nGJet == 5\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}3_nJet5\".format(tagger)] = \"nGJet_MediumDeep{} == 3 && nGJet == 5\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}4+_nJet5\".format(tagger)] = \"nGJet_MediumDeep{} >= 4 && nGJet == 5\".format(tagger)\n",
    "        \n",
    "        theCats[\"nMediumDeep{}0_nJet6\".format(tagger)] = \"nGJet_MediumDeep{} == 0 && nGJet == 6\".format(tagger)\n",
    "        theCats[\"nMediumDeep{}1_nJet6\".format(tagger)] = \"nGJet_MediumDeep{} == 1 && nGJet == 6\".format(tagger)\n",
    "        theCats[\"nMediumDeep{}2_nJet6\".format(tagger)] = \"nGJet_MediumDeep{} == 2 && nGJet == 6\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}3_nJet6\".format(tagger)] = \"nGJet_MediumDeep{} == 3 && nGJet == 6\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}4+_nJet6\".format(tagger)] = \"nGJet_MediumDeep{} >= 4 && nGJet == 6\".format(tagger)\n",
    "        \n",
    "        theCats[\"nMediumDeep{}0_nJet7\".format(tagger)] = \"nGJet_MediumDeep{} == 0 && nGJet == 7\".format(tagger)\n",
    "        theCats[\"nMediumDeep{}1_nJet7\".format(tagger)] = \"nGJet_MediumDeep{} == 1 && nGJet == 7\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}2_nJet7\".format(tagger)] = \"nGJet_MediumDeep{} == 2 && nGJet == 7\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}3_nJet7\".format(tagger)] = \"nGJet_MediumDeep{} == 3 && nGJet == 7\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}4+_nJet7\".format(tagger)] = \"nGJet_MediumDeep{} >= 4 && nGJet == 7\".format(tagger)\n",
    "        \n",
    "        theCats[\"nMediumDeep{}0_nJet8+\".format(tagger)] = \"nGJet_MediumDeep{} == 0 && nGJet >= 8\".format(tagger)\n",
    "        theCats[\"nMediumDeep{}1_nJet8+\".format(tagger)] = \"nGJet_MediumDeep{} == 1 && nGJet >= 8\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}2_nJet8+\".format(tagger)] = \"nGJet_MediumDeep{} == 2 && nGJet >= 8\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}3_nJet8+\".format(tagger)] = \"nGJet_MediumDeep{} == 3 && nGJet >= 8\".format(tagger)\n",
    "        theCats[\"blind_nMediumDeep{}4+_nJet8+\".format(tagger)] = \"nGJet_MediumDeep{} >= 4 && nGJet >= 8\".format(tagger)\n",
    "        cat_df = collections.OrderedDict()\n",
    "        for ck, cs in theCats.items():\n",
    "            cat_df[ck] = input_df.Filter(cs, cs)\n",
    "        if histos1D_dict != None:\n",
    "            if \"Mountains\" not in histos1D_dict:\n",
    "                histos1D_dict[\"Mountains\"] = {}\n",
    "            for tc in theCats.keys(): \n",
    "                if tc not in histos1D_dict[\"Mountains\"]: \n",
    "                    histos1D_dict[\"Mountains\"][tc] = {}\n",
    "            for tc, cut in theCats.items():\n",
    "                tcn = tc.replace(\"blind_\", \"\")\n",
    "                for x in xrange(nJetsToHisto):\n",
    "                    histos1D_dict[\"Mountains\"][tc][\"Jet_pt_jet{}\".format(x+1)] = cat_df[tc].Histo1D((\"Jet_pt_jet{}[{}]({})\".format(x+1, tcn, wgtVar), \"\", 100, 0, 500), \"GJet_pt_jet{}\".format(x+1), wgtVar)\n",
    "                    histos1D_dict[\"Mountains\"][tc][\"Jet_eta_jet{}\".format(x+1)] = cat_df[tc].Histo1D((\"Jet_eta_jet{}[{}]({})\".format(x+1, tcn, wgtVar), \"\", 104, -2.6, 2.6), \"GJet_eta_jet{}\".format(x+1), wgtVar)\n",
    "                    histos1D_dict[\"Mountains\"][tc][\"Jet_phi_jet{}\".format(x+1)] = cat_df[tc].Histo1D((\"Jet_phi_jet{}[{}]({})\".format(x+1, tcn, wgtVar), \"\", 64, -pi, pi), \"GJet_phi_jet{}\".format(x+1), wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MET_pt\"] = cat_df[tc].Histo1D((\"MET_pt_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1000), \"METFixEE2017_pt\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MET_phi\"] = cat_df[tc].Histo1D((\"MET_phi_[{}]({})\".format(tcn, wgtVar), \"\", 20,-pi,pi), \"METFixEE2017_phi\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_all\"] = cat_df[tc].Histo1D((\"Muon_pfRelIso03_all_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 0.2), \"GMuon_pfRelIso03_all\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_chg\"] = cat_df[tc].Histo1D((\"Muon_pfRelIso03_chg_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 0.2), \"GMuon_pfRelIso03_chg\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso04_all\"] = cat_df[tc].Histo1D((\"Muon_pfRelIso04_all_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 0.2), \"GMuon_pfRelIso04_all\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_all\"] = cat_df[tc].Histo1D((\"Electron_pfRelIso03_all_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 0.2), \"GElectron_pfRelIso03_all\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_chg\"] = cat_df[tc].Histo1D((\"Electron_pfRelIso03_chg_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 0.2), \"GElectron_pfRelIso03_chg\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"HT\"] = cat_df[tc].Histo1D((\"HT_[{}]({})\".format(tcn, wgtVar), \"\", 30,400,2000), \"GJet_HT\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"H\"] = cat_df[tc].Histo1D((\"H_[{}]({})\".format(tcn, wgtVar), \"\", 30,400,2000), \"GJet_H\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"HT2M\"] = cat_df[tc].Histo1D((\"HT2M_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1000), \"GJet_HT2M\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"H2M\"] = cat_df[tc].Histo1D((\"H2M_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1500), \"GJet_H2M\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"HTb\"] = cat_df[tc].Histo1D((\"HTb_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1000), \"GJet_HTb\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"HTH\"] = cat_df[tc].Histo1D((\"HTH_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1), \"GJet_HTH\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"HTRat\"] = cat_df[tc].Histo1D((\"HTRat_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1), \"GJet_HTRat\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dRbb\"] = cat_df[tc].Histo1D((\"dRbb_[{}]({})\".format(tcn, wgtVar), \"\", 16,0,2*pi), \"GJet_dRbb\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dPhibb\"] = cat_df[tc].Histo1D((\"dPhibb_[{}]({})\".format(tcn, wgtVar), \"\", 16,-pi,pi), \"GJet_dPhibb\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dEtabb\"] = cat_df[tc].Histo1D((\"dEtabb_[{}]({})\".format(tcn, wgtVar), \"\", 10,0,5), \"GJet_dEtabb\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"GLepton_pt_LeadLep\"] = cat_df[tc].Histo1D((\"GLepton_pt_LeadLep_[{}]({})\".format(tcn, wgtVar), \"\", 100,0,500), \"GLepton_pt_LeadLep\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"GLepton_pt_SubleadLep\"] = cat_df[tc].Histo1D((\"GLepton_pt_SubleadLep_[{}]({})\".format(tcn, wgtVar), \"\", 100,0,500), \"GLepton_pt_SubleadLep\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"GMuon_pt\"] = cat_df[tc].Histo1D((\"GMuon_pt_[{}]({})\".format(tcn, wgtVar), \"\", 100,0,500), \"GMuon_pt\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"GLepton_eta_LeadLep\"] = cat_df[tc].Histo1D((\"GLepton_eta_LeadLep_[{}]({})\".format(tcn, wgtVar), \"\", 52,-2.6,2.6), \"GLepton_eta_LeadLep\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"GLepton_eta_SubleadLep\"] = cat_df[tc].Histo1D((\"GLepton_eta_SubleadLep_[{}]({})\".format(tcn, wgtVar), \"\", 52,-2.6,2.6), \"GLepton_eta_SubleadLep\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"GLepton_eta_SubleadLep\"] = cat_df[tc].Histo1D((\"GLepton_eta_SubleadLep_[{}]({})\".format(tcn, wgtVar), \"\", 52,-2.6,2.6), \"GLepton_eta_SubleadLep\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dRll\"] = cat_df[tc].Histo1D((\"dRll_[{}]({})\".format(tcn, wgtVar), \"\", 16,0,2*pi), \"GLepton_dRll\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dPhill\"] = cat_df[tc].Histo1D((\"dPhill_[{}]({})\".format(tcn, wgtVar), \"\", 16,-pi,pi), \"GLepton_dPhill\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dEtall\"] = cat_df[tc].Histo1D((\"dEtall_[{}]({})\".format(tcn, wgtVar), \"\", 10,0,5), \"GLepton_dEtall\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofMETandEl\"] = cat_df[tc].Histo1D((\"MTofMETandEl_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofMETandEl\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofMETandMu\"] = cat_df[tc].Histo1D((\"MTofMETandMu_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofMETandMu\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofElandMu\"] = cat_df[tc].Histo1D((\"MTofElandMu_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofElandMu\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nJet\"] = cat_df[tc].Histo1D((\"nJet_[{}]({})\".format(tcn, wgtVar), \"\", 14, 0, 14), \"nGJet\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nLooseDeepCSV\"] = cat_df[tc].Histo1D((\"nJet_LooseDeepCSV_[{}]({})\".format(tcn, wgtVar), \"\", 6, 0, 6), \"nGJet_LooseDeepCSV\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nMediumDeepCSV\"] = cat_df[tc].Histo1D((\"nJet_MediumDeepCSV_[{}]({})\".format(tcn, wgtVar), \"\", 6, 0, 6), \"nGJet_MediumDeepCSV\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nTightDeepCSV\"] = cat_df[tc].Histo1D((\"nJet_TightDeepCSV_[{}]({})\".format(tcn, wgtVar), \"\", 6, 0, 6), \"nGJet_TightDeepCSV\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nLooseDeepJet\"] = cat_df[tc].Histo1D((\"nJet_LooseDeepJet_[{}]({})\".format(tcn, wgtVar), \"\", 6, 0, 6), \"nGJet_LooseDeepJet\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nMediumDeepJet\"] = cat_df[tc].Histo1D((\"nJet_MediumDeepJet_[{}]({})\".format(tcn, wgtVar), \"\", 6, 0, 6), \"nGJet_MediumDeepJet\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nTightDeepJet\"] = cat_df[tc].Histo1D((\"nJet_TightDeepJet_[{}]({})\".format(tcn, wgtVar), \"\", 6, 0, 6), \"nGJet_TightDeepJet\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nLooseMuon\"] = cat_df[tc].Histo1D((\"nLooseGMuon_[{}]({})\".format(tcn, wgtVar), \"\", 4, 0, 4), \"nLooseGMuon\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nMediumMuon\"] = cat_df[tc].Histo1D((\"nMediumGMuon_[{}]({})\".format(tcn, wgtVar), \"\", 4, 0, 4), \"nMediumGMuon\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nTightMuon\"] = cat_df[tc].Histo1D((\"nTightGMuon_[{}]({})\".format(tcn, wgtVar), \"\", 4, 0, 4), \"nTightGMuon\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nLooseElectron\"] = cat_df[tc].Histo1D((\"nLooseGElectron_[{}]({})\".format(tcn, wgtVar), \"\", 4, 0, 4), \"nLooseGElectron\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nMediumElectron\"] = cat_df[tc].Histo1D((\"nMediumGElectron_[{}]({})\".format(tcn, wgtVar), \"\", 4, 0, 4), \"nMediumGElectron\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nTightElectron\"] = cat_df[tc].Histo1D((\"nTightGElectron_[{}]({})\".format(tcn, wgtVar), \"\", 4, 0, 4), \"nTightGElectron\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nLooseLepton\"] = cat_df[tc].Histo1D((\"nLooseGLepton_[{}]({})\".format(tcn, wgtVar), \"\", 4, 0, 4), \"nLooseGLepton\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nMediumLepton\"] = cat_df[tc].Histo1D((\"nMediumGLepton_[{}]({})\".format(tcn, wgtVar), \"\", 4, 0, 4), \"nMediumGLepton\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nTightLepton\"] = cat_df[tc].Histo1D((\"nTightGLepton_[{}]({})\".format(tcn, wgtVar), \"\", 4, 0, 4), \"nTightGLepton\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofMETandEl\"] = cat_df[tc].Histo1D((\"MTofMETandEl_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofMETandEl\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofMETandMu\"] = cat_df[tc].Histo1D((\"MTofMETandMu_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofMETandMu\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofElandMu\"] = cat_df[tc].Histo1D((\"MTofElandMu_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofElandMu\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Muon_InvMass\"] = cat_df[tc].Histo1D((\"Muon_InvMass_[{}]({})\".format(tcn, wgtVar), \"\", 60, 0, 150), \"GMuon_InvariantMass\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Electron_InvMass\"] = cat_df[tc].Histo1D((\"Electron_InvMass_[{}]({})\".format(tcn, wgtVar), \"\", 60, 0, 150), \"GElectron_InvariantMass\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Muon_InvMass_v_MET\"] = cat_df[tc].Histo2D((\"Muon_InvMass_v_MET_[{}]({})\".format(tcn, wgtVar), \"\", 30, 0, 150, 20, 0, 400), \"GMuon_InvariantMass\", \"METFixEE2017_pt\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Electron_InvMass_v_MET\"] = cat_df[tc].Histo2D((\"Electron_InvMass_v_MET_[{}]({})\".format(tcn, wgtVar), \"\", 30, 0, 150, 20, 0, 400), \"GElectron_InvariantMass\", \"METFixEE2017_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 30, 0., 0.2, 20,30.,1030.), \"GMuon_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 30, 0, 0.2, 20,30,1030), \"GMuon_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso04_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso04_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso04_all;MET\", 30, 0, 0.2, 20,30,1030), \"GMuon_pfRelIso04_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 30, 0, 0.2, 20,30,1030), \"GElectron_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 30, 0, 0.2, 20,30,1030), \"GElectron_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                \n",
    "                if isData == False:\n",
    "                    pass                \n",
    "            \n",
    "        if histos2D_dict != None:\n",
    "            if \"Mountains\" not in histos2D_dict:\n",
    "                histos2D_dict[\"Mountains\"] = {}\n",
    "            for tc in theCats.keys(): \n",
    "                if tc not in histos2D_dict[\"Mountains\"]: \n",
    "                    histos2D_dict[\"Mountains\"][tc] = {}\n",
    "            for tc, cut in theCats.items():\n",
    "                tcn = tc.replace(\"blind_\", \"\")\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 30, 0., 0.2, 20,30.,1030.), \"GMuon_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 30, 0, 0.2, 20,30,1030), \"GMuon_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso04_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso04_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso04_all;MET\", 30, 0, 0.2, 20,30,1030), \"GMuon_pfRelIso04_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 30, 0, 0.2, 20,30,1030), \"GElectron_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 30, 0, 0.2, 20,30,1030), \"GElectron_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                #### Older versions\n",
    "                #histos2D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 100, 0., 0.2, 100,30.,1030.), \"GMuon_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos2D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 100, 0, 0.2, 100,30,1030), \"GMuon_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos2D_dict[\"Mountains\"][tc][\"Muon_pfRelIso04_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso04_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso04_all;MET\", 100, 0, 0.2, 100,30,1030), \"GMuon_pfRelIso04_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos2D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 100, 0, 0.2, 100,30,1030), \"GElectron_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos2D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 100, 0, 0.2, 100,30,1030), \"GElectron_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                if isData == False:\n",
    "                    #histos2D_dict[\"Mountains\"][tc][\"test1\"] = cat_df[tc].Histo2D((\"test1_[{}]({})\".format(tcn, wgtVar), \";nTrueInt;npvsGood\", 150, 0, 150, 150, 0, 150), \"GMuon_pfRelIso03_all\", \"PV_npvsGood\", wgtVar)\n",
    "                    #histos2D_dict[\"Mountains\"][tc][\"test2\"] = cat_df[tc].Histo2D((\"test2_[{}]({})\".format(tcn, wgtVar), \";nTrueInt;npvsGood\", 150, 0, 150, 150, 0, 150), \"GMuon_pfRelIso03_all\", \"METFixEE2017_pt\", wgtVar)\n",
    "                    #histos2D_dict[\"Mountains\"][tc][\"npvsGood_vs_nTrueInttest\"] = cat_df[tc].Histo2D((\"npvsGood_vs_nTrueInttest_[{}]({})\".format(tcn, wgtVar), \";nTrueInt;npvsGood\", 150, 0, 150, 150, 0, 150), \"GElectron_pfRelIso03_all\", \"MET_pt_flat\", wgtVar)\n",
    "                    histos2D_dict[\"Mountains\"][tc][\"npvsGood_vs_nTrueInt\"] = cat_df[tc].Histo2D((\"npvsGood_vs_nTrueInt_[{}]({})\".format(tcn, wgtVar), \";nTrueInt;npvsGood\", 150, 0, 150, 150, 0, 150), \"Pileup_nTrueInt\", \"PV_npvsGood\", wgtVar)\n",
    "                    histos2D_dict[\"Mountains\"][tc][\"npvsGood_vs_nPU\"] = cat_df[tc].Histo2D((\"npvsGood_vs_nPU_[{}]({})\".format(tcn, wgtVar), \";nPU;npvsGood\", 150, 0, 150, 150, 0, 150), \"Pileup_nPU\", \"PV_npvsGood\", wgtVar)\n",
    "                    histos2D_dict[\"Mountains\"][tc][\"npvs_vs_nTrueInt\"] = cat_df[tc].Histo2D((\"npvs_vs_nTrueInt_[{}]({})\".format(tcn, wgtVar), \";nTrueInt;npvs\", 150, 0, 150, 150, 0, 150), \"Pileup_nTrueInt\", \"PV_npvs\", wgtVar)\n",
    "                    histos2D_dict[\"Mountains\"][tc][\"npvs_vs_nPU\"] = cat_df[tc].Histo2D((\"npvs_vs_nPU_[{}]({})\".format(tcn, wgtVar), \";nPU;npvs\", 150, 0, 150, 150, 0, 150), \"Pileup_nPU\", \"PV_npvs\", wgtVar)\n",
    "      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jet bit dictionary, for reference\n",
    "JMLpassbits = {'PV_minNDoF':                            0b00000000000000000001,\n",
    "                 'PV_maxAbsZ':                            0b00000000000000000010,\n",
    "                 'PV_maxRho':                             0b00000000000000000100,\n",
    "                 'MET_globalSuperTightHalo2016Filter':    0b00000000000000001000,\n",
    "                 'MET_goodVertices':                      0b00000000000000010000,\n",
    "                 'MET_HBHENoiseFilter':                   0b00000000000000100000,\n",
    "                 'MET_HBHENoiseIsoFilter':                0b00000000000001000000,\n",
    "                 'MET_EcalDeadCellTriggerPrimitiveFilter':0b00000000000010000000,\n",
    "                 'MET_BadPFMuonFilter':                   0b00000000000100000000,\n",
    "                 'MET_ecalBadCalibFilterV2':              0b00000000001000000000,\n",
    "                 'MET_pt':                                0b00000000010000000000,\n",
    "                 'unused1':                               0b00000000100000000000, #N\n",
    "                 'Lepton_ZWindow':                        0b00000001000000000000, #N\n",
    "                 'Jet_nJet25':                            0b00000010000000000000, #N\n",
    "                 'Jet_nJet20':                            0b00000100000000000000,\n",
    "                 'HT':                                    0b00001000000000000000,\n",
    "                 'Jet_nBJet_2DCSV':                       0b00010000000000000000, #N\n",
    "                 'Jet_nBJet_2DJet':                       0b00100000000000000000, #N\n",
    "                 'unused2':                               0b01000000000000000000, #N\n",
    "                 'unused3':                               0b10000000000000000000, #N\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##################################################\n",
    "### CHOOSE SAMPLE DICT AND CHANNEL TO ANALYZE ####\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    "#Focus on limited set of events at a time\n",
    "#levels_of_interest = set([\"ElMu_selection\"])\n",
    "#levels_of_interest = set([\"MuMu_selection\",])\n",
    "#levels_of_interest = set([\"ElEl_selection\",])\n",
    "#levels_of_interest = set([\"selection\", \"ElMu_selection\", \"ElEl_selection\", \"MuMu_selection\", \"Mu_selection\", \"El_selection\"])\n",
    "#levels_of_interest = set([\"baseline\", \"MuMu_baseline\", \"ElEl_baseline\", \"selection\", \"MuMu_selection\", \"ElMu_selection\"])\n",
    "#levels_of_interest = set([\"baseline\", \"MuMu_selection\", \"ElMu_selection\"])\n",
    "\n",
    "#Choose the sample dictionary to run\n",
    "#theSampleDict = ttbooker #needs modification to make work...\n",
    "#theSampleDict = ttttbooker\n",
    "#theSampleDict = microbooker #tttt, ttbar-DL unfiltered, DY, one single top sample\n",
    "#theSampleDict = minibooker #tttt, all ttbar, both single top, DY\n",
    "#theSampleDict = booker #All\n",
    "#theSampleDict = bookerV2 #All with reprocessing (WIP: Other data streams, ttVJets, Filtered samples!)\n",
    "#theSampleDict = tt_data_V2\n",
    "#theSampleDict = pyrdfbooker\n",
    "\n",
    "\n",
    "#Use skimmed channels flag\n",
    "useSkimmed = True\n",
    "#chooseChannel = \"ElMu\"\n",
    "chooseChannel = \"MuMu\"\n",
    "#chooseChannel = \"ElEl\"\n",
    "#chooseChannel = \"Mu\"\n",
    "#chooseChannel = \"El\"\n",
    "#chooseChannel = \"test\"\n",
    "#source_level = \"LJMLogic\"\n",
    "#source_level = \"LJMLogic/ElMu_selection\"\n",
    "#source_level = \"LJMLogic/MuMu_selection\"\n",
    "#source_level = \"LJMLogic/ElEl_selection\"\n",
    "if chooseChannel == \"ElMu\":\n",
    "    levels_of_interest = set([\"ElMu_selection\",])\n",
    "    theSampleDict = bookerV2_ElMu.copy()\n",
    "    theSampleDict.update(bookerV2_MC)\n",
    "    if useSkimmed == True:\n",
    "        source_level = \"LJMLogic/ElMu_selection\"\n",
    "elif chooseChannel == \"MuMu\":\n",
    "    levels_of_interest = set([\"MuMu_selection\",])\n",
    "    theSampleDict = bookerV2_MuMu.copy()\n",
    "    theSampleDict.update(bookerV2_MC)\n",
    "    if useSkimmed == True:\n",
    "        source_level = \"LJMLogic/MuMu_selection\"\n",
    "elif chooseChannel == \"ElEl\":    \n",
    "    levels_of_interest = set([\"ElEl_selection\",])\n",
    "    theSampleDict = bookerV2_ElEl.copy()\n",
    "    theSampleDict.update(bookerV2_MC)\n",
    "    if useSkimmed == True:\n",
    "        source_level = \"LJMLogic/ElEl_selection\"\n",
    "elif chooseChannel == \"Mu\":    \n",
    "    levels_of_interest = set([\"Mu_selection\",])\n",
    "    theSampleDict = bookerV2_Mu.copy()\n",
    "    theSampleDict.update(bookerV2_MC)\n",
    "    if useSkimmed == True:\n",
    "        print(\"No skimmed samples prepared for this selection level, please advise\")\n",
    "elif chooseChannel == \"El\":    \n",
    "    levels_of_interest = set([\"El_selection\",])\n",
    "    theSampleDict = bookerV2_El.copy()\n",
    "    theSampleDict.update(bookerV2_MC)\n",
    "    if useSkimmed == True:\n",
    "        print(\"No skimmed samples prepared for this selection level, please advise\")\n",
    "elif chooseChannel == \"test\":\n",
    "    levels_of_interest = set([\"ElMu_selection\", \"MuMu_selection\", \"ElEl_selection\"])\n",
    "    theSampleDict = microbookerV2.copy()\n",
    "    if useSkimmed == True:\n",
    "        print(\"No skimmed samples prepared for this selection level, please advise\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Choose the weight variation\n",
    "#theWeight = \"wgt_SUMW\"\n",
    "#theWeight = \"wgt_SUMW_PU\"\n",
    "#theWeight = \"wgt_SUMW_LSF\"\n",
    "#theWeight = \"wgt_SUMW_L1PF\"\n",
    "#theWeight = \"wgt_SUMW_PU_LSF\"\n",
    "theWeight = \"wgt_SUMW_PU_LSF_L1PF\"\n",
    "#theWeight = \"wgt_SUMW_LSF_L1PF\"\n",
    "#theWeight = \"wgt_NUMW_LSF_L1PF\"\n",
    "\n",
    "#Name the channel that's being analyzed for saving files, and the format (.C, .root, .pdf, .eps, .gif, .png, .jpeg, etc)\n",
    "fileChannel = \"ElMu\"\n",
    "#theFormat = \".pdf\"\n",
    "theFormat = \".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating selection and baseline bits\")\n",
    "b = {}\n",
    "b[\"ElMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) > 0\".format(Chan[\"ElMu_baseline\"])\n",
    "b[\"MuMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"], \n",
    "                                                                                                                                Chan[\"MuMu_baseline\"])\n",
    "b[\"ElEl_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"], \n",
    "                                                                                                                                Chan[\"ElEl_baseline\"])\n",
    "b[\"Mu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"], Chan[\"Mu_baseline\"])\n",
    "b[\"El_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + \n",
    "                                                                                                                    Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"], Chan[\"El_baseline\"])\n",
    "b[\"selection\"] = \"ESV_TriggerAndLeptonLogic_selection > 0\"\n",
    "b[\"ElMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) > 0\".format(Chan[\"ElMu_selection\"])\n",
    "b[\"MuMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"], Chan[\"MuMu_selection\"])\n",
    "b[\"ElEl_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"], Chan[\"ElEl_selection\"])\n",
    "b[\"Mu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"], Chan[\"Mu_selection\"])\n",
    "b[\"El_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"]\n",
    "                                                                            + Chan[\"Mu_selection\"], Chan[\"El_selection\"]) \n",
    "#b[\"ESV_JetMETLogic_baseline\"] = \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00001100011111111111) #This enables the MET pt cut (11) and nJet (15) and HT (16) cuts from PostProcessor\n",
    "b[\"ESV_JetMETLogic_baseline\"] = \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00000000001111111111) #Only do the PV and MET filters, nothing else\n",
    "#b[\"ESV_JetMETLogic_selection\"] = \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00001100011111111111) #FIXME, this isn't right!\n",
    "b[\"ESV_JetMETLogic_selection\"] = \"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00001100011111111111)#This enables the MET pt cut (11) and nJet (15) and HT (16) cuts from PostProcessor\n",
    "b[\"ESV_JetMETLogic_selection\"] = \"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00000000001111111111)\n",
    "#b[\"ESV_JetMETLogic_default\"] = \"(ESV_JetMETLogic_baseline & {}) > 0\".format(0b11111111111111111111)\n",
    "#print(b[\"ESV_JetMETLogic_selection\"])\n",
    "\n",
    "stitchDict = {'2016': {'SL': {'nGenJets': None,\n",
    "                                           'nGenLeps': None,\n",
    "                                           'GenHT': None},\n",
    "                                    'DL': {'nGenJets': None,\n",
    "                                           'nGenLeps': None,\n",
    "                                           'GenHT': None}\n",
    "                                },\n",
    "                           '2017': {'SL': {'nGenJets': 9,\n",
    "                                           'nGenLeps': 1,\n",
    "                                           'GenHT': 500},\n",
    "                                    'DL': {'nGenJets': 7,\n",
    "                                           'nGenLeps': 2,\n",
    "                                           'GenHT': 500}\n",
    "                                },\n",
    "                           '2018': {'SL': {'nGenJets': 9,\n",
    "                                           'nGenLeps': 1,\n",
    "                                           'GenHT': 500},\n",
    "                                    'DL': {'nGenJets': 7,\n",
    "                                           'nGenLeps': 2,\n",
    "                                           'GenHT': 500}\n",
    "                                }\n",
    "                       }\n",
    "\n",
    "\n",
    "filtered = {}\n",
    "base = {}\n",
    "reports = {}\n",
    "#theValidSet = set([\"tt_SL\", \"tt_SL-GF\", \"tt_DL-GF\"])\n",
    "for name, vals in theSampleDict.items():\n",
    "    #print(\"Skipping all samples except {}\".format(theValidSet))\n",
    "    #if name not in theValidSet: continue\n",
    "    print(\"Initializing RDataFrame - {}\".format(name))\n",
    "    filtered[name] = {}\n",
    "    base[name] = RDF(\"Events\", vals[\"source\"][source_level])\n",
    "    reports[name] = base[name].Report()\n",
    "    for lvl in levels_of_interest:\n",
    "        if \"baseline\" in lvl:\n",
    "            JMLOG = \"ESV_JetMETLogic_baseline\"\n",
    "        elif \"selection\" in lvl:\n",
    "            JMLOG = \"ESV_JetMETLogic_selection\"\n",
    "        else:\n",
    "            JMLOG = \"ESV_JetMETLogic_default\"\n",
    "            \n",
    "        if lvl == \"baseline\":\n",
    "            filtered[name][lvl] = base[name]#.Filter(b[JMLOG], JMLOG)#.Cache()\n",
    "        else:\n",
    "            filtered[name][lvl] = base[name].Filter(b[lvl], lvl)#.Filter(b[JMLOG], JMLOG)#.Cache()\n",
    "        #Cache() seemingly has an issue with the depth/breadth of full NanoAOD file. Perhaps one with fewer branches would work\n",
    "        #filtered[name][lvl] = filtered[name][lvl].Cache()\n",
    "        if vals.get(\"stitch\") != None:\n",
    "            stitch_def = collections.OrderedDict()\n",
    "            stitch_def[\"stitch_jet_mask\"] = \"GenJet_pt > 30\"\n",
    "            stitch_def[\"stitch_HT_mask\"] = \"GenJet_pt > 30 && abs(GenJet_eta) < 2.4\"\n",
    "            stitch_def[\"stitch_lep_mask\"] = \"abs(LHEPart_pdgId) == 15 || abs(LHEPart_pdgId) == 13 || abs(LHEPart_pdgId) == 11\"\n",
    "            stitch_def[\"stitch_nGenLep\"] = \"LHEPart_pdgId[stitch_lep_mask].size()\"\n",
    "            stitch_def[\"stitch_nGenJet\"] = \"GenJet_pt[stitch_jet_mask].size()\"\n",
    "            stitch_def[\"stitch_GenHT\"] = \"Sum(GenJet_pt[stitch_HT_mask])\"\n",
    "            \n",
    "            stdict = stitchDict[vals.get(\"era\")][vals.get(\"stitch\").get(\"channel\")]\n",
    "            stitch_cut = \"stitch_nGenLep == {} && stitch_nGenJet >= {} && stitch_GenHT >= {}\"\\\n",
    "                .format(stdict.get(\"nGenLeps\"), stdict.get(\"nGenJets\"), stdict.get(\"GenHT\"))\n",
    "            if vals.get(\"stitch\").get(\"source\") == \"Nominal\":\n",
    "                stitch_cut = \"!({})\".format(stitch_cut)\n",
    "            elif vals.get(\"stitch\").get(\"source\") == \"Filtered\":\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Invalid stitching source type\")\n",
    "                sys.exit(1)\n",
    "            print(stitch_cut)\n",
    "            for k, v in stitch_def.items():\n",
    "                filtered[name][lvl] = filtered[name][lvl].Define(\"{}\".format(k), \"{}\".format(v))\n",
    "            filtered[name][lvl] = filtered[name][lvl].Filter(stitch_cut, \"nJet_GenHT_Filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = {}\n",
    "counts = {}\n",
    "histos1D = {}\n",
    "histos1D_PU = {}\n",
    "histos2D = {}\n",
    "histosNS = {} #unstacked histograms\n",
    "the_df = {}\n",
    "print(\"Starting loop for booking\")\n",
    "for name, vals in theSampleDict.items():\n",
    "    #if name not in theValidSet: continue\n",
    "    #if name not in [\"tttt\", \"ElMu_F\"]: continue\n",
    "    print(\"Booking - {}\".format(name))\n",
    "    counts[name] = {}\n",
    "    histos1D[name] = {}\n",
    "    histos1D_PU[name] = {}\n",
    "    histos2D[name] = {}\n",
    "    histosNS[name] = {}\n",
    "    the_df[name] = {}\n",
    "    #counts[name][\"baseline\"] = filtered[name].Count() #Unnecessary with baseline in levels of interest?\n",
    "    for lvl in levels_of_interest:\n",
    "        the_df[name][lvl] = defineLeptons(filtered[name][lvl], \n",
    "                                            input_lvl_filter=lvl,\n",
    "                                            isData=vals[\"isData\"], \n",
    "                                            useBackupChannel=False)\n",
    "        #Use the cutPV and METFilters function to do cutflow on these requirements...\n",
    "        the_df[name][lvl] = cutPVandMETFilters(the_df[name][lvl], lvl, isData=vals[\"isData\"])\n",
    "        if vals[\"isData\"] == False:\n",
    "            the_df[name][lvl] = defineWeights(the_df[name][lvl],\n",
    "                                            crossSection=vals[\"crossSection\"], \n",
    "                                            sumWeights=vals[\"sumWeights\"], \n",
    "                                            lumi=lumi[era],\n",
    "                                            nEvents=vals[\"nEvents\"], \n",
    "                                            nEventsPositive=vals[\"nEventsPositive\"], \n",
    "                                            nEventsNegative=vals[\"nEventsNegative\"], \n",
    "                                            isData=vals[\"isData\"], \n",
    "                                            verbose=False,)\n",
    "        else:\n",
    "            the_df[name][lvl] = defineWeights(the_df[name][lvl],\n",
    "                                             isData=True,\n",
    "                                             verbose=False)\n",
    "        the_df[name][lvl] = defineJets(the_df[name][lvl],\n",
    "                                       era=\"2017\",\n",
    "                                       useDeepCSV=True\n",
    "                                      )\n",
    "        the_df[name][lvl] = the_df[name][lvl].Define(\"RVec_MET_pt\", \"ROOT::VecOps::RVec<float> encaps; encaps.push_back(METFixEE2017_pt); return encaps;\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet > 2\", \"nJet > 2\")\n",
    "        the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet > 3\", \"nJet > 3\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet_MediumDeepCSV > 1\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet_MediumDeepJet > 1\", \"nMedDeepJet > 1\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"METFixEE2017_pt > 40\", \"MET > 40\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"METFixEE2017_pt > 0\", \"MET > 50\")\n",
    "        the_df[name][lvl] = the_df[name][lvl].Filter(\"METFixEE2017_pt > 0\", \"MET > 0\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"GJet_HT > 450\", \"HT > 450\")\n",
    "        the_df[name][lvl] = the_df[name][lvl].Filter(\"GJet_HT > 500\", \"HT > 500\")\n",
    "        counts[name][lvl] = the_df[name][lvl].Count()\n",
    "        histos1D[name][lvl] = {}\n",
    "        histos1D_PU[name][lvl] = {}\n",
    "        histosNS[name][lvl] = {}\n",
    "        histos2D[name][lvl] = {}\n",
    "#        fillHistos(the_df[name][lvl], wgtVar=theWeight, isData = vals[\"isData\"],\n",
    "#                   histos1D_dict=histos1D[name][lvl], histos2D_dict=histos2D[name][lvl], \n",
    "#                   histosNS_dict=histosNS[name][lvl],\n",
    "#                   doMuons=False, doElectrons=False, doLeptons=False, \n",
    "#                   doJets=False, doWeights=False, doEventVars=False,\n",
    "#                   makeMountains=True, useDeepCSV=True)\n",
    "        fillHistos(the_df[name][lvl], wgtVar=theWeight, isData = vals[\"isData\"],\n",
    "                   histos1D_dict=histos1D[name][lvl], histos2D_dict=histos2D[name][lvl], \n",
    "                   histosNS_dict=histosNS[name][lvl],\n",
    "                   doMuons=True, doElectrons=True, doLeptons=True, \n",
    "                   doJets=True, doWeights=False, doEventVars=True,\n",
    "                   makeMountains=True, useDeepCSV=True)\n",
    "#        fillHistos(the_df[name][lvl], wgtVar=\"wgt_SUMW_PU_LSF\", histos1D_dict=histos1D[name][lvl], \n",
    "#                   histos2D_dict=histos2D[name][lvl], histosNS_dict=histosNS[name][lvl],\n",
    "#                   doMuons=False, doElectrons=False, doLeptons=True, \n",
    "#                   doJets=False, doWeights=True, doEventVars=False)\n",
    "#        fillHistos(the_df[name][lvl], wgtVar=\"wgt_SUMW_PU\", histos1D_dict=histos1D[name][lvl], \n",
    "#                   histos2D_dict=histos2D[name][lvl], histosNS_dict=histosNS[name][lvl],\n",
    "#                   doMuons=False, doElectrons=False, doLeptons=False, \n",
    "#                   doJets=False, doWeights=False, doEventVars=True)\n",
    "#        fillHistos(the_df[name][lvl], wgtVar=\"wgt_SUMW_PU\", histos1D_dict=histos1D_PU[name][lvl], \n",
    "#                   histos2D_dict=histos2D[name][lvl], histosNS_dict=histosNS[name][lvl],\n",
    "#                   doMuons=True, doElectrons=True, doLeptons=True, \n",
    "#                   doJets=True, doWeights=True, doEventVars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Warning: if filtered[name][lvl] RDFs are not reset, then calling Define(*) on them will cause the error\"\\\n",
    "      \" with 'program state reset' due to multiple definitions for the same variable\")\n",
    "loopcounter = 0\n",
    "start = time.clock()\n",
    "substart = {}\n",
    "subfinish = {}\n",
    "for name, cnt in counts.items():\n",
    "    #if name in [\"MuMu\", \"ElMu\", \"ElEl\"]: continue\n",
    "    substart[name] = time.clock()\n",
    "    loopcounter += 1\n",
    "    print(\"==========={}/{}\\n{}\".format(loopcounter, len(counts), name))\n",
    "    if \"baseline\" in cnt:\n",
    "        print(\"Baseline = \" + str(cnt[\"baseline\"].GetValue()))\n",
    "    else:\n",
    "        print(\"Baseline\")\n",
    "    if \"ElMu_baseline\" in cnt:\n",
    "        print(\"\\tElMu = {}\".format(cnt[\"ElMu_baseline\"].GetValue()),end='')\n",
    "    if \"MuMu_baseline\" in cnt:\n",
    "        print(\"\\tMuMu = {}\".format(cnt[\"MuMu_baseline\"].GetValue()),end='')\n",
    "    if \"ElEl_baseline\" in cnt:\n",
    "        print(\"\\tElEl = {}\".format(cnt[\"ElEl_baseline\"].GetValue()),end='')\n",
    "    if \"Mu_baseline\" in cnt:\n",
    "        print(\"\\tMu = {}\".format(cnt[\"Mu_baseline\"].GetValue()),end='')\n",
    "    if \"El_baseline\" in cnt:\n",
    "        print(\"\\tEl = {}\".format(cnt[\"El_baseline\"].GetValue()),end='')\n",
    "    print(\"\")\n",
    "    if \"ElMu_baseline\" in cnt and \"ElEl_baseline\" in cnt and \"MuMu_baseline\" in cnt\\\n",
    "            and \"Mu_baseline\" in cnt and \"El_baseline\" in cnt:\n",
    "        print(\"\\nTotal = {}\".format(cnt[\"ElMu_baseline\"].GetValue() + cnt[\"MuMu_baseline\"].GetValue() + cnt[\"ElEl_baseline\"].GetValue() + cnt[\"Mu_baseline\"].GetValue() + cnt[\"El_baseline\"].GetValue()))\n",
    "    if \"selection\" in cnt:\n",
    "        print(\"Selection = \" + str(cnt[\"selection\"].GetValue()))\n",
    "    else: \n",
    "        print(\"Selection\")\n",
    "    if \"ElMu_selection\" in cnt:\n",
    "        print(\"\\tElMu = {}\".format(cnt[\"ElMu_selection\"].GetValue()),end='')\n",
    "    if \"MuMu_selection\" in cnt:\n",
    "        print(\"\\tMuMu = {}\".format(cnt[\"MuMu_selection\"].GetValue()),end='')\n",
    "    if \"ElEl_selection\" in cnt:\n",
    "        print(\"\\tElEl = {}\".format(cnt[\"ElEl_selection\"].GetValue()),end='')\n",
    "    if \"Mu_selection\" in cnt:\n",
    "        print(\"\\tMu = {}\".format(cnt[\"Mu_selection\"].GetValue()),end='')\n",
    "    if \"El_selection\" in cnt:\n",
    "        print(\"\\tEl = {}\".format(cnt[\"El_selection\"].GetValue()),end='')\n",
    "    print(\"\")  \n",
    "    if \"ElMu_selection\" in cnt and \"ElEl_selection\" in cnt and \"MuMu_selection\" in cnt\\\n",
    "            and \"Mu_selection\" in cnt and \"El_selection\" in cnt:\n",
    "        print(\"\\nTotal = {}\".format(cnt[\"ElMu_selection\"].GetValue() + cnt[\"MuMu_selection\"].GetValue() + cnt[\"ElEl_selection\"].GetValue() + cnt[\"Mu_selection\"].GetValue() + cnt[\"El_selection\"].GetValue()))\n",
    "    subfinish[name] = time.clock()\n",
    "    print(\"====> Took {}s to process sample {}\".format(subfinish[name] - substart[name], name))\n",
    "finish = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Took {}s to process\".format(finish - start))\n",
    "for name, val in substart.items():\n",
    "    print(\"Took {}s to process sample {}\".format(subfinish[name] - substart[name], name))\n",
    "print()\n",
    "masterfinish = time.time() #clock gives cpu time, not accurate multi-core?\n",
    "print(\"Took {}m {}s to process in real-time\".format((masterfinish - masterstart)//60, (masterfinish - masterstart)%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeHistosForCombine(hist_dict, directory, levels_of_iterest, dict_key=\"Mountains\", mode=\"RECREATE\"):\n",
    "    rootDict = {}\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "    for name, levels_dict in hist_dict.items():\n",
    "        for level, obj_dict in levels_dict.items():\n",
    "            if level not in levels_of_interest: continue\n",
    "            if not os.path.isdir(directory + \"/\" + level):\n",
    "                os.makedirs(directory + \"/\" + level)\n",
    "            for pre_obj_name, obj_val in obj_dict[dict_key].items():\n",
    "                for hname, hist in obj_val.items():\n",
    "                    dictKey = pre_obj_name + \"_\" + hname\n",
    "                    if dictKey not in rootDict:\n",
    "                        rootDict[dictKey] = ROOT.TFile.Open(\"{}.root\"\\\n",
    "                                     .format(directory + \"/\" + level + \"/\"+ dictKey), mode)\n",
    "                    rootDict[dictKey].cd()\n",
    "                    hptr = hist.GetPtr()\n",
    "                    oldname = hptr.GetName()\n",
    "                    hptr.SetName(\"{}\".format(name))\n",
    "                    hptr.Write()\n",
    "                    hptr.SetName(\"{}\".format(oldname)) #Avoid overwriting things by switching back, save from segfault\n",
    "    for f in rootDict.values():\n",
    "        f.Close()\n",
    "        \n",
    "def writeHistos(hist_dict, directory, levels_of_iterest, samples_of_interest, dict_key=\"Mountains\", mode=\"RECREATE\"):\n",
    "    rootDict = {}\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "    for name, levels_dict in hist_dict.items():\n",
    "        if name not in samples_of_interest: continue\n",
    "        for level, obj_dict in levels_dict.items():\n",
    "            if level not in levels_of_interest: continue\n",
    "            if not os.path.isdir(directory + \"/\" + level):\n",
    "                os.makedirs(directory + \"/\" + level)\n",
    "            rootDict[name] = ROOT.TFile.Open(\"{}.root\"\\\n",
    "                                         .format(directory + \"/\" + level + \"/\"+ name), mode)\n",
    "            for pre_obj_name, obj_val in obj_dict[dict_key].items():\n",
    "                for hname, hist in obj_val.items():\n",
    "                    #help(hist)\n",
    "                    dictKey = pre_obj_name + \"_\" + hname\n",
    "                    if dictKey not in rootDict:\n",
    "                        \n",
    "                    rootDict[dictKey].cd()\n",
    "                    hptr = hist.GetPtr()\n",
    "                    oldname = hptr.GetName()\n",
    "                    hptr.SetName(\"{}\".format(pre_obj_name + \"$\" + hname))\n",
    "                    hptr.Write()\n",
    "                    hptr.SetName(\"{}\".format(oldname)) #Avoid overwriting things by switching back, save from segfault\n",
    "    for f in rootDict.values():\n",
    "        f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDict = {}\n",
    "histDir = \"select_20200229\"\n",
    "if not os.path.isdir(histDir):\n",
    "    os.makedirs(histDir)\n",
    "for name, levels_dict in histos1D.items():\n",
    "    #if \"DY\" not in name and \"t\" not in name: continue\n",
    "    #if theSampleDict[name][\"isData\"] == True: continue\n",
    "    print(name, end='')\n",
    "    #print(theSampleDict[name].keys())\n",
    "    print(\" - c=\" + str(theSampleDict[name][\"color\"]))\n",
    "    for level, obj_dict in levels_dict.items():\n",
    "        if level not in levels_of_interest: continue\n",
    "        if not os.path.isdir(histDir + \"/\" + level):\n",
    "            os.makedirs(histDir + \"/\" + level)\n",
    "        print(\"\\t\" + level)\n",
    "        print(obj_dict.keys())\n",
    "        for pre_obj_name, obj_val in obj_dict[\"Mountains\"].items():\n",
    "            obj_name = \"Mountains_\" + pre_obj_name\n",
    "            print(\"\\t\\t\" + obj_name)\n",
    "            for hname, hist in obj_val.items():\n",
    "                #print(\"\\t\\t\\t\" + hname)\n",
    "                #help(hist)\n",
    "                dictKey = pre_obj_name + \"_\" + hname\n",
    "                if dictKey not in rootDict:\n",
    "                    rootDict[dictKey] = ROOT.TFile.Open(\"{}.root\"\\\n",
    "                                 .format(histDir + \"/\" + level + \"/\"+ dictKey), \"RECREATE\")\n",
    "                rootDict[dictKey].cd()\n",
    "                hptr = hist.GetPtr()\n",
    "                oldname = hptr.GetName()\n",
    "                hptr.SetName(\"{}\".format(name))\n",
    "                hptr.Write()\n",
    "                hptr.SetName(\"{}\".format(oldname)) #Avoid overwriting things by switching back, save from segfault\n",
    "for f in rootDict.values():\n",
    "    f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, report in reports.items():\n",
    "    if \"El\" in name or \"Mu\" in name: continue\n",
    "    print(\"{}\".format(name))\n",
    "    report.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fff = ROOT.TCanvas(\"fff\", \"\", 800, 600)\n",
    "fff.cd()\n",
    "histos1D[\"tt_DL-GF\"][\"MuMu_selection\"][\"Mountains\"]['nMediumDeepJet2']['Muon_InvMass'].Draw(\"COLZ TEXT\")\n",
    "fff.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacks = {}\n",
    "stacksource = {} #Create sortable lists to fill stacks from\n",
    "stacksource_data = {} #create separte list to append all the data to, so that they can be conbined into one hist file and added to the stacksoure at the end\n",
    "model_dict = [histos1D[k] for k in theSampleDict.keys() if theSampleDict[k][\"isData\"] == False]\n",
    "model_dict = model_dict[0]\n",
    "if len(model_dict) < 1:\n",
    "    raise RuntimeError(\"Failure, no histogram dictionary found to form stacks from\")\n",
    "for level, obj_dict in model_dict.items():\n",
    "    if level not in levels_of_interest: continue\n",
    "    stacks[level] = {}\n",
    "    stacksource[level] = {}\n",
    "    stacksource_data[level] = {}\n",
    "    for obj_name, obj_val in obj_dict.items():\n",
    "        if obj_name == \"Mountains\": continue #extra depth to account for, custom implementation until next version developed\n",
    "        stacks[level][obj_name] = {}\n",
    "        stacksource[level][obj_name] = {}\n",
    "        stacksource_data[level][obj_name] = {}\n",
    "        for hname, hist in obj_val.items():\n",
    "            stacks[level][obj_name][hname] = []\n",
    "            stacks[level][obj_name][hname].append(ROOT.THStack(\"s_{}_{}_{}\".format(level, obj_name, hname), \"{}_{}_{}\".format(level, obj_name, hname)))\n",
    "            stacksource[level][obj_name][hname] = []\n",
    "            stacksource_data[level][obj_name][hname] = []\n",
    "    for pre_obj_name, obj_val in obj_dict[\"Mountains\"].items():\n",
    "        obj_name = \"Mountains_\" + pre_obj_name\n",
    "        stacks[level][obj_name] = {}\n",
    "        stacksource[level][obj_name] = {}\n",
    "        stacksource_data[level][obj_name] = {}\n",
    "        for hname, hist in obj_val.items():\n",
    "            stacks[level][obj_name][hname] = []\n",
    "            stacks[level][obj_name][hname].append(ROOT.THStack(\"s_{}_{}_{}\".format(level, obj_name, hname), \"{}_{}_{}\".format(level, obj_name, hname)))\n",
    "            stacksource[level][obj_name][hname] = []\n",
    "            stacksource_data[level][obj_name][hname] = []\n",
    "for name, levels_dict in histos1D.items():\n",
    "    #if \"DY\" not in name and \"t\" not in name: continue\n",
    "    #if theSampleDict[name][\"isData\"] == True: continue\n",
    "    print(name, end='')\n",
    "    #print(theSampleDict[name].keys())\n",
    "    print(\" - c=\" + str(theSampleDict[name][\"color\"]))\n",
    "    for level, obj_dict in levels_dict.items():\n",
    "        if level not in levels_of_interest: continue\n",
    "        print(\"\\t\" + level)\n",
    "        for pre_obj_name, obj_val in obj_dict[\"Mountains\"].items():\n",
    "            obj_name = \"Mountains_\" + pre_obj_name\n",
    "            print(\"\\t\\t\" + obj_name)\n",
    "            for hname, hist in obj_val.items():\n",
    "                print(\"\\t\\t\\t\" + hname)\n",
    "                #help(hist)\n",
    "                hptr = hist.GetPtr().Clone()\n",
    "                hptr.SetFillColor(theSampleDict[name][\"color\"])\n",
    "                hptr.SetLineColor(theSampleDict[name][\"color\"])\n",
    "                #stacks[level][obj_name][hname].Add(hptr)\n",
    "                #stacksource[level][obj_name][hname].append((hptr, hptr.GetIntegral()))\n",
    "                #Integral fails sometimes, use sum of weights...\n",
    "                if theSampleDict[name][\"isData\"] == False:\n",
    "                    stacksource[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "                else:\n",
    "                    stacksource_data[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "        for obj_name, obj_val in obj_dict.items():\n",
    "            if obj_name == \"Mountains\": continue #extra depth to account for, custom implementation until next version developed\n",
    "            print(\"\\t\\t\" + obj_name)\n",
    "            for hname, hist in obj_val.items():\n",
    "                print(\"\\t\\t\\t\" + hname)\n",
    "                #help(hist)\n",
    "                hptr = hist.GetPtr().Clone()\n",
    "                hptr.SetFillColor(theSampleDict[name][\"color\"])\n",
    "                hptr.SetLineColor(theSampleDict[name][\"color\"])\n",
    "                #stacks[level][obj_name][hname].Add(hptr)\n",
    "                #stacksource[level][obj_name][hname].append((hptr, hptr.GetIntegral()))\n",
    "                #Integral fails sometimes, use sum of weights...\n",
    "                if theSampleDict[name][\"isData\"] == False:\n",
    "                    stacksource[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "                else:\n",
    "                    stacksource_data[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "print()\n",
    "#Now cycle through and sort each list, once it contains all hists from every source (outermost loop - name - above)\n",
    "print(stacksource_data)\n",
    "for level, obj_dict in model_dict.items():\n",
    "    if level not in levels_of_interest: continue\n",
    "    for pre_obj_name, obj_val in obj_dict[\"Mountains\"].items():\n",
    "        obj_name = \"Mountains_\" + pre_obj_name\n",
    "        for hname, hist in obj_val.items():\n",
    "            #Sort the MC-only histograms\n",
    "            stacksource[level][obj_name][hname].sort(key=lambda b: b[1], reverse=False)\n",
    "            \n",
    "            #Create a MC-only histogram for statistics purposes\n",
    "            tmpMC = None\n",
    "            for himc, h_mc in enumerate(stacksource[level][obj_name][hname]):\n",
    "                if himc == 0:\n",
    "                    #take first histo\n",
    "                    tmpMC = h_mc[0].Clone()\n",
    "                    tmpMC.SetTitle(\"MC\")\n",
    "                else:\n",
    "                    #hadd the other histos\n",
    "                    #tmpMC = tmpMC + h_mc[0].Clone()\n",
    "                    tmpMC.Add(h_mc[0].Clone())\n",
    "            if tmpMC != None:\n",
    "                #tmpMC.SetMarkerStyle(0)\n",
    "                tmpMC.SetLineColor(ROOT.kRed)  #FIXME Color from largest sample?\n",
    "                tmpMC.SetFillColorAlpha(ROOT.kRed, 0) #FIXME\n",
    "            stacks[level][obj_name][hname].append(tmpMC)\n",
    "            \n",
    "            tmp = None\n",
    "            for hid, h_data in enumerate(stacksource_data[level][obj_name][hname]):\n",
    "                if hid == 0:\n",
    "                    #take first histo\n",
    "                    tmp = h_data[0].Clone()\n",
    "                    tmp.SetTitle(\"Data\")\n",
    "                else:\n",
    "                    #hadd the other histos\n",
    "                    #tmp = tmp + h_data[0].Clone()\n",
    "                    tmp.Add(h_data[0].Clone())\n",
    "            if tmp != None:\n",
    "                tmp.SetMarkerStyle(0) #20 round dot, with SetMarkerSize(1.0) in an example\n",
    "                tmp.SetLineColor(ROOT.kBlack)\n",
    "                tmp.SetFillColorAlpha(ROOT.kWhite, 0)\n",
    "            stacks[level][obj_name][hname].append(tmp)\n",
    "                \n",
    "            for hptrTup in stacksource[level][obj_name][hname]:\n",
    "                #add to the THStack in the first position of the tuple\n",
    "                stacks[level][obj_name][hname][0].Add(hptrTup[0])\n",
    "    for obj_name, obj_val in obj_dict.items():\n",
    "        if obj_name == \"Mountains\": continue #extra depth to account for, custom implementation until next version developed\n",
    "        for hname, hist in obj_val.items():\n",
    "            #Sort the MC-only histograms\n",
    "            stacksource[level][obj_name][hname].sort(key=lambda b: b[1], reverse=False)\n",
    "            \n",
    "            #Create a MC-only histogram for statistics purposes\n",
    "            tmpMC = None\n",
    "            for himc, h_mc in enumerate(stacksource[level][obj_name][hname]):\n",
    "                if himc == 0:\n",
    "                    #take first histo\n",
    "                    tmpMC = h_mc[0].Clone()\n",
    "                    tmpMC.SetTitle(\"MC\")\n",
    "                else:\n",
    "                    #hadd the other histos\n",
    "                    #tmpMC = tmpMC + h_mc[0].Clone()\n",
    "                    tmpMC.Add(h_mc[0].Clone())\n",
    "            if tmpMC != None:\n",
    "                #tmpMC.SetMarkerStyle(0)\n",
    "                tmpMC.SetLineColor(ROOT.kRed) #FIXME Color set to highest integral's\n",
    "                tmpMC.SetLineWidth(0)\n",
    "                tmpMC.SetFillColorAlpha(ROOT.kRed, 0)\n",
    "            stacks[level][obj_name][hname].append(tmpMC)\n",
    "            \n",
    "            tmp = None\n",
    "            for hid, h_data in enumerate(stacksource_data[level][obj_name][hname]):\n",
    "                if hid == 0:\n",
    "                    #take first histo\n",
    "                    tmp = h_data[0].Clone()\n",
    "                    tmp.SetTitle(\"Data\")\n",
    "                else:\n",
    "                    #hadd the other histos\n",
    "                    #tmp = tmp + h_data[0].Clone()\n",
    "                    tmp.Add(h_data[0].Clone())\n",
    "            if tmp != None:\n",
    "                tmp.SetMarkerStyle(0) #20 round dot, with SetMarkerSize(1.0) in an example\n",
    "                tmp.SetLineColor(ROOT.kBlack)\n",
    "                #tmp.SetFillColorAlpha(ROOT.kWhite, 0)\n",
    "            stacks[level][obj_name][hname].append(tmp)\n",
    "                \n",
    "            for hptrTup in stacksource[level][obj_name][hname]:\n",
    "                #add to the THStack in the first position of the tuple\n",
    "                stacks[level][obj_name][hname][0].Add(hptrTup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2 = ROOT.TCanvas()\n",
    "#c2.cd()\n",
    "#histos2D[\"tttt\"][\"ElMu_selection\"][\"Mountains\"][\"nMediumDeepCSV0\"][\"npvsGood_vs_nTrueInt\"].Draw(\"COLZ\")\n",
    "#c2.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leg = ROOT.TLegend(0.75,0.80, 0.95, 0.90)\n",
    "#leg = ROOT.TLegend(0.15,0.10)\n",
    "#leg.SetFillColor(0)\n",
    "#leg.SetBorderSize(0)\n",
    "leg.SetNColumns(2)\n",
    "leg.SetTextSize(0.03)\n",
    "leg_colors = set([smpl[\"color\"] for smpl in theSampleDict.values()])\n",
    "leg_tuple = [(smpl[0], smpl[1]) for smpl in leg_dict.items() if smpl[1] in leg_colors]\n",
    "leg_hists = {}\n",
    "for samplecategory, color in leg_tuple:\n",
    "    leg_hists[color] = ROOT.TH1D(samplecategory, samplecategory, 0, 0, 1)\n",
    "    if samplecategory != \"Data\":\n",
    "        leg_hists[color].SetFillColor(color)\n",
    "        leg.AddEntry(leg_hists[color], samplecategory, \"F\")\n",
    "    else:\n",
    "        leg.AddEntry(leg_hists[color], samplecategory, \"P\")\n",
    "%jsroot on \n",
    "#help(ROOT.TLegend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%jsroot off\n",
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if obj_name != \"Jets\": continue\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        c.Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        #The `mode` has up to nine digits that can be set to on (1 or 2), off (0).\n",
    " \n",
    "         #mode = ksiourmen  (default = 000001111)\n",
    "         #k = 1;  kurtosis printed\n",
    "         #k = 2;  kurtosis and kurtosis error printed\n",
    "         #s = 1;  skewness printed\n",
    "         #s = 2;  skewness and skewness error printed\n",
    "         #i = 1;  integral of bins printed\n",
    "         #i = 2;  integral of bins with option \"width\" printed\n",
    "         #o = 1;  number of overflows printed\n",
    "         #u = 1;  number of underflows printed\n",
    "         #r = 1;  standard deviation printed\n",
    "         #r = 2;  standard deviation and standard deviation error printed\n",
    "         #m = 1;  mean value printed\n",
    "         #m = 2;  mean and mean error values printed\n",
    "         #e = 1;  number of entries printed\n",
    "         #n = 1;  name of histogram is printed\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[1].Draw(\"SAMES\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        c.SetLogy()\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        c.SetLogy(0)\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if obj_name != \"Muons\": continue\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        c.Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[1].Draw(\"SAMES\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        c.SetLogy()\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        c.SetLogy(0)\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if obj_name != \"Electrons\": continue\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        c.Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[1].Draw(\"SAMES\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        c.SetLogy()\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        c.SetLogy(0)\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if obj_name != \"Leptons\": continue\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        c.Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[1].Draw(\"SAMES\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        c.SetLogy()\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        c.SetLogy(0)\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if obj_name != \"EventVars\": continue\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        c.Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[1].Draw(\"SAMES\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        c.SetLogy()\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        c.SetLogy(0)\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%jsroot on\n",
    "unblind_whitelist = set([])\n",
    "CanvasCache = {}\n",
    "CanvasCache[\"Open/Close\"] = ROOT.TCanvas(\"open_close\", \"\", 800, 100)\n",
    "\n",
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if \"Mountains\" not in obj_name: continue\n",
    "    print(obj_name)\n",
    "    CanvasCache[obj_name] = {}\n",
    "    #Save to a pdf using the '.pdf(' string to make a file that stays open for subsequent writes to the same filename. To be closed by '.pdf)' \n",
    "    CanvasCache[\"Open/Close\"].SaveAs(\"./{channel}/{object_name}_All.pdf(\".format(channel=fileChannel.replace(\"_selection\", \"\"), object_name=obj_name.replace(\"Mountains_\", \"\")))\n",
    "    for sname, stack in sorted(obj_dict.items()):\n",
    "        c = None\n",
    "        if \"_vs_\" in sname: #hack to draw 2D histos in the 1D histo dict\n",
    "            CanvasCache[obj_name][sname] = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 1800)\n",
    "            CanvasCache[obj_name][sname].Divide(1,3)\n",
    "            CanvasCache[obj_name][sname].cd(1)\n",
    "        else:\n",
    "        #if True:\n",
    "            CanvasCache[obj_name][sname] = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "            CanvasCache[obj_name][sname].cd()\n",
    "        CanvasCache[obj_name][sname].SetLogy()\n",
    "        CanvasCache[obj_name][sname].Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        if \"_vs_\" in sname: #hack to draw 2D histos in the 1D histo dict\n",
    "            stack[0].Draw(\"\")\n",
    "        else:\n",
    "            stack[0].Draw(\"HIST S\")\n",
    "        #Draw the MC summed histogram for stats (better way with THStack? why the fuck don't people document this in a useful way?)\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            if \"_vs_\" in sname: #hack to draw 2D histos in the 1D histo dict\n",
    "                stack[1].Draw(\"SAMES\") #Also SAME0, SAMES0 which 'do not use the z axis of the previous plot'\n",
    "                CanvasCache[obj_name][sname].cd(2)\n",
    "                tmp1 = stack[1].Clone()\n",
    "                tmp1.SetLineColor(ROOT.kBlue)\n",
    "                tmp1.SetFillColorAlpha(ROOT.kGreen, 0.7)\n",
    "                tmp1.Draw(\"VIOLINX\")\n",
    "                #stack[1].ProfileX().Draw(\"E3\")\n",
    "                CanvasCache[obj_name][sname].cd(3)\n",
    "                tmp1.Draw(\"VIOLINY\")\n",
    "                #stack[1].ProfileY().Draw(\"E3\")\n",
    "                CanvasCache[obj_name][sname].cd(1)\n",
    "            else:\n",
    "                stack[1].Draw(\"SAMES HIST\")\n",
    "        #Draw the data histogram, assuming that it's unblinded (\"blind\" not in the name and or in the whitelist )\n",
    "        if len(stack) > 2 and stack[2] != None and (\"blind\" not in obj_name or obj_name in unblind_whitelist):\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            if \"_vs_\" in sname: #hack to draw 2D histos in the 1D histo dict\n",
    "                stack[2].Draw(\"SAMES\") #Maybe add ARR for arrow mode? or something else\n",
    "                CanvasCache[obj_name][sname].cd(2)\n",
    "                tmp2 = stack[2].Clone()\n",
    "                tmp2.SetLineColor(ROOT.kRed)\n",
    "                tmp2.SetFillColorAlpha(ROOT.kGray, 0.4)\n",
    "                tmp2.Draw(\"SAMES CANDLEX\")\n",
    "                #stack[2].ProfileX().Draw(\"PE1 SAMES\")\n",
    "                CanvasCache[obj_name][sname].cd(3)\n",
    "                tmp2.Draw(\"SAMES CANDLEY\")\n",
    "                #stack[2].ProfileY().Draw(\"PE1 SAMES\")\n",
    "                CanvasCache[obj_name][sname].cd(1)\n",
    "            else:\n",
    "                stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Internal}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        CanvasCache[obj_name][sname].Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None and (\"blind\" not in obj_name or obj_name in unblind_whitelist):\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        CanvasCache[obj_name][sname].SetLogy()\n",
    "        CanvasCache[obj_name][sname].SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        CanvasCache[obj_name][sname].SaveAs(\"./{channel}/{object_name}_All.pdf\".format(channel=fileChannel.replace(\"_selection\", \"\"), object_name=obj_name.replace(\"Mountains_\", \"\"), wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        CanvasCache[obj_name][sname].SetLogy(0)\n",
    "        CanvasCache[obj_name][sname].SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        CanvasCache[obj_name][sname].SaveAs(\"./{channel}/{object_name}_All.pdf\".format(channel=fileChannel.replace(\"_selection\", \"\"), object_name=obj_name.replace(\"Mountains_\", \"\"), wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "    #Close the pdf using '.pdf)' \n",
    "    CanvasCache[\"Open/Close\"].SaveAs(\"./{channel}/{object_name}_All.pdf)\".format(channel=fileChannel.replace(\"_selection\", \"\"), object_name=obj_name.replace(\"Mountains_\", \"\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterfinish2 = time.time() #clock gives cpu time, not accurate multi-core?\n",
    "print(\"Took {}m {}s to process in real-time including plots\".format((masterfinish2 - masterstart)//60, (masterfinish - masterstart)%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From example: https://root.cern.ch/doc/master/df103__NanoAODHiggsAnalysis_8py_source.html\n",
    "\n",
    "#def plot(sig, bkg, data, x_label, filename):\n",
    "#     \"\"\"\n",
    "#     Plot invariant mass for signal and background processes from simulated\n",
    "#     events overlay the measured data.\n",
    "#     \"\"\"\n",
    "#     # Canvas and general style options\n",
    "#     ROOT.gStyle.SetOptStat(0)\n",
    "#     ROOT.gStyle.SetTextFont(42)\n",
    "#     d = ROOT.TCanvas(\"d\", \"\", 800, 700)\n",
    "#     d.SetLeftMargin(0.15)\n",
    "# \n",
    "#     # Get signal and background histograms and stack them to show Higgs signal\n",
    "#     # on top of the background process\n",
    "#     h_bkg = bkg\n",
    "#     h_cmb = sig.Clone()\n",
    "# \n",
    "#     h_cmb.Add(h_bkg)\n",
    "#     h_cmb.SetTitle(\"\")\n",
    "#     h_cmb.GetXaxis().SetTitle(x_label)\n",
    "#     h_cmb.GetXaxis().SetTitleSize(0.04)\n",
    "#     h_cmb.GetYaxis().SetTitle(\"N_{Events}\")\n",
    "#     h_cmb.GetYaxis().SetTitleSize(0.04)\n",
    "#     h_cmb.SetLineColor(ROOT.kRed)\n",
    "#     h_cmb.SetLineWidth(2)\n",
    "#     h_cmb.SetMaximum(18)\n",
    "#     h_bkg.SetLineWidth(2)\n",
    "#     h_bkg.SetFillStyle(1001)\n",
    "#     h_bkg.SetLineColor(ROOT.kBlack)\n",
    "#     h_bkg.SetFillColor(ROOT.kAzure - 9)\n",
    "# \n",
    "#     # Get histogram of data points\n",
    "#     h_data = data\n",
    "#     h_data.SetLineWidth(1)\n",
    "#     h_data.SetMarkerStyle(20)\n",
    "#     h_data.SetMarkerSize(1.0)\n",
    "#     h_data.SetMarkerColor(ROOT.kBlack)\n",
    "#     h_data.SetLineColor(ROOT.kBlack)\n",
    "# \n",
    "#     # Draw histograms\n",
    "#     h_cmb.DrawCopy(\"HIST\")\n",
    "#     h_bkg.DrawCopy(\"HIST SAME\")\n",
    "#     h_data.DrawCopy(\"PE1 SAME\")\n",
    "# \n",
    "#     # Add legend\n",
    "#     legend = ROOT.TLegend(0.62, 0.70, 0.82, 0.88)\n",
    "#     legend.SetFillColor(0)\n",
    "#     legend.SetBorderSize(0)\n",
    "#     legend.SetTextSize(0.03)\n",
    "#     legend.AddEntry(h_data, \"Data\", \"PE1\")\n",
    "#     legend.AddEntry(h_bkg, \"ZZ\", \"f\")\n",
    "#     legend.AddEntry(h_cmb, \"m_{H} = 125 GeV\", \"f\")\n",
    "#     legend.Draw()\n",
    "# \n",
    "#     # Add header\n",
    "#     cms_label = ROOT.TLatex()\n",
    "#     cms_label.SetTextSize(0.04)\n",
    "#     cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Open Data}\")\n",
    "#     header = ROOT.TLatex()\n",
    "#     header.SetTextSize(0.03)\n",
    "#     header.DrawLatexNDC(0.63, 0.92, \"#sqrt{s} = 8 TeV, L_{int} = 11.6 fb^{-1}\")\n",
    "# \n",
    "#     # Save plot\n",
    "#     d.SaveAs(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gg1 = ROOT.ROOT.RDF.SaveGraph(the_df['tttt']['ElMu_selection'], './mydot.dot')\n",
    "#!dot -Tsvg mydot.dot -o mydot.svg\n",
    "#listOfImageNames = ['./mydot.svg',\n",
    "#                    ]\n",
    "#\n",
    "#for imageName in listOfImageNames:\n",
    "#    display(SVG(filename=imageName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = ROOT.TCanvas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacks[\"ElMu_selection\"][\"Mountains_nMediumDeepJet0\"][\"Muon_pfRelIso03_chg_vs_MET\"]\n",
    "#stacksource_data[\"ElMu_selection\"][\"Mountains_nMediumDeepJet0\"][\"Muon_pfRelIso03_chg_vs_MET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
