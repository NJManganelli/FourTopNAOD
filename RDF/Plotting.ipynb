{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz --user\n",
    "#!echo $PYTHONPATH\n",
    "#!ls -ltr /eos/user/n/nmangane/.local/lib/python2.7/site-packages/\n",
    "#!export PATH=/eos/user/n/nmangane/.local/lib/python2.7/site-packages/:$PATH\n",
    "#!ls -ltr | grep .root\n",
    "#!which root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os, time\n",
    "import ROOT\n",
    "import collections\n",
    "import pprint\n",
    "import math\n",
    "import array\n",
    "#from ruamel.yaml import YAML\n",
    "from IPython.display import Image, display, SVG\n",
    "#import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPlotJSON_nJet = {\n",
    "    \"Plot_nJet4_$VAR\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": \"nJet4_$VAR.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_nJet5_$VAR\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": \"nJet5_$VAR.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_blind_nJet6_$VAR\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": \"blind_nJet6_$VAR.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_blind_nJet7_$VAR\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": \"blind_nJet7_$VAR.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_blind_nJet8+_$VAR\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": \"blind_nJet8+_$VAR.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Canvas_nJet_$VAR\":{\n",
    "        \"Type\": \"CanvasConfig\",\n",
    "        \"Title\": \"$VAR\",\n",
    "        \"Margins\": [0.1, 0.1, 0.1, 0.1],\n",
    "        \"Coordinates\": [],\n",
    "        \"Plots\": [\"Plot_nJet4_$VAR\", \"Plot_nJet5_$VAR\", \"Plot_blind_nJet6_$VAR\", \"Plot_blind_nJet7_$VAR\", \"Plot_blind_nJet8+_$VAR\"],\n",
    "        \"Labels\": [\"$CHANNEL\\n nJet=4\", \"$CHANNEL\\n nJet=5\", \"$CHANNEL\\n nJet=6\", \"$CHANNEL\\n nJet=7\", \"$CHANNEL\\n nJet>=8\" ],\n",
    "        \"Legend\": \"DefaultLegend\",\n",
    "        \"XPixels\": 1200, \n",
    "        \"YPixels\": 1000,\n",
    "        \"XAxisTitle\": \"$VAR\",\n",
    "        \"YAxisTitle\": \"Events/bin\",\n",
    "        \"DoRatio\": True,\n",
    "        \"doLogY\": False,\n",
    "        \"DoMountainrange\": True,\n",
    "    },\n",
    "    \"Canvas_LogY_nJet_$VAR\":{\n",
    "        \"Type\": \"CanvasConfig\",\n",
    "        \"Title\": \"$VAR\",\n",
    "        \"Margins\": [0.1, 0.1, 0.1, 0.1],\n",
    "        \"Coordinates\": [],\n",
    "        \"Plots\": [\"Plot_nJet4_$VAR\", \"Plot_nJet5_$VAR\", \"Plot_blind_nJet6_$VAR\", \"Plot_blind_nJet7_$VAR\", \"Plot_blind_nJet8+_$VAR\"],\n",
    "        \"Labels\": [\"$CHANNEL nJet == 4\", \"$CHANNEL nJet == 5\", \"$CHANNEL nJet == 6\", \"$CHANNEL nJet == 7\", \"$CHANNEL nJet >= 8\" ],\n",
    "        \"Legend\": \"DefaultLegend\",\n",
    "        \"XPixels\": 1200, \n",
    "        \"YPixels\": 1000,\n",
    "        \"XAxisTitle\": \"$VAR\",\n",
    "        \"YAxisTitle\": \"Events/bin\",\n",
    "        \"DoRatio\": True,\n",
    "        \"doLogY\": True,\n",
    "        \"DoMountainrange\": True,\n",
    "    },\n",
    "}\n",
    "modelPlotJSON_nMediumDeepCSV2_nJet = {\n",
    "    \"Plot_nMediumDeepCSV2_nJet4_$VAR\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": \"nMediumDeepCSV2_nJet4_$VAR.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_nMediumDeepCSV2_nJet5_$VAR\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": \"nMediumDeepCSV2_nJet5_$VAR.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_blind_nMediumDeepCSV2_nJet6_$VAR\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": \"nMediumDeepCSV2_nJet6_$VAR.root\",\n",
    "        \"Unblind\": True,\n",
    "    },\n",
    "    \"Plot_blind_nMediumDeepCSV2_nJet7_$VAR\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": \"blind_nMediumDeepCSV2_nJet7_$VAR.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_blind_nMediumDeepCSV2_nJet8+_$VAR\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": \"blind_nMediumDeepCSV2_nJet8+_$VAR.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Canvas_nJet_$VAR\":{\n",
    "        \"Type\": \"CanvasConfig\",\n",
    "        \"Title\": \"$VAR\",\n",
    "        \"Margins\": [0.1, 0.1, 0.1, 0.1],\n",
    "        \"Coordinates\": [],\n",
    "        \"Plots\": [\"Plot_nMediumDeepCSV2_nJet4_$VAR\", \"Plot_nMediumDeepCSV2_nJet5_$VAR\", \"Plot_blind_nMediumDeepCSV2_nJet6_$VAR\", \"Plot_blind_nMediumDeepCSV2_nJet7_$VAR\", \"Plot_blind_nMediumDeepCSV2_nJet8+_$VAR\"],\n",
    "        \"Labels\": [\"$CHANNEL\\n nJet=4 nBTag=2\", \"$CHANNEL\\n nJet=5 nBTag=2\", \"$CHANNEL\\n nJet=6 nBTag=2\", \"$CHANNEL\\n nJet=7 nBTag=2\", \"$CHANNEL\\n nJet>=8 nBTag=2\" ],\n",
    "        \"Legend\": \"DefaultLegend\",\n",
    "        \"XPixels\": 1200, \n",
    "        \"YPixels\": 1000,\n",
    "        \"XAxisTitle\": \"$VAR\",\n",
    "        \"YAxisTitle\": \"Events/bin\",\n",
    "        \"DoRatio\": True,\n",
    "        \"doLogY\": False,\n",
    "        \"DoMountainrange\": True,\n",
    "    },\n",
    "    \"Canvas_LogY_nJet_$VAR\":{\n",
    "        \"Type\": \"CanvasConfig\",\n",
    "        \"Title\": \"$VAR\",\n",
    "        \"Margins\": [0.1, 0.1, 0.1, 0.1],\n",
    "        \"Coordinates\": [],\n",
    "        \"Plots\": [\"Plot_nMediumDeepCSV2_nJet4_$VAR\", \"Plot_nMediumDeepCSV2_nJet5_$VAR\", \"Plot_blind_nMediumDeepCSV2_nJet6_$VAR\", \"Plot_blind_nMediumDeepCSV2_nJet7_$VAR\", \"Plot_blind_nMediumDeepCSV2_nJet8+_$VAR\"],\n",
    "        \"Labels\": [\"$CHANNEL\\n nJet=4 nBTag=2\", \"$CHANNEL\\n nJet=5 nBTag=2\", \"$CHANNEL\\n nJet=6 nBTag=2\", \"$CHANNEL\\n nJet=7 nBTag=2\", \"$CHANNEL\\n nJet>=8 nBTag=2\" ],\n",
    "        \"Legend\": \"DefaultLegend\",\n",
    "        \"XPixels\": 1200, \n",
    "        \"YPixels\": 1000,\n",
    "        \"XAxisTitle\": \"$VAR\",\n",
    "        \"YAxisTitle\": \"Events/bin\",\n",
    "        \"DoRatio\": True,\n",
    "        \"doLogY\": True,\n",
    "        \"DoMountainrange\": True,\n",
    "    },\n",
    "}\n",
    "modelPlotJSON_nJet_noLogY = {}\n",
    "for k, v in modelPlotJSON_nJet.items():\n",
    "    if \"_LogY_\" in k: continue\n",
    "    modelPlotJSON_nJet_noLogY[k] = v\n",
    "def plotJSONFromVars(model, variables, channel=\"No Channel\"):\n",
    "    if channel == \"ElMu\":\n",
    "        nice_channel = \"#it{e}#mu\"\n",
    "    elif channel == \"MuMu\":\n",
    "        nice_channel = \"#mu#mu\"\n",
    "    elif channel == \"ElEl\":\n",
    "        nice_channel = \"#it{e}#it{e}\"\n",
    "    else:\n",
    "        nice_channel = channel\n",
    "    theDict = {}\n",
    "    for variable in variables:\n",
    "        for k, v in model.items():\n",
    "            newKey = k.replace(\"$VAR\", variable)\n",
    "            theDict[newKey] = {}\n",
    "            for vk, vv in v.items():\n",
    "                #newSubkey = vk.replace(\"$VAR\", variable)\n",
    "                if type(vv) == str:\n",
    "                    newSubvalue = vv.replace(\"$VAR\", variable).replace(\"$CHANNEL\", nice_channel)\n",
    "                elif type(vv) == list:\n",
    "                    newSubvalue = []\n",
    "                    for l in vv:\n",
    "                        if type(l) == str:\n",
    "                            newSubvalue.append(l.replace(\"$VAR\", variable).replace(\"$CHANNEL\", nice_channel))\n",
    "                        else:\n",
    "                            newSubvalue.append(l)\n",
    "                else:\n",
    "                    newSubvalue = vv\n",
    "                theDict[newKey][vk] = newSubvalue\n",
    "    return theDict\n",
    "pprint.pprint(plotJSONFromVars(modelPlotJSON_nJet, [\"HT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1180, 1185, 1179, 1181, 1183, 1182, 1184\n",
    "defaultAndLegends = {\n",
    "    \"DefaultPlot\":{\n",
    "        \"Type\": \"DefaultPlot\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": None,\n",
    "        \"Unblind\": False,\n",
    "        \"RatioYMin\": 0.5,\n",
    "        \"RatioYMax\": 1.5,\n",
    "    },\n",
    "    \"DefaultLegend\":{\n",
    "        \"Type\": \"DefaultLegend\",\n",
    "        \"Coordinates\": [0.0, 0.1, 0.3, 0.65],\n",
    "        \"nColumns\": 1,\n",
    "        \"OLDY-Coordinates\": [0.35, 0.75, 0.95, 0.90],\n",
    "        \"OLDY-nColumns\": 3,\n",
    "        \"Categories\": {\n",
    "            \"tttt\": {\"Color\": ROOT.kAzure+4,\n",
    "                     \"Names\": [\"tttt\"],\n",
    "                     \"Style\": \"Fill\",\n",
    "                    },\n",
    "            \"ttbar\": {\"Color\": ROOT.kRed,\n",
    "                      \"Names\": [\"tt_DL\", \"tt_SL\", \"tt_DL-GF\", \"tt_SL-GF\"],\n",
    "                      \"Style\": \"Fill\",\n",
    "                     },\n",
    "            \"singletop\": {\"Color\": ROOT.kYellow,\n",
    "                          \"Names\": [\"ST_tW\", \"ST_tbarW\"],\n",
    "                          \"Style\": \"Fill\",\n",
    "                         },\n",
    "            \"ttH\":  {\"Color\": ROOT.kMagenta,\n",
    "                     \"Names\": [\"ttH\"],\n",
    "                     \"Style\": \"Fill\",\n",
    "                    },\n",
    "            \"ttVJets\": {\"Color\": ROOT.kViolet,\n",
    "                        \"Names\": [\"ttWJets\", \"ttZJets\"],\n",
    "                        \"Style\": \"Fill\",\n",
    "                       },\n",
    "            \"ttultrarare\": {\"Color\": ROOT.kCyan,\n",
    "                            \"Names\": [\"ttWW\", \"ttWH\", \"ttWZ\", \"ttZZ\", \"ttZH\", \"ttHH\", \"tttJ\"],\n",
    "                            \"Style\": \"Fill\",\n",
    "                           },\n",
    "            \"DY\": {\"Color\": ROOT.kGreen,\n",
    "                   \"Names\": [\"DYJets_DL\"],\n",
    "                   \"Style\": \"Fill\",\n",
    "                  },\n",
    "            \"Data\": {\"Color\": ROOT.kBlack,\n",
    "                     \"Names\": [\"MuMu_A\", \"MuMu_B\", \"MuMu_C\", \"MuMu_D\", \"MuMu_E\", \"MuMu_F\", \"MuMu_G\", \"MuMu_H\",\n",
    "                               \"ElMu_A\", \"ElMu_B\", \"ElMu_C\", \"ElMu_D\", \"ElMu_E\", \"ElMu_F\", \"ElMu_G\", \"ElMu_H\",\n",
    "                               \"ElEl_A\", \"ElEl_B\", \"ElEl_C\", \"ElEl_D\", \"ElEl_E\", \"ElEl_F\", \"ElEl_G\", \"ElEl_H\",\n",
    "                               \"El_A\", \"El_B\", \"El_C\", \"El_D\", \"El_E\", \"El_F\", \"El_G\", \"El_H\",\n",
    "                               \"Mu_A\", \"Mu_B\", \"Mu_C\", \"Mu_D\", \"Mu_E\", \"Mu_F\", \"Mu_G\", \"Mu_H\",\n",
    "                               \"ElMu\", \"MuMu\", \"ElEl\", \"El\", \"Mu\",],\n",
    "                     \"Style\": \"Marker\",\n",
    "                    },\n",
    "            \"QCD\": {\"Color\": ROOT.kPink,\n",
    "                    \"Names\": [\"QCD_HT200\", \"QCD_HT300\", \"QCD_HT500\", \"QCD_HT700\", \n",
    "                              \"QCD_HT1000\", \"QCD_HT1500\", \"QCD_HT2000\"],\n",
    "                    \"Style\": \"Fill\",\n",
    "                   },\n",
    "        },\n",
    "        \"Supercategories\": {\n",
    "            \"Signal+Background\": {\"Names\": [\"tttt\", \"ttbar\", \"singletop\", \"ttH\", \"ttVJets\", \"ttultrarare\", \"DY\", \"QCD\"],\n",
    "                                  \"Stack\": True,\n",
    "                                  \"Draw\": \"HIST\",\n",
    "                                 },\n",
    "            \"Data\": {\"Names\": [\"Data\"],\n",
    "                     \"Stack\": False,\n",
    "                     \"Draw\": \"PE1\",\n",
    "                    },\n",
    "        },\n",
    "        \"Ratios\": {\"Data/MC\": {\"Numerator\": \"Data\",\n",
    "                               \"Denominator\": \"Signal+Background\",\n",
    "                               \"Color\": ROOT.kBlack,\n",
    "                               \"Style\": \"Marker\"\n",
    "                              }\n",
    "                  },\n",
    "    },\n",
    "    \"SinglePlotLegend\":{\n",
    "        \"Type\": \"DefaultLegend\",\n",
    "        \"Coordinates\": [0.75, 0.80, 0.95, 0.90],\n",
    "        \"nColumns\": 3,\n",
    "        \"Categories\": {\n",
    "            \"tttt\": {\"Color\": ROOT.kAzure-2,\n",
    "                     \"Names\": [\"tttt\"],\n",
    "                     \"Style\": \"Fill\",\n",
    "                    },\n",
    "            \"ttbar\": {\"Color\": ROOT.kRed,\n",
    "                      \"Names\": [\"tt_DL\", \"tt_SL\", \"tt_DL-GF\", \"tt_SL-GF\"],\n",
    "                      \"Style\": \"Fill\",\n",
    "                     },\n",
    "            \"singletop\": {\"Color\": ROOT.kYellow,\n",
    "                          \"Names\": [\"ST_tW\", \"ST_tbarW\"],\n",
    "                          \"Style\": \"Fill\",\n",
    "                         },\n",
    "            \"ttH\":  {\"Color\": ROOT.kMagenta,\n",
    "                     \"Names\": [\"ttH\"],\n",
    "                     \"Style\": \"Fill\",\n",
    "                    },\n",
    "            \"ttVJets\": {\"Color\": ROOT.kViolet,\n",
    "                        \"Names\": [\"ttWJets\", \"ttZJets\"],\n",
    "                        \"Style\": \"Fill\",\n",
    "                       },\n",
    "            \"ttultrarare\": {\"Color\": ROOT.kGreen,\n",
    "                            \"Names\": [\"ttWW\", \"ttWH\", \"ttWZ\", \"ttZZ\", \"ttZH\", \"ttHH\", \"tttJ\"],\n",
    "                            \"Style\": \"Fill\",\n",
    "                           },\n",
    "            \"DY\": {\"Color\": ROOT.kCyan,\n",
    "                   \"Names\": [\"DYJets_DL\"],\n",
    "                   \"Style\": \"Fill\",\n",
    "                  },\n",
    "            \"Data\": {\"Color\": ROOT.kBlack,\n",
    "                     \"Names\": [\"MuMu_A\", \"MuMu_B\", \"MuMu_C\", \"MuMu_D\", \"MuMu_E\", \"MuMu_F\", \"MuMu_G\", \"MuMu_H\",\n",
    "                               \"ElMu_A\", \"ElMu_B\", \"ElMu_C\", \"ElMu_D\", \"ElMu_E\", \"ElMu_F\", \"ElMu_G\", \"ElMu_H\",\n",
    "                               \"ElEl_A\", \"ElEl_B\", \"ElEl_C\", \"ElEl_D\", \"ElEl_E\", \"ElEl_F\", \"ElEl_G\", \"ElEl_H\",\n",
    "                               \"El_A\", \"El_B\", \"El_C\", \"El_D\", \"El_E\", \"El_F\",\n",
    "                               \"Mu_A\", \"Mu_B\", \"Mu_C\", \"Mu_D\", \"Mu_E\", \"Mu_F\",\n",
    "                               \"ElMu\", \"ElEl\", \"El\", \"Mu\",],\n",
    "                     \"Style\": \"Marker\",\n",
    "                    },\n",
    "            \"QCD\": {\"Color\": ROOT.kPink,\n",
    "                    \"Names\": [\"QCD_HT200\", \"QCD_HT300\", \"QCD_HT500\", \"QCD_HT700\", \n",
    "                              \"QCD_HT1000\", \"QCD_HT1500\", \"QCD_HT2000\"],\n",
    "                    \"Style\": \"Fill\",\n",
    "                   },\n",
    "        },\n",
    "        \"Supercategories\": {\n",
    "            \"Signal+Background\": {\"Names\": [\"tttt\", \"ttbar\", \"singletop\", \"ttH\", \"ttVJets\", \"ttultrarare\", \"DY\", \"QCD\"],\n",
    "                                  \"Stack\": True,\n",
    "                                  \"Draw\": \"HIST\",\n",
    "                                 },\n",
    "            \"Data\": {\"Names\": [\"Data\"],\n",
    "                     \"Stack\": False,\n",
    "                     \"Draw\": \"PE1\",\n",
    "                    },\n",
    "        },\n",
    "        \"Ratios\": {\"Data/MC\": {\"Numerator\": \"Data\",\n",
    "                               \"Denominator\": \"Signal+Background\",\n",
    "                               \"Color\": ROOT.kBlack,\n",
    "                               \"Style\": \"Marker\"\n",
    "                              }\n",
    "                  },\n",
    "    },\n",
    "    \"DefaultCanvas\":{\n",
    "        \"Type\": \"DefaultCanvas\",\n",
    "        \"Title\": \"DefaultCanvasTitle\",\n",
    "        \"Margins\": [0.1, 0.1, 0.1, 0.1],\n",
    "        \"Plots\": None,\n",
    "        \"XPixels\": 800, \n",
    "        \"YPixels\": 800,\n",
    "        \"DoRatio\": False,\n",
    "        \"DoMountainrange\": False,\n",
    "    },\n",
    "}\n",
    "defaultForStitchComparison = {\n",
    "    \"DefaultPlot\":{\n",
    "        \"Type\": \"DefaultPlot\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": None,\n",
    "        \"Unblind\": False,\n",
    "        \"RatioYMin\": 0.5,\n",
    "        \"RatioYMax\": 1.5,\n",
    "    },\n",
    "    \"DefaultLegend\":{\n",
    "        \"Type\": \"DefaultLegend\",\n",
    "        \"Coordinates\": [0.35, 0.75, 0.95, 0.90],\n",
    "        \"nColumns\": 3,\n",
    "        \"Categories\": {\n",
    "            \"tttt\": {\"Color\": ROOT.kAzure-2,\n",
    "                     \"Names\": [\"tttt\"],\n",
    "                     \"Style\": \"Fill\",\n",
    "                    },\n",
    "            \"ttbar\": {\"Color\": ROOT.kRed,\n",
    "                      \"Names\": [\"tt_DL\", \"tt_SL\", \"tt_DL-GF\", \"tt_SL-GF\"],\n",
    "                      \"Style\": \"Fill\",\n",
    "                     },\n",
    "            \"ttbar-UNSTITCHED\": {\"Color\": ROOT.kRed,\n",
    "                      \"Names\": [\"tt_DL-UNSTITCHED\", \"tt_SL-UNSTITCHED\",],\n",
    "                      \"Style\": \"Fill\",\n",
    "                     },\n",
    "            \"singletop\": {\"Color\": ROOT.kYellow,\n",
    "                          \"Names\": [\"ST_tW\", \"ST_tbarW\"],\n",
    "                          \"Style\": \"Fill\",\n",
    "                         },\n",
    "            \"ttH\":  {\"Color\": ROOT.kMagenta,\n",
    "                     \"Names\": [\"ttH\"],\n",
    "                     \"Style\": \"Fill\",\n",
    "                    },\n",
    "            \"ttVJets\": {\"Color\": ROOT.kViolet,\n",
    "                        \"Names\": [\"ttWJets\", \"ttZJets\"],\n",
    "                        \"Style\": \"Fill\",\n",
    "                       },\n",
    "            \"ttultrarare\": {\"Color\": ROOT.kGreen,\n",
    "                            \"Names\": [\"ttWW\", \"ttWH\", \"ttWZ\", \"ttZZ\", \"ttZH\", \"ttHH\", \"tttJ\"],\n",
    "                            \"Style\": \"Fill\",\n",
    "                           },\n",
    "            \"DY\": {\"Color\": ROOT.kCyan,\n",
    "                   \"Names\": [\"DYJets_DL\"],\n",
    "                   \"Style\": \"Fill\",\n",
    "                  },\n",
    "            \"Data\": {\"Color\": ROOT.kBlack,\n",
    "                     \"Names\": [\"MuMu_A\", \"MuMu_B\", \"MuMu_C\", \"MuMu_D\", \"MuMu_E\", \"MuMu_F\", \"MuMu_G\", \"MuMu_H\",\n",
    "                               \"ElMu_A\", \"ElMu_B\", \"ElMu_C\", \"ElMu_D\", \"ElMu_E\", \"ElMu_F\", \"ElMu_G\", \"ElMu_H\",\n",
    "                               \"ElEl_A\", \"ElEl_B\", \"ElEl_C\", \"ElEl_D\", \"ElEl_E\", \"ElEl_F\", \"ElEl_G\", \"ElEl_H\",\n",
    "                               \"El_A\", \"El_B\", \"El_C\", \"El_D\", \"El_E\", \"El_F\",\n",
    "                               \"Mu_A\", \"Mu_B\", \"Mu_C\", \"Mu_D\", \"Mu_E\", \"Mu_F\",\n",
    "                               \"ElMu\", \"ElEl\", \"El\", \"Mu\",],\n",
    "                     \"Style\": \"Marker\",\n",
    "                    },\n",
    "            \"QCD\": {\"Color\": ROOT.kPink,\n",
    "                    \"Names\": [\"QCD_HT200\", \"QCD_HT300\", \"QCD_HT500\", \"QCD_HT700\", \n",
    "                              \"QCD_HT1000\", \"QCD_HT1500\", \"QCD_HT2000\"],\n",
    "                    \"Style\": \"Fill\",\n",
    "                   },\n",
    "        },\n",
    "        \"Supercategories\": {\n",
    "            \"Signal+Background\": {\"Names\": [\"tttt\", \"ttbar\", \"singletop\", \"ttH\", \"ttVJets\", \"ttultrarare\", \"DY\", \"QCD\"],\n",
    "                                  \"Stack\": True,\n",
    "                                  \"Draw\": \"HIST\",\n",
    "                                 },\n",
    "            \"UNSTITCHED\": {\"Names\": [\"tttt\", \"ttbar-UNSTITCHED\", \"singletop\", \"ttH\", \"ttVJets\", \"ttultrarare\", \"DY\", \"QCD\"],\n",
    "                                  \"Stack\": False,\n",
    "                                  \"Draw\": \"PE1\",\n",
    "                                 },\n",
    "        },\n",
    "        \"Ratios\": {\"Unstitched/Stitched\": {\"Numerator\": \"UNSTITCHED\",\n",
    "                               \"Denominator\": \"Signal+Background\",\n",
    "                               \"Color\": ROOT.kBlack,\n",
    "                               \"Style\": \"Marker\"\n",
    "                              }\n",
    "                  },\n",
    "    },\n",
    "    \"DefaultCanvas\":{\n",
    "        \"Type\": \"DefaultCanvas\",\n",
    "        \"Title\": \"DefaultCanvasTitle\",\n",
    "        \"Margins\": [0.1, 0.1, 0.1, 0.1],\n",
    "        \"Plots\": None,\n",
    "        \"XPixels\": 800, \n",
    "        \"YPixels\": 800,\n",
    "        \"DoRatio\": False,\n",
    "        \"DoMountainrange\": False,\n",
    "    },\n",
    "}\n",
    "defaultForStitchComparisonOnlyTT = {\n",
    "    \"DefaultPlot\":{\n",
    "        \"Type\": \"DefaultPlot\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Rebin\": None,\n",
    "        \"Files\": None,\n",
    "        \"Unblind\": False,\n",
    "        \"RatioYMin\": 0.5,\n",
    "        \"RatioYMax\": 1.5,\n",
    "    },\n",
    "    \"DefaultLegend\":{\n",
    "        \"Type\": \"DefaultLegend\",\n",
    "        \"Coordinates\": [0.35, 0.75, 0.95, 0.90],\n",
    "        \"nColumns\": 3,\n",
    "        \"Categories\": {\n",
    "            \"ttbar\": {\"Color\": ROOT.kRed,\n",
    "                      \"Names\": [\"tt_DL\", \"tt_SL\", \"tt_DL-GF\", \"tt_SL-GF\"],\n",
    "                      \"Style\": \"Fill\",\n",
    "                     },\n",
    "            \"ttbar-UNSTITCHED\": {\"Color\": ROOT.kBlack,\n",
    "                      \"Names\": [\"tt_DL-UNSTITCHED\", \"tt_SL-UNSTITCHED\",],\n",
    "                      \"Style\": \"Marker\",\n",
    "                     },\n",
    "        },\n",
    "        \"Supercategories\": {\n",
    "            \"STITCHED\": {\"Names\": [\"ttbar\",],\n",
    "                                  \"Stack\": True,\n",
    "                                  \"Draw\": \"HIST\",\n",
    "                                 },\n",
    "            \"UNSTITCHED\": {\"Names\": [\"ttbar-UNSTITCHED\",],\n",
    "                                  \"Stack\": False,\n",
    "                                  \"Draw\": \"PE1\",\n",
    "                                 },\n",
    "        },\n",
    "        \"Ratios\": {\"Unstitched/Stitched\": {\"Numerator\": \"UNSTITCHED\",\n",
    "                               \"Denominator\": \"STITCHED\",\n",
    "                               \"Color\": ROOT.kBlack,\n",
    "                               \"Style\": \"Marker\"\n",
    "                              }\n",
    "                  },\n",
    "    },\n",
    "    \"DefaultCanvas\":{\n",
    "        \"Type\": \"DefaultCanvas\",\n",
    "        \"Title\": \"DefaultCanvasTitle\",\n",
    "        \"Margins\": [0.1, 0.1, 0.1, 0.1],\n",
    "        \"Plots\": None,\n",
    "        \"XPixels\": 800, \n",
    "        \"YPixels\": 800,\n",
    "        \"DoRatio\": False,\n",
    "        \"DoMountainrange\": False,\n",
    "    },\n",
    "}\n",
    "argsDOTplotJSON = {\n",
    "    \"Plot_nJet4_HT\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Style\": {\"MC\": \"Fill\",\n",
    "                  \"Data\": \"Marker\",\n",
    "                 },\n",
    "        \"Files\": \"nJet4_HT.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_nJet5_HT\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Style\": {\"MC\": \"Fill\",\n",
    "                  \"Data\": \"Marker\",\n",
    "                 },\n",
    "        \"Files\": \"nJet5_HT.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_blind_nJet6_HT\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Style\": {\"MC\": \"Fill\",\n",
    "                  \"Data\": \"Marker\",\n",
    "                 },\n",
    "        \"Files\": \"blind_nJet6_HT.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_blind_nJet7_HT\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Style\": {\"MC\": \"Fill\",\n",
    "                  \"Data\": \"Marker\",\n",
    "                 },\n",
    "        \"Files\": \"blind_nJet7_HT.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Plot_blind_nJet8+_HT\":{\n",
    "        \"Type\": \"PlotConfig\",\n",
    "        \"Title\": \"DefaultPlotTitle\",\n",
    "        \"Xaxis\": None,\n",
    "        \"Yaxis\": None,\n",
    "        \"Rebin\": None,\n",
    "        \"Style\": {\"MC\": \"Fill\",\n",
    "                  \"Data\": \"Marker\",\n",
    "                 },\n",
    "        \"Files\": \"blind_nJet8+_HT.root\",\n",
    "        \"Unblind\": False,\n",
    "    },\n",
    "    \"Canvas_HT\":{\n",
    "        \"Type\": \"CanvasConfig\",\n",
    "        \"Title\": \"HT (nJet == {4, 5, 6, 7, 8+})\",\n",
    "        \"Margins\": [0.05, 0.05, 0.1, 0.1],\n",
    "        \"Plots\": [\"Plot_nJet4_HT\", \"Plot_nJet5_HT\", \"Plot_blind_nJet6_HT\", \"Plot_blind_nJet7_HT\", \"Plot_blind_nJet8+_HT\"],\n",
    "        \"Legend\": \"DefaultLegend\",\n",
    "        \"XPixels\": 1200, \n",
    "        \"YPixels\": 1000,\n",
    "        \"DoRatio\": True,\n",
    "        \"DoMountainrange\": True,\n",
    "        \"doLogY\": False,\n",
    "    },\n",
    "    \"Canvas_LogY_HT\":{\n",
    "        \"Type\": \"CanvasConfig\",\n",
    "        \"Title\": \"HT (nJet == {4, 5, 6, 7, 8+})\",\n",
    "        \"Margins\": [0.1, 0.1, 0.1, 0.1],\n",
    "        \"Plots\": [\"Plot_nJet4_HT\", \"Plot_nJet5_HT\", \"Plot_blind_nJet6_HT\", \"Plot_blind_nJet7_HT\", \"Plot_blind_nJet8+_HT\"],\n",
    "        \"Legend\": \"DefaultLegend\",\n",
    "        \"XPixels\": 1200, \n",
    "        \"YPixels\": 1000,\n",
    "        \"DoRatio\": True,\n",
    "        \"DoMountainrange\": True,\n",
    "        \"doLogY\": True,\n",
    "    },\n",
    "}\n",
    "#Add the defaults and any common legends to the dictionary\n",
    "argsDOTplotJSON.update(defaultAndLegends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setGStyle(nDivisions=105):\n",
    "    #ROOT.gStyle.SetCanvasBorderMode(0)\n",
    "    #ROOT.gStyle.SetCanvasColor(ROOT.kWhite)\n",
    "    ##ROOT.gStyle.SetCanvasDefH(600)\n",
    "    ##ROOT.gStyle.SetCanvasDefW(600)\n",
    "    ##ROOT.gStyle.SetCanvasDefX(0)\n",
    "    ##ROOT.gStyle.SetCanvasDefY(0)\n",
    "\n",
    "    ##ROOT.gStyle.SetPadTopMargin(0.08)\n",
    "    ##ROOT.gStyle.SetPadBottomMargin(0.13)\n",
    "    ##ROOT.gStyle.SetPadLeftMargin(0.16)\n",
    "    ##ROOT.gStyle.SetPadRightMargin(0.05)\n",
    "\n",
    "    ROOT.gStyle.SetHistLineColor(1)\n",
    "    ROOT.gStyle.SetHistLineStyle(0)\n",
    "    ROOT.gStyle.SetHistLineWidth(1)\n",
    "    ROOT.gStyle.SetEndErrorSize(2)\n",
    "    ROOT.gStyle.SetMarkerStyle(20)\n",
    "\n",
    "    ROOT.gStyle.SetOptTitle(0)\n",
    "    ROOT.gStyle.SetTitleFont(42)\n",
    "    ROOT.gStyle.SetTitleColor(1)\n",
    "    ROOT.gStyle.SetTitleTextColor(1)\n",
    "    ROOT.gStyle.SetTitleFillColor(10)\n",
    "    ROOT.gStyle.SetTitleFontSize(0.05)\n",
    "\n",
    "    ROOT.gStyle.SetTitleColor(1, \"XYZ\")\n",
    "    ROOT.gStyle.SetTitleFont(42, \"XYZ\")\n",
    "    ROOT.gStyle.SetTitleSize(0.05, \"XYZ\")\n",
    "    ROOT.gStyle.SetTitleXOffset(1.00)\n",
    "    ROOT.gStyle.SetTitleYOffset(1.60)\n",
    "\n",
    "    ROOT.gStyle.SetLabelColor(1, \"XYZ\")\n",
    "    ROOT.gStyle.SetLabelFont(42, \"XYZ\")\n",
    "    ROOT.gStyle.SetLabelOffset(0.007, \"XYZ\")\n",
    "    ROOT.gStyle.SetLabelSize(0.04, \"XYZ\")\n",
    "    \n",
    "    ROOT.gStyle.SetAxisColor(1, \"XYZ\")\n",
    "    ROOT.gStyle.SetStripDecimals(True)\n",
    "    ROOT.gStyle.SetTickLength(0.03, \"XYZ\")\n",
    "    ROOT.gStyle.SetNdivisions(nDivisions, \"XYZ\")\n",
    "    ROOT.gStyle.SetPadTickX(1)\n",
    "    ROOT.gStyle.SetPadTickY(1)\n",
    "\n",
    "    ROOT.gStyle.SetPaperSize(20., 20.)\n",
    "    ROOT.gStyle.SetHatchesLineWidth(5)\n",
    "    ROOT.gStyle.SetHatchesSpacing(0.05)\n",
    "\n",
    "    ROOT.TGaxis.SetExponentOffset(-0.08, 0.01, \"Y\")\n",
    "\n",
    "def createRatio(h1, h2, Cache=None, ratioTitle=\"input 0 vs input 1\", ratioColor = ROOT.kBlack, yMin = 0.5, yMax = 1.5, isBlinded=False, scaleText=1.0, nDivisions=105):\n",
    "    #h3 = h1.Clone(\"rat_{}_{}\".format(h1.GetName(), ratioTitle.replace(\" \", \"_\")))\n",
    "    #h3 = h1.Clone(\"rat_{}\".format(h1.GetName()))\n",
    "    h3 = h1.Clone(\"ratio_{}__{}\".format( (h1.GetName()).replace(\"h_\",\"\"), (h2.GetName()).replace(\"h_\",\"\") ))\n",
    "    h3.SetLineColor(ratioColor)\n",
    "    #FIXME#h3.SetMarkerStyle(21)\n",
    "    # h3.SetTitle(\"\")\n",
    "    # Set up plot for markers and errors according to ROOT example, but SetStats(0) might be too minimal sometimes\n",
    "    h3.Sumw2()\n",
    "    h3.SetStats(0)\n",
    "    h3.Divide(h2)\n",
    "    h3.SetMinimum(yMin)\n",
    "    h3.SetMaximum(yMax)\n",
    "\n",
    "    # Adjust y-axis settings\n",
    "    y = h3.GetYaxis()\n",
    "    y.SetTitle(ratioTitle)\n",
    "    y.SetNdivisions(nDivisions)\n",
    "    #FIXME#y.SetTitleSize(20)\n",
    "    #FIXME#y.SetTitleFont(43)\n",
    "    #FIXME#y.SetTitleOffset(2.5) #1.55\n",
    "    #FIXME#y.SetLabelFont(43)\n",
    "    y.SetLabelSize(y.GetLabelSize()*scaleText)\n",
    "\n",
    "    # Adjust x-axis settings\n",
    "    x = h3.GetXaxis()\n",
    "    x.SetNdivisions(nDivisions)\n",
    "    #FIXME#x.SetTitleSize(20)\n",
    "    #FIXME#x.SetTitleFont(43)\n",
    "    #FIXME#x.SetTitleOffset(4.0)\n",
    "    #FIXME#x.SetLabelFont(43)\n",
    "    x.SetLabelSize(x.GetLabelSize()*scaleText)\n",
    "\n",
    "    #Do blinding\n",
    "    if isBlinded:\n",
    "        for i in xrange(h3.GetNbinsX()):\n",
    "            h3.SetBinContent(i+1, 0.0)\n",
    "        h3.SetMarkerColor(ROOT.kWhite)\n",
    "        h3.SetLineColor(ROOT.kWhite)\n",
    "        h3.SetFillColor(ROOT.kWhite)\n",
    "    if Cache == None:\n",
    "        Cache = {}\n",
    "    #These keys will not be sufficient for multiple ratios to be plotted together, #FIXME\n",
    "    Cache[\"ratio_hist\"] = h3\n",
    "    Cache[\"ratio_Xaxis\"] = x\n",
    "    Cache[\"ratio_Yaxis\"] = y\n",
    "    return Cache\n",
    "\n",
    "\n",
    "def createCanvasPads(canvasTitle, Cache=None, doRatio=False, doMountainrange=False, setXGrid=False, setYGrid=False,\n",
    "                     nXPads=1, topFraction=0.7, bordersLRTB=[0.1, 0.1, 0.1, 0.1], xPixels=800, yPixels=800):\n",
    "    \"\"\"Create canvas with two pads vertically for each of doLin and doLog if they are true\"\"\"\n",
    "    #Divide implicitely creates subpads. This function uses more explicit methods to do the same with varying pad sizes\n",
    "    c = ROOT.TCanvas(canvasTitle, canvasTitle, xPixels, yPixels)\n",
    "    # Upper histogram plot is pad1\n",
    "    upperPads = []\n",
    "    lowerPads = []\n",
    "    #Calculate borders as fraction of the canvas, starting from the desired input. The borders will include area for\n",
    "    #axes and titles.\n",
    "    bordersL = bordersLRTB[0]\n",
    "    bordersR = bordersLRTB[1]\n",
    "    bordersT = bordersLRTB[2]\n",
    "    bordersB = bordersLRTB[3]\n",
    "    #FIXME: Add in space for margins on the left, which will require an additional offset when calculating the edges\n",
    "    usableLR = 1.0 - bordersL - bordersR\n",
    "    usableTB = 1.0 - bordersT - bordersB\n",
    "    #FIXME: This is really for Mountain Ranges where they're all joined. If pads are to be separated, should \n",
    "    #not make assumptions about the larger left/right pads that include border size.\n",
    "    #Then try limiting precision to get rid of weird visual artifacts by casting to limited precision string and back\n",
    "    xEdgesLow = [bordersL + usableLR*z/float(nXPads) for z in xrange(nXPads)]\n",
    "    #Unnecessary for pdf, doesn't help with jsroot canvas gap between 3rd and 4th pads in mountain range\n",
    "    #xEdgesLow = [float(\"{:.3f}\".format(edge)) for edge in xEdgesLow] \n",
    "    xEdgesHigh = [bordersL + usableLR*(z+1)/float(nXPads) for z in xrange(nXPads)]\n",
    "    #xEdgesHigh = [float(\"{:.3f}\".format(edge)) for edge in xEdgesHigh]\n",
    "    #Now the edges must be calculated for each pad, hardcode nYPads = 2\n",
    "    nYPads = 2\n",
    "    #Here's where we correct the 1st and last pads to make space for the border/pad margin\n",
    "    xEdgesLow[0] -= bordersL\n",
    "    xEdgesHigh[-1] += bordersR\n",
    "    yEdgesLow = [0, bordersB + usableTB*(1-topFraction)]\n",
    "    yEdgesHigh = [bordersB + usableTB*(1-topFraction), 1]\n",
    "    #yEdgesLow[0] -= bordersB\n",
    "    #yEdgesHigh[-1] += bordersT\n",
    "    yDivision = 1-bordersT\n",
    "    if doRatio:\n",
    "        yDivision = 1-topFraction\n",
    "        \n",
    "    #Calculate the pad margins, which will be converted from the desired border size as fraction of the total canvas size\n",
    "    #to equivalent fraction of the pad size itself, using the edges arrays.\n",
    "    marginL = bordersL/(xEdgesHigh[0] - xEdgesLow[0])\n",
    "    marginR = bordersR/(xEdgesHigh[-1] - xEdgesLow[-1])\n",
    "    marginB = bordersB/(yEdgesHigh[0] - yEdgesLow[0])\n",
    "    marginT = bordersT/(yEdgesHigh[-1] - yEdgesLow[-1])\n",
    "    #print(\"{} {} \\n {} {}\".format(xEdgesLow, xEdgesHigh, yEdgesLow, yEdgesHigh))\n",
    "    #print(\"{} {} {} {}\".format(marginL, marginR, marginT, marginB))\n",
    "\n",
    "\n",
    "    for z in xrange(nXPads):\n",
    "        c.cd()  # returns to main canvas before defining another pad, to not create sub-subpad\n",
    "        padU = ROOT.TPad(\"{}_{}\".format(canvasTitle,z), \"{}_{}\".format(canvasTitle,z), \n",
    "                        xEdgesLow[z], yEdgesLow[-1], xEdgesHigh[z], yEdgesHigh[-1]) #xmin ymin xmax ymax as fraction\n",
    "        #Set margins for pads depending on passed configuration option, whether ratio and mountainranging are enabled\n",
    "        padU.SetTopMargin(marginT)\n",
    "        if doRatio:\n",
    "            padU.SetBottomMargin(0)  # joins upper and lower plot\n",
    "        else:\n",
    "            padU.SetBottomMargin(marginB)\n",
    "        if doMountainrange:\n",
    "            #Only set the margin to 0 if there is at least one pad to the right, which is equal to zlast = nXPads - 1. Don't do the last right margin...\n",
    "            if 0 <= z < nXPads - 1:\n",
    "                padU.SetRightMargin(0)\n",
    "            else:\n",
    "                padU.SetRightMargin(marginR)\n",
    "            #Now do the left margins, only starting with the second pad, should it exist (hence the equality switching versus the right margins)\n",
    "            if 0 < z <= nXPads - 1:\n",
    "                padU.SetLeftMargin(0)\n",
    "            else:\n",
    "                padU.SetLeftMargin(marginL)\n",
    "        if setXGrid:\n",
    "            padU.SetGridx()\n",
    "        if setYGrid:\n",
    "            padU.SetGridy()\n",
    "        padU.Draw()\n",
    "        if doRatio:\n",
    "            # Lower ratio plot is pad2\n",
    "            padL = ROOT.TPad(\"ratio_{}_{}\".format(canvasTitle,z), \"ratio_{}_{}\".format(canvasTitle,z), \n",
    "                             xEdgesLow[z], yEdgesLow[0], xEdgesHigh[z], yEdgesHigh[0]) #xmin ymin xmax ymax as fraction\n",
    "            padL.SetTopMargin(0)  # joins upper and lower plot\n",
    "            padL.SetBottomMargin(marginB)\n",
    "            if doMountainrange:\n",
    "                #Only set the margin to 0 if there is at least one pad to the right, which is equal to zlast = nXPads - 1. Don't do the last right margin...\n",
    "                if 0 <= z < nXPads - 1:\n",
    "                    padL.SetRightMargin(0)\n",
    "                else:\n",
    "                    padL.SetRightMargin(marginR)\n",
    "                #Now do the left margins, only starting with the second pad, should it exist (hence the equality switching versus the right margins)\n",
    "                if 0 < z <= nXPads - 1:\n",
    "                    padL.SetLeftMargin(0)\n",
    "                else:\n",
    "                    padL.SetLeftMargin(marginL)\n",
    "            if setXGrid:\n",
    "                padL.SetGridx()\n",
    "            if setYGrid:\n",
    "                padL.SetGridy()\n",
    "            padL.Draw()\n",
    "            lowerPads.append(padL)\n",
    "        upperPads.append(padU)\n",
    "    if Cache == None:\n",
    "        Cache = {}\n",
    "    Cache[\"canvas\"] = c\n",
    "    Cache[\"canvas/xEdgesLow\"] = xEdgesLow\n",
    "    Cache[\"canvas/xEdgesHigh\"] = xEdgesHigh\n",
    "    Cache[\"canvas/yEdgesLow\"] = yEdgesLow\n",
    "    Cache[\"canvas/yEdgesHigh\"] = yEdgesHigh\n",
    "    Cache[\"canvas/marginL\"] = marginL\n",
    "    Cache[\"canvas/marginR\"] = marginR\n",
    "    Cache[\"canvas/marginT\"] = marginT\n",
    "    Cache[\"canvas/marginB\"] = marginB\n",
    "    Cache[\"canvas/upperPads\"] = upperPads\n",
    "    Cache[\"canvas/lowerPads\"] = lowerPads\n",
    "    return Cache\n",
    "\n",
    "def createCanvasPads_OldVersion(canvasTitle, Cache=None, doRatio=False, doMountainrange=False, setXGrid=False, setYGrid=False,\n",
    "                     nXPads=1, topFraction=0.7, marginsLRTB=[0.1, 0.1, 0.1, 0.1], xPixels=800, yPixels=800):\n",
    "    \"\"\"Create canvas with two pads vertically for each of doLin and doLog if they are true\"\"\"\n",
    "    #Divide implicitely creates subpads. This function uses more explicit methods to do the same with varying pad sizes\n",
    "    c = ROOT.TCanvas(canvasTitle, canvasTitle, xPixels, yPixels)\n",
    "    # Upper histogram plot is pad1\n",
    "    upperPads = []\n",
    "    lowerPads = []\n",
    "    marginL = marginsLRTB[0]\n",
    "    marginR = marginsLRTB[1]\n",
    "    marginT = marginsLRTB[2]\n",
    "    marginB = marginsLRTB[3]\n",
    "    #FIXME: Add in space for margins on the left, which will require an additional offset when calculating the edges\n",
    "    usableLR = 1.0 - marginL - marginR\n",
    "    usableTB = 1.0 - marginT - marginB\n",
    "    xEdgesLow = [marginL + usableLR*z/float(nXPads) for z in xrange(nXPads)]\n",
    "    xEdgesHigh = [marginL + usableLR*(z+1)/float(nXPads) for z in xrange(nXPads)]\n",
    "    #Margins aren't wholly correct for first and last pads, so hardcode a correction here:\n",
    "    xEdgesLow[0] -= marginL/5.0\n",
    "    xEdgesHigh[-1] += marginR/5.0\n",
    "    yDivision = 1-marginT\n",
    "    if doRatio:\n",
    "        yDivision = 1-topFraction\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    for z in xrange(nXPads):\n",
    "        c.cd()  # returns to main canvas before defining another pad, to not create sub-subpad\n",
    "        padU = ROOT.TPad(\"{}_{}\".format(canvasTitle,z), \"{}_{}\".format(canvasTitle,z), \n",
    "                        xEdgesLow[z], yDivision, xEdgesHigh[z], 1.0 - marginT) #xmin ymin xmax ymax as fraction\n",
    "        #Set margins for pads depending on passed configuration option, whether ratio and mountainranging are enabled\n",
    "        padU.SetTopMargin(marginT)\n",
    "        if doRatio:\n",
    "            padU.SetBottomMargin(0)  # joins upper and lower plot\n",
    "        else:\n",
    "            padU.SetBottomMargin(marginB)\n",
    "        if doMountainrange:\n",
    "            #Only set the margin to 0 if there is at least one pad to the right, which is equal to zlast = nXPads - 1. Don't do the last right margin...\n",
    "            if 0 <= z < nXPads - 1:\n",
    "                padU.SetRightMargin(0)\n",
    "            else:\n",
    "                padU.SetRightMargin(marginR)\n",
    "            #Now do the left margins, only starting with the second pad, should it exist (hence the equality switching versus the right margins)\n",
    "            if 0 < z <= nXPads - 1:\n",
    "                padU.SetLeftMargin(0)\n",
    "            else:\n",
    "                padU.SetLeftMargin(marginL)\n",
    "        if setXGrid:\n",
    "            padU.SetGridx()\n",
    "        if setYGrid:\n",
    "            padU.SetGridy()\n",
    "        padU.Draw()\n",
    "        if doRatio:\n",
    "            # Lower ratio plot is pad2\n",
    "            padL = ROOT.TPad(\"ratio_{}_{}\".format(canvasTitle,z), \"ratio_{}_{}\".format(canvasTitle,z), \n",
    "                             xEdgesLow[z], marginB, xEdgesHigh[z], yDivision) #xmin ymin xmax ymax as fraction\n",
    "            padL.SetTopMargin(0)  # joins upper and lower plot\n",
    "            padL.SetBottomMargin(marginB)\n",
    "            if doMountainrange:\n",
    "                #Only set the margin to 0 if there is at least one pad to the right, which is equal to zlast = nXPads - 1. Don't do the last right margin...\n",
    "                if 0 <= z < nXPads - 1:\n",
    "                    padL.SetRightMargin(0)\n",
    "                else:\n",
    "                    padL.SetRightMargin(marginR)\n",
    "                #Now do the left margins, only starting with the second pad, should it exist (hence the equality switching versus the right margins)\n",
    "                if 0 < z <= nXPads - 1:\n",
    "                    padL.SetLeftMargin(0)\n",
    "                else:\n",
    "                    padL.SetLeftMargin(marginL)\n",
    "            if setXGrid:\n",
    "                padL.SetGridx()\n",
    "            if setYGrid:\n",
    "                padL.SetGridy()\n",
    "            padL.Draw()\n",
    "            lowerPads.append(padL)\n",
    "        upperPads.append(padU)\n",
    "    if Cache == None:\n",
    "        Cache = {}\n",
    "    #Store the edges in the Cache, along with the canvas, upper and lower pads\n",
    "    Cache[\"canvas\"] = c\n",
    "    Cache[\"canvas/upperPads\"] = upperPads\n",
    "    Cache[\"canvas/lowerPads\"] = lowerPads\n",
    "    Cache[\"canvas/xEdgesLow\"] = xEdgesLow\n",
    "    Cache[\"canvas/xEdgesHigh\"] = xEdgesHigh\n",
    "    Cache[\"canvas/yEdgesLow\"] = yEdgesLow\n",
    "    Cache[\"canvas/yEdgesHigh\"] = yEdgesHigh\n",
    "    return Cache\n",
    "\n",
    "def getLabelAndHeader(Cache=None, label=\"#bf{CMS Internal}\", header=\"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(\"PLACEHOLDER\"), marginTop=0.1):\n",
    "    # Add header\n",
    "    cms_label = ROOT.TLatex()\n",
    "    cms_label.SetTextSize(0.04)\n",
    "    cms_label.DrawLatexNDC(0.05, 1-0.55*marginTop, str(label))\n",
    "    cms_header = ROOT.TLatex()\n",
    "    cms_header.SetTextSize(0.03)\n",
    "    cms_header.DrawLatexNDC(0.63, 1-0.6*marginTop, str(header))\n",
    "    if Cache == None:\n",
    "        Cache = {}\n",
    "    Cache[\"cms_label\"] = cms_label\n",
    "    Cache[\"cms_header\"] = cms_header\n",
    "    return Cache\n",
    "\n",
    "def addHists(inputHists, name, scaleArray = None):\n",
    "    retHist = None\n",
    "    for hn, hist in enumerate(inputHists):\n",
    "        if hn == 0:\n",
    "            retHist = hist.Clone(\"{}\".format(name))\n",
    "            if scaleArray != None and len(scaleArray) == len(inputHists):\n",
    "                retHist.Scale(scaleArray[hn])\n",
    "        else:\n",
    "            if scaleArray != None and len(scaleArray) == len(inputHists):\n",
    "                retHist.Add(hist, scaleArray[hn])\n",
    "            else:\n",
    "                retHist.Add(hist)\n",
    "    return retHist\n",
    "\n",
    "def makeCategoryHists(histFile, legendConfig, rootNamePrefix, systematic=None, rebin=None, verbose=False, debug=False):\n",
    "    \"\"\"Function tailored to using a legendConfig to create histograms of added \"\"\"\n",
    "    #Take the legendConfig, which includes coloring and style information in addition to \n",
    "    #The Categories group contains the name of each category along with its color, style, and list of histogram (base) names\n",
    "    #Particular details like title, axes, etc. are left to the higher level function to change.\n",
    "    if type(legendConfig) != dict or \"Categories\" not in legendConfig.keys():\n",
    "        raise ValueError(\"legendConfig passed to makeCategoryHists contains no 'Categories' key\")\n",
    "    histKeys = set([hist.GetName() for hist in histFile.GetListOfKeys()])\n",
    "    if debug:\n",
    "        print(\"The histKeys are: {}\".format(histKeys))\n",
    "    #Create dictionary of histograms to be returned by the function\n",
    "    retHists = {}\n",
    "    #Create a baseName using the passed rootPrefixName and systematic, if non-None. Will be combined with category information\n",
    "    #when making each added histogram's name\n",
    "    baseName = None\n",
    "    if systematic == None:\n",
    "        baseName = rootNamePrefix + \"*\"\n",
    "    else:\n",
    "        baseName = rootNamePrefix + \"_\" + systematic + \"*\"\n",
    "    #Cycle through the config's categories\n",
    "    for cat, config in legendConfig[\"Categories\"].items():\n",
    "        histoList = []\n",
    "        addHistoName = baseName + cat\n",
    "        scaleArray = config.get(\"ScaleArray\", None)\n",
    "        for nn, hname in enumerate(config[\"Names\"]):\n",
    "            if debug: print(\"Creating addHistoName {}\".format(addHistoName))\n",
    "            #Skip plots that contain neither the systematic requested nor the nominal histogram\n",
    "            if systematic != None:\n",
    "                #guard against config file that has more histos than are in the file itself\n",
    "                if hname + \"_\" + systematic not in histKeys and hname not in histKeys:\n",
    "                    if verbose:\n",
    "                        print(\"for {} and rootNamePrefix {}, makeCombinationHists failed to find a histogram (systematic or nominal) corresponding to {}\"\\\n",
    "                          .format(histFile.GetName(), rootNamePrefix, hname))\n",
    "                    continue\n",
    "                else:\n",
    "                    #Append the histo to a list which will be added using a dedicated function\n",
    "                    histoList.append(histFile.Get(hname + \"_\" + systematic))\n",
    "            elif systematic == None:\n",
    "                #guard against config file that has more histos than are in the file itself\n",
    "                if hname not in histKeys:\n",
    "                    if verbose:\n",
    "                        print(\"for {} and rootNamePrefix {}, makeCombinationHists failed to find a histogram (nominal) corresponding to {}\"\\\n",
    "                          .format(histFile.GetName(), rootNamePrefix, hname))\n",
    "                    continue\n",
    "                else:\n",
    "                    #Append the histo to a list which will be added using a dedicated function\n",
    "                    histoList.append(histFile.Get(hname))\n",
    "            \n",
    "\n",
    "        #Make the new histogram with addHistoName, optionally with per-histogram scaling factors\n",
    "        if debug:\n",
    "            print(\"The histoList currently is: {} and the desired categories is {}\".format(histoList, config[\"Names\"]))\n",
    "        #print(addHistoName)\n",
    "        \n",
    "        if len(histoList) == 0:\n",
    "            if debug:\n",
    "                print(\"for category '{}' and config '{}', the histoList is empty\".format(cat, config[\"Names\"]))\n",
    "            continue\n",
    "        else:\n",
    "            retHists[cat] = addHists(histoList, addHistoName, scaleArray = scaleArray)\n",
    "            if rebin == None:\n",
    "                pass\n",
    "            elif type(rebin) == int:\n",
    "                retHists[cat].Rebin(rebin)\n",
    "            elif type(rebin) == list:\n",
    "                rebin_groups = len(rebin) - 1\n",
    "                rebin_array = array.array('d', rebin)\n",
    "                original_name = retHists[cat].GetName()\n",
    "                retHists[cat].SetName(original_name + \"_originalBinning\")\n",
    "                retHists[cat] = retHists[cat].Rebin(rebin_groups, original_name, rebin_array)\n",
    "            else:\n",
    "                print(\"Unsupported rebin input type in [histo_category: {} ]: {}\".format(addHistoName, type(rebin)))\n",
    "            if debug:\n",
    "                print(\"the retHists for category '{}' is {}\".format(cat, retHists))\n",
    "            #Modify the histogram with style and color information, where appropriate\n",
    "            if config[\"Style\"] == \"Fill\":\n",
    "                retHists[cat].SetFillColor(int(config[\"Color\"]))\n",
    "                retHists[cat].SetLineColor(int(config[\"Color\"]))\n",
    "            elif config[\"Style\"] == \"FillAlpha\":\n",
    "                retHists[cat].SetFillColorAlpha(config[\"Color\"], config.get(\"Alpha\", 0.5))\n",
    "                retHists[cat].SetLineColor(config[\"Color\"])\n",
    "            elif config[\"Style\"] == \"Line\":     \n",
    "                retHists[cat].SetLineColor(config[\"Color\"])\n",
    "            elif config[\"Style\"] == \"Marker\":   \n",
    "                retHists[cat].SetMarkerStyle(0)\n",
    "                retHists[cat].SetMarkerSize(1.0)\n",
    "                retHists[cat].SetMarkerColor(config[\"Color\"])\n",
    "            else:\n",
    "                pass\n",
    "    return retHists\n",
    "\n",
    "def makeSuperCategories(histFile, legendConfig, rootName, systematic=None, orderByIntegral=True, \n",
    "                        rebin=None, verbose=False, debug=False):\n",
    "    \"\"\"histFile is an open ROOT file containing histograms without subdirectories, legendConfig contains 'Categories'\n",
    "    with key: value pairs of sample categories (like ttbar or Drell-Yan) and corresponding list of histogram sample names\n",
    "    (like tt_SL, tt_SL-GF, tt_DL, etc.) that are subcomponents of the sample)\n",
    "    The 'SuperCategories' in the configuration contains key: value pairs where the list then references the 'Categories'\n",
    "    to be stacked together.\n",
    "    However, category names should not include any _$SYSTEMATIC postfix; instead, it will be assumed to be appended to each histogram's category name,\n",
    "    so the histograms made for each category will include the _$SYSTEMATIC variation if present, and the nominal if not.\"\"\"\n",
    "    retDict = {}\n",
    "    \n",
    "    #Prepare a counter so we know how many categories are actuallly filled, whatever the legendConfig has as default\n",
    "    nFilledCategories = 0\n",
    "    #Get coordinates for the legend, create it, store the pointer in the dictionary (so it isn't deleted, to hammer the point over and over)\n",
    "    coord = legendConfig.get(\"Coordinates\")\n",
    "    nColumns = legendConfig.get(\"nColumns\")\n",
    "    leg = ROOT.TLegend(coord[0], coord[1], coord[2], coord[3])\n",
    "    #leg.SetBorderSize(0)\n",
    "    #nColumns = math.floor(math.sqrt(len(legendConfig.get(\"Categories\"))))\n",
    "    leg.SetNColumns(nColumns)\n",
    "    if debug:\n",
    "        print(\"nColumns = {} generated from {}\".format(nColumns, len(legendConfig.get(\"Categories\"))))\n",
    "    leg.SetTextSize(0.03)\n",
    "    retDict[\"Legend\"] = leg\n",
    "    \n",
    "    #Create dictionary to return one level up, calling makeCategoryHists to combine subsamples together \n",
    "    #and do color, style configuration for them. Pass through the rebin parameter\n",
    "    retDict[\"Categories/hists\"] = makeCategoryHists(histFile, legendConfig, rootNamePrefix=rootName,\n",
    "                                                    systematic=systematic, rebin=rebin, verbose=verbose, debug=debug)\n",
    "    if debug:\n",
    "        print(\"the retDict contains:\")\n",
    "        pprint.pprint(retDict[\"Categories/hists\"])\n",
    "    #Create an ordered list of tuples using either the integral of each category histogram or just the name (for consistency)\n",
    "    orderingList = []\n",
    "    for cat_name, cat_hist in retDict[\"Categories/hists\"].items():\n",
    "        orderingList.append((cat_hist.GetSumOfWeights(), cat_name, cat_hist, ))\n",
    "    if orderByIntegral:\n",
    "        orderingList.sort(key=lambda j: j[0], reverse=False)\n",
    "    else:\n",
    "        orderingList.sort(key=lambda j: j[1], reverse=False)\n",
    "    #Create dictionary of supercategory items\n",
    "    retDict[\"Supercategories\"] = {}\n",
    "    retDict[\"Supercategories/stats\"] = {}\n",
    "    retDict[\"Supercategories/hists\"] = {} #This will be the last histogram in a stack, or the final added histogram in an unstacked Supercategory\n",
    "    retDict[\"Supercategories/xAxis\"] = {}\n",
    "    retDict[\"Supercategories/yAxis\"] = {}\n",
    "    for super_cat_name, super_cat_list in legendConfig[\"Supercategories\"].items():\n",
    "        if verbose:\n",
    "            print(\"Working on Supercategory '{}' with list {}\".format(super_cat_name, super_cat_list))\n",
    "        #seperate out the orderedLists into sublists which can be combined differently for stacked and unstacked types\n",
    "        #superCategories[\"{}/list\".format(super_cat_name)] = [tup for tup in orderingList if orderingList[1] in super_cat_list[\"Names\"]]\n",
    "        if verbose:\n",
    "            print(\"the list of names to check in the supercategory: {}\".format(super_cat_list[\"Names\"]))\n",
    "        tmpList = [tup for tup in orderingList if tup[1] in super_cat_list[\"Names\"]]\n",
    "        #Check that the list is non-empty, continue to next supercategory otherwise\n",
    "        if len(tmpList) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "        #branch based on whether to do stacking or another addition instead\n",
    "        if debug:\n",
    "            print(\"the value in the dictionary is: {}\".format(super_cat_list[\"Stack\"]))\n",
    "            print(super_cat_list)\n",
    "        if super_cat_list[\"Stack\"] == True:\n",
    "            retDict[\"Supercategories\"][super_cat_name] = ROOT.THStack(\"s_{}*{}\".format(rootName, super_cat_name), \"\")\n",
    "            for tup in tmpList:\n",
    "                legendCode = legendConfig[\"Categories\"][tup[1]][\"Style\"]\n",
    "                if legendCode == \"Fill\" or legendCode == \"FillAlpha\":\n",
    "                    legendCode = \"F\"\n",
    "                elif legendCode == \"Line\":\n",
    "                    legendCode = \"L\"\n",
    "                else:\n",
    "                    #Assume Marker style\n",
    "                    legendCode = \"P\"\n",
    "                #Add the legend entry\n",
    "                leg.AddEntry(tup[2], tup[1], legendCode)\n",
    "                #Add the category histogram to the stack\n",
    "                retDict[\"Supercategories\"][super_cat_name].Add(tup[2])\n",
    "            #Acquire the stats for the finished stack and store it in the dictionary, but we only half-prepare this, since the histogram must be 'drawn' before a stats object is created\n",
    "            retDict[\"Supercategories/hists\"][super_cat_name] = retDict[\"Supercategories\"][super_cat_name].GetStack().Last()#.GetListOfFunctions().FindObject(\"stats\")\n",
    "            #retDict[\"Supercategories/xAxis\"][super_cat_name] = retDict[\"Supercategories\"][super_cat_name].GetStack().First().GetXaxis()\n",
    "            #retDict[\"Supercategories/yAxis\"][super_cat_name] = retDict[\"Supercategories\"][super_cat_name].GetStack().First().GetYaxis()\n",
    "        #Treat it as a super addition of histograms instead\n",
    "        else:\n",
    "            retDict[\"Supercategories\"][super_cat_name] = addHists([tup[2] for tup in tmpList], \"s_{}*{}\".format(rootName, super_cat_name), scaleArray = None)\n",
    "            legendCode = legendConfig[\"Categories\"][tup[1]][\"Style\"]\n",
    "            if legendCode == \"Fill\" or legendCode == \"FillAlpha\":\n",
    "                legendCode = \"F\"\n",
    "            elif legendCode == \"Line\":\n",
    "                legendCode = \"L\"\n",
    "            else:\n",
    "                #Assume Marker style\n",
    "                legendCode = \"P\"\n",
    "            #Add the legend entry, but instead of the tup[2] histogram, the overall added hist.\n",
    "            leg.AddEntry(retDict[\"Supercategories\"][super_cat_name], tup[1], legendCode)\n",
    "            retDict[\"Supercategories/hists\"][super_cat_name] = retDict[\"Supercategories\"][super_cat_name]#.GetListOfFunctions().FindObject(\"stats\")\n",
    "            #retDict[\"Supercategories/xAxis\"][super_cat_name] = retDict[\"Supercategories\"][super_cat_name].GetXaxis()\n",
    "            #retDict[\"Supercategories/yAxis\"][super_cat_name] = retDict[\"Supercategories\"][super_cat_name].GetYaxis()\n",
    "    #Modify the number of columns based on actual filled Categories\n",
    "    nColumns = int(math.floor(math.sqrt(nFilledCategories)))\n",
    "           \n",
    "    return retDict\n",
    "\n",
    "def makeStack_Prototype(histFile, histList=None, legendConfig=None, rootName=None, systematic=None, orderByIntegral=True):\n",
    "    \"\"\"histFile is an open ROOT file containing histograms without subdirectories, histList is a python list of the name of histograms to be stacked together,\n",
    "    not including any _$SYSTEMATIC postfix; this latter part will be assumed to be appended to each histogram, and when the systematic option is used,\n",
    "    this function will stack histograms that have _$SYSTEMATIC postfix; if such a histogram is not present, the nominal histogram without a _$SYSTEMATIC will\n",
    "    be used.\n",
    "    \n",
    "    legendConfig should be a dictionary containing subgrouping, color, and style information about the samples to be loaded\"\"\"\n",
    "    if histList == None and legendConfig == None:\n",
    "        raise ValueError(\"makeStack has received no histList and no legendConfig to create a stack from...\")\n",
    "    elif histList == None:\n",
    "        pass \n",
    "    #Check that the desired histograms is actually present in the root file, separating into category where systematic variation is present and fallback nominal\n",
    "    hists_systematic_set = set([])\n",
    "    if systematic != None:\n",
    "        hists_systematic_set = set([inclusion for inclusion in histList for hist in histFile.GetListOfKeys() if \"{}_{}\".format(inclusion, systematic) == hist.GetName()])\n",
    "    hists_nominal_set = set([inclusion for inclusion in histList for hist in histFile.GetListOfKeys() if inclusion == hist.GetName()])\n",
    "    hists_nominal_set = hist_nominal - hists_systematic\n",
    "    hists_systematic = [\"{}_{}\".format(inclusion, systematic) for inclusion in hists_systematic_set]\n",
    "    hists_nominal = [inclusion for inclusion in hists_nominal_set]\n",
    "    print(hists_systematic)\n",
    "    print(hists_nominal)\n",
    "    \n",
    "    \n",
    "def loopPlottingJSON(inputJSON, Cache=None, directory=\".\", batchOutput=False, pdfOutput=None, verbose=False, debug=False, nDivisions=105):\n",
    "    \"\"\"Loop through a JSON encoded plotcard to draw plots based on root files containing histograms.\n",
    "    Must pass a cache (python dictionary) to the function to prevent python from garbage collecting everything.\"\"\"\n",
    "    \n",
    "    #Disable drawing in batch mode\n",
    "    if batchOutput:\n",
    "        ROOT.gROOT.SetBatch()\n",
    "        \n",
    "    #set default style\n",
    "    setGStyle(nDivisions=nDivisions)\n",
    "    \n",
    "    #Parse the config file into non-default legends, canvases, and plots; make a separate dictionary for the default legend, plot, and canvas which \n",
    "    # are the fallback for any options\n",
    "    legends = dict([(i, j) for i, j in inputJSON.items() if j.get(\"Type\") == \"LegendConfig\"])\n",
    "    canvases = dict([(i, j) for i, j in inputJSON.items() if j.get(\"Type\") == \"CanvasConfig\"])\n",
    "    plots = dict([(i, j) for i, j in inputJSON.items() if j.get(\"Type\") == \"PlotConfig\"])\n",
    "    defaults = dict([(i, j) for i, j in inputJSON.items() if j.get(\"Type\") in [\"DefaultPlot\", \"DefaultCanvas\", \"DefaultLegend\"]])\n",
    "\n",
    "    #Cache everything, we don't want python garbage collecting our objects before we're done using them. \n",
    "    if Cache == None:\n",
    "        Cache = {}\n",
    "    #Loop through the canvases to create. These are the head configurations for making our plots. The Cache should be filled with CanvasConfigs (unique), \n",
    "    #because PlotConfigs may be reused!\n",
    "    #Each CanvasConfig should point to a LegendConfig, which in turn configures how to organize the individual histograms for stacks and grouping\n",
    "    #Each CanvasConfig also must point to a number of PlotConfigs, where a mountain range canvas of 3 categories would point to 3 PlotConfigs.\n",
    "    #The PlotConfig itself has a field for the root file which contains all the sample/data subcategories for that individual histogram \n",
    "    # (for example, ttbar (single lepton), tttt, ttH, DY, data for the leading Muon_pt). \n",
    "    print(\"Looping through canvases\")\n",
    "    can_num = 0\n",
    "    can_max = len(canvases.keys())\n",
    "    for can_name, can_dict in sorted(canvases.items(), key=lambda x: x[0].split(\"_\")[-1], reverse=False):\n",
    "        can_num += 1\n",
    "        CanCache = {} #shorter access to this canvas dictionary\n",
    "        Cache[can_name] = CanCache\n",
    "        \n",
    "        #Acquire the details of this canvas, including the list of (sub)plots, the number of pixels, whether to include a ratio, etc.\n",
    "        CanCache[\"subplots\"] = can_dict.get(\"Plots\")\n",
    "        CanCache[\"sublabels\"] = can_dict.get(\"Labels\")\n",
    "        canTitle = can_dict.get(\"Title\", defaults[\"DefaultCanvas\"].get(\"Title\"))\n",
    "        canCoordinates = can_dict.get(\"Coordinates\", defaults[\"DefaultCanvas\"].get(\"Coordinates\"))\n",
    "        canCoordinates = can_dict.get(\"Margins\", defaults[\"DefaultCanvas\"].get(\"Margins\"))\n",
    "        nXPads = len(CanCache[\"subplots\"])\n",
    "        xPixels=can_dict.get(\"XPixels\", defaults[\"DefaultCanvas\"].get(\"XPixels\"))\n",
    "        yPixels=can_dict.get(\"YPixels\", defaults[\"DefaultCanvas\"].get(\"YPixels\"))\n",
    "        xAxisTitle=can_dict.get(\"XAxisTitle\", defaults[\"DefaultCanvas\"].get(\"XAxisTitle\"))\n",
    "        yAxisTitle=can_dict.get(\"YAxisTitle\", defaults[\"DefaultCanvas\"].get(\"YAxisTitle\"))\n",
    "        doRatio=can_dict.get(\"DoRatio\", defaults[\"DefaultCanvas\"].get(\"DoRatio\"))\n",
    "        doMountainrange=can_dict.get(\"DoMountainrange\", defaults[\"DefaultCanvas\"].get(\"DoMountainrange\"))\n",
    "        doLogY=can_dict.get(\"doLogY\", defaults[\"DefaultCanvas\"].get(\"doLogY\"))\n",
    "        #Load the requested legendConfig, grabing the default if necessary\n",
    "        legendConfig = legends.get(can_dict.get(\"Legend\", \"FallbackToDefault\"), defaults[\"DefaultLegend\"])\n",
    "        \n",
    "        #Load the LegendConfig which denotes which samples to use, colors to assign, etc.\n",
    "        \n",
    "        #Call createCanvasPads with our Can(vas)Cache, allowing us to toss the returned dictionary.\n",
    "        #_ = createCanvasPads(can_name, CanCache, doRatio=doRatio, doMountainrange=doMountainrange, setXGrid=False, \n",
    "        #                     setYGrid=False, nXPads=nXPads, topFraction=0.7, marginsLRTB = canCoordinates, \n",
    "        #                     xPixels=xPixels, yPixels=yPixels)\n",
    "        _ = createCanvasPads(can_name, CanCache, doRatio=doRatio, doMountainrange=doMountainrange, setXGrid=False, \n",
    "                             setYGrid=False, nXPads=nXPads, topFraction=0.7, bordersLRTB = canCoordinates, \n",
    "                             xPixels=xPixels, yPixels=yPixels)\n",
    "        CanCache[\"subplots/files\"] = []\n",
    "        CanCache[\"subplots/supercategories\"] = []\n",
    "        CanCache[\"subplots/ratios\"] = []\n",
    "        CanCache[\"subplots/channels\"] = []\n",
    "        CanCache[\"subplots/histograms\"] = []\n",
    "        CanCache[\"subplots/stats\"] = []\n",
    "        CanCache[\"subplots/rebins\"] = []\n",
    "        CanCache[\"subplots/labels\"] = []\n",
    "        #generate the header and label for the canvas, adding them in the cache as 'cms_label' and 'cms_header' \n",
    "        _ = getLabelAndHeader(Cache=CanCache, \n",
    "                              label=\"#bf{CMS Internal}\", \n",
    "                              header=\"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(41.53),\n",
    "                              marginTop=CanCache[\"canvas/marginT\"])\n",
    "        for pn, subplot_name in enumerate(CanCache[\"subplots\"]):\n",
    "            subplot_dict = plots[\"{}\".format(subplot_name)]\n",
    "            nice_name = subplot_name.replace(\"Plot_\", \"\").replace(\"Plot\", \"\")\n",
    "            #Open the file and append it to the list\n",
    "            CanCache[\"subplots/files\"].append(ROOT.TFile.Open(\"{}/{}\".format(directory, subplot_dict[\"Files\"])))\n",
    "            CanCache[\"subplots/rebins\"].append(subplot_dict.get(\"Rebin\"))\n",
    "            #Call makeSuperCategories with the very same file [pn] referenced, plus the legendConfig\n",
    "            CanCache[\"subplots/supercategories\"].append(makeSuperCategories(CanCache[\"subplots/files\"][pn], legendConfig, nice_name, \n",
    "                                systematic=None, orderByIntegral=True, rebin=CanCache[\"subplots/rebins\"][pn], verbose=verbose, debug=False))\n",
    "            #access the list of upperPads created by createCanvasPads(...)\n",
    "            CanCache[\"canvas/upperPads\"][pn].cd()\n",
    "            \n",
    "            #FIXME\n",
    "            #test_canvas.cd()\n",
    "            #Draw-Number (dn) to add \"SAME\" for additional histograms, similarly for ratios (rdn)\n",
    "            dn = 0\n",
    "            rdn = 0\n",
    "            #Do nasty in-place sorting of the dictionary to get the Stacks drawn first, by getting the key from each key-value pair and getting the \"Stack\" field value,\n",
    "            #from the legendConfig, recalling we need the key part of the tuple (tuple[0]) with a reverse to put the Stack == True items up front...\n",
    "            for super_cat_name, drawable in sorted(CanCache[\"subplots/supercategories\"][pn][\"Supercategories\"].items(), \n",
    "                                                   key=lambda x: legendConfig[\"Supercategories\"][x[0]][\"Stack\"], reverse=True):\n",
    "                #Don't draw blinded data...\n",
    "                if \"data\" in super_cat_name.lower() and \"blind\" in subplot_name.lower() and subplot_dict.get(\"Unblind\", False) == False:\n",
    "                    continue\n",
    "                #Draw SAME if not the first item, using options present in legend configuration\n",
    "                draw_command = legendConfig[\"Supercategories\"][super_cat_name][\"Draw\"]\n",
    "                if dn > 0:\n",
    "                    draw_command += \" SAME\"\n",
    "                if debug:\n",
    "                    print(\"supercategory: {}    type: {}    command: {}\".format(super_cat_name, type(drawable), draw_command))\n",
    "                \n",
    "                #Because these are stacks, don't bother with getting axes and setting titles, just choose whether\n",
    "                #it needs both the x and y axes or just y axis (to avoid many x axis titles being drawn)\n",
    "                if pn == (len(CanCache[\"subplots\"]) - 1):\n",
    "                    drawable.SetTitle(\";{};{}\".format(xAxisTitle, yAxisTitle))\n",
    "                else:\n",
    "                    drawable.SetTitle(\";;{}\".format(yAxisTitle))\n",
    "                drawable.Draw(draw_command)\n",
    "                #increment our counter\n",
    "                dn += 1\n",
    "            if pn == 0:\n",
    "                #Draw the legend in the first category for now...\n",
    "                CanCache[\"subplots/supercategories\"][pn][\"Legend\"].Draw()\n",
    "                scaleText = (1-CanCache[\"canvas/marginL\"])\n",
    "                offsetText = CanCache[\"canvas/marginL\"]\n",
    "                CanCache[\"cms_label\"].Draw()\n",
    "                #Draw the label on the leftmost top pad\n",
    "                #CanCache[\"cms_label\"].Draw()\n",
    "                #Set the y axis title\n",
    "                #####drawable.SetTitle(yAxisTitle)\n",
    "                pass\n",
    "            elif pn == len(CanCache[\"subplots\"]):\n",
    "                scaleText = 0.66\n",
    "                #scaleText = (1-CanCache[\"canvas/marginR\"])\n",
    "                offsetText = 0\n",
    "                CanCache[\"cms_header\"].Draw()\n",
    "                #####drawable.SetTitle(yAxisTitle)\n",
    "                pass\n",
    "            else:\n",
    "                scaleText = 1.0\n",
    "                offsetText = 0\n",
    "            if doLogY:\n",
    "                CanCache[\"canvas/upperPads\"][pn].SetLogy()\n",
    "                \n",
    "            #Create the subpad label, to be drawn. Text stored in CanCache[\"sublabels\"] which should be a list, possibly a list of tuples in the future\n",
    "            CanCache[\"subplots/labels\"].append(ROOT.TLatex())\n",
    "            #padArea = (CanCache[\"canvas/xEdgesHigh\"][pn] - CanCache[\"canvas/xEdgesLow\"][pn])*(CanCache[\"canvas/yEdgesHigh\"][-1] - CanCache[\"canvas/yEdgesLow\"][-1])\n",
    "            #padWidth = (CanCache[\"canvas/xEdgesHigh\"][pn] - CanCache[\"canvas/xEdgesLow\"][pn])\n",
    "            #CanCache[\"subplots/labels\"][-1].SetTextSize(0.5*scaleText) #.04?\n",
    "            CanCache[\"subplots/labels\"][-1].SetTextSizePixels(int(0.05*xPixels*scaleText)) #.04?\n",
    "            CanCache[\"subplots/labels\"][-1].DrawLatexNDC(0.10 + offsetText, 0.78, \"{}\".format(CanCache[\"sublabels\"][pn]))\n",
    "            CanCache[\"subplots/labels\"][-1].Draw()\n",
    "            \n",
    "            #Draw the pad\n",
    "            CanCache[\"canvas/upperPads\"][pn].Draw()\n",
    "            #Now do the ratio plots, if requested\n",
    "            CanCache[\"canvas/lowerPads\"][pn].cd()\n",
    "            if doRatio:\n",
    "                CanCache[\"subplots/ratios\"].append({})\n",
    "                #Get the ratio min/max from the subplot dictionary, falling back to the default plot if there is none\n",
    "                ratioYMin = subplot_dict.get(\"RatioYMin\", defaults[\"DefaultPlot\"].get(\"RatioYMin\"))\n",
    "                ratioYMax = subplot_dict.get(\"RatioYMax\", defaults[\"DefaultPlot\"].get(\"RatioYMax\"))\n",
    "                for aRatioName, aRatio in legendConfig.get(\"Ratios\", defaults[\"DefaultLegend\"].get(\"Ratios\")).items():\n",
    "                    #Get the name of the 'numerator' Supercategory, then use that to grab the final histogram for it (not a THStack! use \"Supercategories/hists\" instead)\n",
    "                    num = aRatio[\"Numerator\"]\n",
    "                    num_hist = CanCache[\"subplots/supercategories\"][pn][\"Supercategories/hists\"][num]\n",
    "                    den = aRatio[\"Denominator\"]\n",
    "                    den_hist = CanCache[\"subplots/supercategories\"][pn][\"Supercategories/hists\"][den]\n",
    "                    color = aRatio[\"Color\"]\n",
    "                    isBlinded=False #flag for making empty ratio plot to still draw axes, etc.\n",
    "                    if (\"data\" in num.lower() or \"data\" in den.lower()) and \"blind\" in subplot_name.lower() and subplot_dict.get(\"Unblind\", False) == False:\n",
    "                        if debug: print(\"Skipping blinded category with data\")\n",
    "                        isBlinded=True #set flag to create empty histo\n",
    "                    #Give it the dictionary we just appended when creating the ratio and storing the axes/other root memory objects\n",
    "                    _ = createRatio(num_hist, den_hist, Cache = CanCache[\"subplots/ratios\"][-1], ratioTitle = aRatioName, \n",
    "                                                  ratioColor = color, yMin = ratioYMin, yMax = ratioYMax, isBlinded=isBlinded, scaleText=scaleText, nDivisions=nDivisions)\n",
    "                    ratio_draw_command = legendConfig[\"Supercategories\"][num][\"Draw\"]\n",
    "                    if rdn > 0:\n",
    "                        ratio_draw_command += \" SAME\"\n",
    "                    CanCache[\"subplots/ratios\"][-1][\"ratio_hist\"].Draw(ratio_draw_command)\n",
    "                    #Set the x axis title if it's the last drawable item\n",
    "                    if pn == (len(CanCache[\"subplots\"]) - 1):\n",
    "                        CanCache[\"subplots/ratios\"][-1][\"ratio_Xaxis\"].SetTitle(xAxisTitle)\n",
    "                    #increment our counter for ratios\n",
    "                    rdn += 1\n",
    "                #FIXME: better would be to make the Supercategory \"blindable\" instead of assuming 'data' is in the name\n",
    "            #Draw the pad regardless, for consistency\n",
    "            CanCache[\"canvas/lowerPads\"][pn].Draw() \n",
    "        CanCache[\"canvas\"].cd()    \n",
    "        \n",
    "        #Disable default title and make our own\n",
    "        ROOT.gStyle.SetOptTitle(1);\n",
    "        #CanCache[\"canvas_title\"] = ROOT.TPaveLabel(.25,.95,.6,.99, canTitle,\"trndc\");\n",
    "        CanCache[\"canvas_title\"] = ROOT.TLatex()\n",
    "        canTitlePerc = 0.2\n",
    "        CanCache[\"canvas_title\"].SetTextSizePixels(int(canTitlePerc*xPixels))\n",
    "        CanCache[\"canvas_title\"].DrawLatexNDC(0.5*(1-canTitlePerc), .95, str(canTitle))\n",
    "        CanCache[\"canvas_title\"].Draw()\n",
    "        #CanCache[\"cms_label\"].Draw()\n",
    "        CanCache[\"canvas\"].Draw()\n",
    "        print(\"\\tDrew {}\".format(can_name))\n",
    "        if pdfOutput != None:\n",
    "            if can_num == 1: #count from 1 since we increment at the beginning of the loop on this one\n",
    "                print(\"Opening {}\".format(pdfOutput))\n",
    "                CanCache[\"canvas\"].SaveAs(\"{}(\".format(pdfOutput))\n",
    "            elif can_num == can_max:\n",
    "                print(\"Closing {}\".format(pdfOutput))\n",
    "                CanCache[\"canvas\"].SaveAs(\"{})\".format(pdfOutput))\n",
    "            else:\n",
    "                CanCache[\"canvas\"].SaveAs(\"{}\".format(pdfOutput))\n",
    "    return Cache\n",
    "\n",
    "def loopPlotJSON_Prototype(inputJSON, Cache=None, directory=\".\"):\n",
    "    \"\"\"Loop through a JSON encoded plotcard to draw plots based on root files containing histograms.\n",
    "    Must pass a cache (python dictionary) to the function to prevent python from garbage collecting everything.\"\"\"\n",
    "    legends = [(i, j) for i, j in inputJSON.items() if j.get(\"Type\") == \"LegendConfig\"]\n",
    "    canvases = [(i, j) for i, j in inputJSON.items() if j.get(\"Type\") == \"CanvasConfig\"]\n",
    "    plots = [(i, j) for i, j in inputJSON.items() if j.get(\"Type\") == \"PlotConfig\"]\n",
    "    \n",
    "    pprint.pprint(plots)\n",
    "    if Cache == None:\n",
    "        Cache = {}\n",
    "    plt_num = 0\n",
    "    for plt_name, plt_dict in plots:\n",
    "        plt_num += 1\n",
    "        Cache[plt_name] = {}\n",
    "        try:\n",
    "            #Form the path to the histogram file using the directory and the file name specified in the plotcard\n",
    "            print(\"Opening file... {}\".format(plt_dict.get(\"Files\")))\n",
    "            f = ROOT.TFile.Open(directory + \"/\" + plt_dict.get(\"Files\"))\n",
    "            Cache[plt_name][\"File\"] = f\n",
    "            for k in f.GetListOfKeys():\n",
    "                hist_name = k.GetName()\n",
    "                Cache[plt_name][hist_name] = f.Get(hist_name)\n",
    "                Cache[plt_name][\"c_{}\".format(hist_name)] = ROOT.TCanvas(\"c_{}_{}\".format(plt_name, hist_name), \"\", 800, 600)\n",
    "                Cache[plt_name][\"c_{}\".format(hist_name)].cd()\n",
    "                Cache[plt_name][hist_name].SetLineColor(ROOT.kRed)\n",
    "                Cache[plt_name][hist_name].Draw(\"HIST\")\n",
    "                Cache[plt_name][\"c_{}\".format(hist_name)].Draw()\n",
    "        except:\n",
    "            print(\"Failed in execution of loopPlotJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "#dd = loopPlottingJSON(argsDOTplotJSON, Cache=None, directory=\"test_20200123\")\n",
    "#dd = loopPlottingJSON(argsDOTplotJSON, Cache=None, directory=\"test_20200206\", pdfOutput=\"test_20200206/test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfSet = {}\n",
    "channel = \"ElMu\"\n",
    "pdfSet[\"nonJetVariables\"] = plotJSONFromVars(modelPlotJSON_nMediumDeepCSV2_nJet, [\"Electron_pfRelIso03_all\",\"Electron_pfRelIso03_chg\",\"H\",\n",
    "                                                     \"H2M\",\"HT\",\"HT2M\",\"HTH\",\"HTRat\",\"HTb\",\"MET_phi\",\"MET_pt\",\n",
    "                                                     \"MTofElandMu\",\"MTofMETandEl\",\"MTofMETandMu\",\"Muon_pfRelIso03_all\",\n",
    "                                                     \"Muon_pfRelIso03_chg\",\"Muon_pfRelIso04_all\",\"dEtabb\",\"dEtall\",\n",
    "                                                     \"dPhibb\",\"dPhill\",\"dRbb\",\"dRll\",\"nMediumDeepCSV\",\"nMediumDeepJet\",\n",
    "                                                       ], channel=channel)\n",
    "pdfSet[\"jetPt\"] = plotJSONFromVars(modelPlotJSON_nMediumDeepCSV2_nJet, [\"Jet_pt_jet1\", \"Jet_pt_jet2\", \"Jet_pt_jet3\", \"Jet_pt_jet4\", \"Jet_pt_jet5\", \n",
    "                                              \"Jet_pt_jet6\", \"Jet_pt_jet7\", \"Jet_pt_jet8\", \"Jet_pt_jet9\", \"Jet_pt_jet10\",\n",
    "                                              ], channel=channel)\n",
    "pdfSet[\"jetEta\"] = plotJSONFromVars(modelPlotJSON_nMediumDeepCSV2_nJet, [\"Jet_eta_jet1\", \"Jet_eta_jet2\", \"Jet_eta_jet3\", \"Jet_eta_jet4\", \"Jet_eta_jet5\", \n",
    "                                               \"Jet_eta_jet6\", \"Jet_eta_jet7\", \"Jet_eta_jet8\", \"Jet_eta_jet9\", \"Jet_eta_jet10\",\n",
    "                                              ], channel=channel)\n",
    "pdfSet[\"jetPhi\"] = plotJSONFromVars(modelPlotJSON_nMediumDeepCSV2_nJet, [\"Jet_phi_jet1\", \"Jet_phi_jet2\", \"Jet_phi_jet3\", \"Jet_phi_jet4\", \"Jet_phi_jet5\", \n",
    "                                               \"Jet_phi_jet6\", \"Jet_phi_jet7\", \"Jet_phi_jet8\", \"Jet_phi_jet9\", \"Jet_phi_jet10\", \n",
    "                                              ], channel=channel)\n",
    "pdfSet[\"MVAVars_nBtag2_nJet\"] = plotJSONFromVars(modelPlotJSON_nMediumDeepCSV2_nJet, [\"H\",\"H2M\",\"HT\",\"HT2M\",\"HTH\",\"HTRat\",\"HTb\",\"dRbb\", \"dRll\", \n",
    "                                                                          \"Jet_pt_jet3\", \"Jet_eta_jet3\", \"Jet_pt_jet4\", \"Jet_eta_jet4\",\n",
    "                                                                          \"GLepton_pt_LeadLep\", \"GLepton_eta_LeadLep\", \"GLepton_pt_SubleadLep\", \"GLepton_eta_SubleadLep\",\n",
    "                                                                          \"nLooseDeepCSV\", \"nMediumDeepCSV\", \"nTightDeepCSV\"], channel=channel)\n",
    "pdfSet[\"MVAVars_nJet\"] = plotJSONFromVars(modelPlotJSON_nJet, [\"H\",\"H2M\",\"HT\",\"HT2M\",\"HTH\",\"HTRat\",\"HTb\",\"dRbb\", \"dRll\", \n",
    "                                                                          \"Jet_pt_jet3\", \"Jet_eta_jet3\", \"Jet_pt_jet4\", \"Jet_eta_jet4\",\n",
    "                                                                          \"GLepton_pt_LeadLep\", \"GLepton_eta_LeadLep\", \"GLepton_pt_SubleadLep\", \"GLepton_eta_SubleadLep\",\n",
    "                                                                          \"nLooseDeepCSV\", \"nMediumDeepCSV\", \"nTightDeepCSV\"], channel=channel)\n",
    "#singlePlot = plotJSONFromVars(modelPlotJSON_nJet, [\"Muon_InvMass\"], channel=\"MuMu\")\n",
    "singlePlot = plotJSONFromVars(modelPlotJSON_nMediumDeepCSV2_nJet, [\"Muon_InvMass\",], channel=channel)\n",
    "pdfSet[\"nonJetVariables\"].update(defaultAndLegends)\n",
    "pdfSet[\"jetPt\"].update(defaultAndLegends)\n",
    "pdfSet[\"jetEta\"].update(defaultAndLegends)\n",
    "pdfSet[\"jetPhi\"].update(defaultAndLegends)\n",
    "pdfSet[\"MVAVars_nBtag2_nJet\"].update(defaultAndLegends)\n",
    "pdfSet[\"MVAVars_nJet\"].update(defaultAndLegends)\n",
    "singlePlot.update(defaultAndLegends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "folder = \"select_20200225/{}_selection\".format(channel)\n",
    "#folder = \"test_20200213\"\n",
    "#plotNonJetVariables = loopPlottingJSON(nonJetVariables, Cache=None, directory=folder, pdfOutput=\"{}/NEWnonJetVariables.pdf\".format(folder))\n",
    "#plotJetPt = loopPlottingJSON(jetPt, Cache=None, directory=folder, pdfOutput=\"{}/NEWjetPt.pdf\".format(folder))\n",
    "#plotJetEta = loopPlottingJSON(jetEta, Cache=None, directory=folder, pdfOutput=\"{}/NEWjetEta.pdf\".format(folder))\n",
    "#plotJetPhi = loopPlottingJSON(jetPhi, Cache=None, directory=folder, pdfOutput=\"{}/NEWjetPhi.pdf\".format(folder))\n",
    "#plotSinglePlot = loopPlottingJSON(singlePlot, Cache=None, directory=folder, pdfOutput=\"./testt.pdf\")\n",
    "resultsDict = {}\n",
    "for k, v in pdfSet.items():\n",
    "    resultsDict[k] = loopPlottingJSON(v, Cache=None, directory=folder, pdfOutput=\"{}/{}.pdf\".format(folder, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfSet[\"MVAVars_nBtag2_nJet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNSTOnonJetVariables = plotJSONFromVars(modelPlotJSON_nJet_noLogY, [\"Electron_pfRelIso03_all\",\"Electron_pfRelIso03_chg\",\"H\",\n",
    "                                                     \"H2M\",\"HT\",\"HT2M\",\"HTH\",\"HTRat\",\"HTb\",\"MET_phi\",\"MET_pt\",\n",
    "                                                     \"MTofElandMu\",\"MTofMETandEl\",\"MTofMETandMu\",\"Muon_pfRelIso03_all\",\n",
    "                                                     \"Muon_pfRelIso03_chg\",\"Muon_pfRelIso04_all\",\"dEtabb\",\"dEtall\",\n",
    "                                                     \"dPhibb\",\"dPhill\",\"dRbb\",\"dRll\",\"nMediumDeepCSV\",\"nMediumDeepJet\",\n",
    "                                                       ])\n",
    "UNSTOjetPt = plotJSONFromVars(modelPlotJSON_nJet_noLogY, [\"Jet_pt_jet1\", \"Jet_pt_jet2\", \"Jet_pt_jet3\", \"Jet_pt_jet4\", \"Jet_pt_jet5\", \n",
    "                                              \"Jet_pt_jet6\", \"Jet_pt_jet7\", \"Jet_pt_jet8\", \"Jet_pt_jet9\", \"Jet_pt_jet10\",\n",
    "                                              ])\n",
    "UNSTOjetEta = plotJSONFromVars(modelPlotJSON_nJet_noLogY, [\"Jet_eta_jet1\", \"Jet_eta_jet2\", \"Jet_eta_jet3\", \"Jet_eta_jet4\", \"Jet_eta_jet5\", \n",
    "                                               \"Jet_eta_jet6\", \"Jet_eta_jet7\", \"Jet_eta_jet8\", \"Jet_eta_jet9\", \"Jet_eta_jet10\",\n",
    "                                              ])\n",
    "UNSTOjetPhi = plotJSONFromVars(modelPlotJSON_nJet_noLogY, [\"Jet_phi_jet1\", \"Jet_phi_jet3\", \"Jet_phi_jet4\", \"Jet_phi_jet5\", \n",
    "                                               \"Jet_phi_jet6\", \"Jet_phi_jet7\", \"Jet_phi_jet8\", \"Jet_phi_jet9\", \"Jet_phi_jet10\", \n",
    "                                              ])\n",
    "#nonJetVariables.update(defaultForStitchComparison)\n",
    "#jetPt.update(defaultForStitchComparison)\n",
    "#jetEta.update(defaultForStitchComparison)\n",
    "#jetPhi.update(defaultForStitchComparison)\n",
    "UNSTOnonJetVariables.update(defaultForStitchComparisonOnlyTT)\n",
    "UNSTOjetPt.update(defaultForStitchComparisonOnlyTT)\n",
    "UNSTOjetEta.update(defaultForStitchComparisonOnlyTT)\n",
    "UNSTOjetPhi.update(defaultForStitchComparisonOnlyTT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "folder = \"select_20200219\"\n",
    "#folder = \"test_20200213\"\n",
    "#UNSTOplotNonJetVariables = loopPlottingJSON(UNSTOnonJetVariables, Cache=None, directory=folder, pdfOutput=\"{}/UNSTOnonJetVariables.pdf\".format(folder))\n",
    "#UNSTOplotJetPt = loopPlottingJSON(UNSTOjetPt, Cache=None, directory=folder, pdfOutput=\"{}/UNSTOjetPt.pdf\".format(folder))\n",
    "UNSTOplotJetEta = loopPlottingJSON(UNSTOjetEta, Cache=None, directory=folder, pdfOutput=\"{}/UNSTOjetEta.pdf\".format(folder))\n",
    "#UNSTOplotJetPhi = loopPlottingJSON(UNSTOjetPhi, Cache=None, directory=folder, pdfOutput=\"{}/UNSTOjetPhi.pdf\".format(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint.pprint(dd)\n",
    "ccc = ROOT.TCanvas(\"ccc\", \"\", 800, 600)\n",
    "ccc.cd()\n",
    "#ppp = ROOT.TPad(\"ppp\", \"ppp\", 0, 0, 1, 1)\n",
    "#ppp.cd()\n",
    "#ppp.Draw()\n",
    "dd['Canvas_nMediumDeepJet2_dAnglebb']['subplots/supercategories'][0]['Supercategories']['Signal+Background'].Draw(\"HIST\")\n",
    "ccc.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ROOT.TFile.Open(\"test_20200123/nJet4_Muon_pfRelIso03_chg.root\")\n",
    "test2 = ROOT.TFile.Open(\"test_20200123/nJet4_Muon_pfRelIso03_all.root\")\n",
    "test3 = ROOT.TFile.Open(\"test_20200123/nJet6_Muon_pfRelIso03_chg.root\")\n",
    "testDict = makeSuperCategories(test, argsDOTplotJSON[\"DefaultLegend\"], \"RelIso_chg\", systematic=None, orderByIntegral=True, debug=False)\n",
    "testDict2 = makeSuperCategories(test2, argsDOTplotJSON[\"DefaultLegend\"], \"RelIso_all\", systematic=None, orderByIntegral=True, debug=False)\n",
    "testDict3 = makeSuperCategories(test3, argsDOTplotJSON[\"DefaultLegend\"], \"RelIso_all_nj6\", systematic=None, orderByIntegral=True, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "print(testDict)\n",
    "cache = createCanvasPads(\"ATest\", Cache=None, doRatio=False, doMountainrange=True, setXGrid=False, setYGrid=False,\n",
    "                     nXPads=3, topFraction=0.7, xPixels=800, yPixels=800)\n",
    "c = cache[\"canvas\"]\n",
    "up = cache[\"canvas/upperPads\"]\n",
    "up[0].cd()\n",
    "testDict['Supercategories']['Signal+Background'].Draw(\"HIST\")\n",
    "testDict['Categories/hists']['singletop'].Draw(\"PE1 SAMES\")#Draw(\"PE! SAMES\") #Does #PE! do something different?\n",
    "up[0].Draw()\n",
    "print(type(testDict['Supercategories/stats']['Signal+Background']))\n",
    "#testDict['Supercategories/stats']['Signal+Background'] = testDict['Supercategories/stats']['Signal+Background'].GetListOfFunctions().FindObject(\"stats\")\n",
    "up[1].cd()\n",
    "testDict2['Supercategories']['Signal+Background'].Draw(\"HIST\")\n",
    "testDict2['Categories/hists']['singletop'].Draw(\"PE1 SAMES\")#Draw(\"PE! SAMES\") #Does #PE! do something different?\n",
    "up[1].Draw()\n",
    "print(type(testDict2['Supercategories/stats']['Signal+Background']))\n",
    "#testDict2['Supercategories/stats']['Signal+Background'] = testDict['Supercategories/stats']['Signal+Background'].GetListOfFunctions().FindObject(\"stats\")\n",
    "up[2].cd()\n",
    "testDict3['Supercategories']['Signal+Background'].Draw(\"HIST\")\n",
    "testDict3['Categories/hists']['singletop'].Draw(\"PE1 SAMES\")#Draw(\"PE! SAMES\") #Does #PE! do something different?\n",
    "up[2].Draw()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = testDict2['Supercategories']['Signal+Background'].GetStack().Last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(a.GetStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "mycache = {}\n",
    "loopPlotJSON(argsDOTplotJSON, mycache, \"test_20200123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ROOT.TFile.Open(\"test_20200123\" + \"/\" + \"nJet4_Muon_pfRelIso03_chg.root\")\n",
    "f.ls()\n",
    "c = ROOT.TCanvas(\"c\")\n",
    "c.Divide(1,3)\n",
    "for kn, k in enumerate(f.GetListOfKeys()):  \n",
    "    c.cd(kn + 1)\n",
    "    h = f.Get(k.GetName())\n",
    "    h.Draw()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterstart = time.time() #.clock() gives cpu time, not what I want for this measure (especially multicore)\n",
    "with open(\"2017_booker.py\", \"r\") as f:\n",
    "    for line in f:\n",
    "        #print(line, end=\"\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME: Need filter efficiency calculated for single lepton generator filtered sample. First approximation will be from MCCM (0.15) but as seen before, it's not ideal. \n",
    "#May need to recalculate using genWeight/sumWeights instead of sign(genWeight)/(nPositiveEvents - nNegativeEvents), confirm if there's any difference.\n",
    "lumi = {\"2017\": 41.53,\n",
    "        \"2018\": 1}\n",
    "era = \"2017\"\n",
    "leg_dict = {\"tttt\": ROOT.kAzure-2,\n",
    "            \"ttbar\": ROOT.kRed,\n",
    "            \"singletop\": ROOT.kYellow,\n",
    "            \"ttH\": ROOT.kMagenta,\n",
    "            \"ttVJets\": ROOT.kViolet,\n",
    "            \"ttultrarare\": ROOT.kGreen,\n",
    "            \"DY\": ROOT.kCyan,\n",
    "            \"Data\": ROOT.kBlack,\n",
    "            \"QCD\": ROOT.kPink,\n",
    "           }\n",
    "print(leg_dict)\n",
    "microbookerV2 = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttt-*_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttt-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt-2_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tttt/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-*_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-2_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-3_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-4_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-5_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-6_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-7_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-8_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-9_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-10_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-11_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-12_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-13_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-14_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_DL/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_SL/$SYSTEMATIC\",\n",
    "    },\n",
    "\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tW_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tW_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ST_tW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ST_tbarW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7745276,\n",
    "        \"nEventsPositive\": 7715654,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 270762750.172525,\n",
    "        \"sumWeights2\": 9611964941.797768,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tbarW_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tbarW_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ST_tbarW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"DYJets_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 49125561,\n",
    "        \"nEventsPositive\": 49103859,\n",
    "        \"nEventsNegative\": 21702,\n",
    "        \"sumWeights\": 49082157.000000,\n",
    "        \"sumWeights2\": 49125561.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 5075.6,\n",
    "        \"color\": leg_dict[\"DY\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-*_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-1_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-2_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-3_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-4_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-5_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-6_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-7_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/DYJets_DL/$SYSTEMATIC\",\n",
    "    },\n",
    "}\n",
    "tt_data_V2 = {\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-*_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-2_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-3_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-4_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-5_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-6_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-7_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-8_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-9_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-10_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-11_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-12_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-13_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-14_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_DL/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_SL/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ElMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"BCDEF\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465 + 15595214 + 9164365 + 19043421 + 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_*_2017.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_*_2017.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ElMu/$SYSTEMATIC\",\n",
    "    },    \n",
    "}\n",
    "bookerV2 = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttt-*_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttt-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt-2_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tttt/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-*_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-2_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-3_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-4_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-5_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-6_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-7_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-8_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-9_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-10_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-11_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-12_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-13_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-NOM-14_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_DL/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-NOM_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_SL/$SYSTEMATIC\",\n",
    "    },\n",
    "\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tW_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tW_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ST_tW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ST_tbarW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7745276,\n",
    "        \"nEventsPositive\": 7715654,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 270762750.172525,\n",
    "        \"sumWeights2\": 9611964941.797768,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tbarW_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ST_tbarW_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ST_tbarW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"DYJets_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 49125561,\n",
    "        \"nEventsPositive\": 49103859,\n",
    "        \"nEventsNegative\": 21702,\n",
    "        \"sumWeights\": 49082157.000000,\n",
    "        \"sumWeights2\": 49125561.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 5075.6,\n",
    "        \"color\": leg_dict[\"DY\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-*_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-1_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-2_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-3_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-4_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-5_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-6_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/DYJets_DL-7_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/DYJets_DL/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8000000,\n",
    "        \"nEventsPositive\": 7916867,\n",
    "        \"nEventsNegative\": 83133,\n",
    "        \"sumWeights\": 4216319.315884,\n",
    "        \"sumWeights2\": 2317497.816608,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.2934,\n",
    "        \"color\": leg_dict[\"ttH\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttH_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttH_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttH/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttWJets\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 9425384,\n",
    "        \"nEventsPositive\": 9404856,\n",
    "        \"nEventsNegative\": 20528,\n",
    "        \"sumWeights\": 9384328.000000,\n",
    "        \"sumWeights2\": 9425384.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.611,\n",
    "        \"color\": leg_dict[\"ttVJets\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWJets_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWJets_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttWJets/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttZJets\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8536618,\n",
    "        \"nEventsPositive\": 8527846,\n",
    "        \"nEventsNegative\": 8772,\n",
    "        \"sumWeights\": 8519074.000000,\n",
    "        \"sumWeights2\": 8536618.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.783,\n",
    "        \"color\": leg_dict[\"ttVJets\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZJets_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZJets_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttZJets/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttWH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199491,\n",
    "        \"nEventsNegative\": 509,\n",
    "        \"sumWeights\": 198839.680865,\n",
    "        \"sumWeights2\": 199704.039588,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.001572,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWH_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWH_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttWH/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttWW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 962000,\n",
    "        \"nEventsPositive\": 962000,\n",
    "        \"nEventsNegative\": 0,\n",
    "        \"sumWeights\": 962000.000000,\n",
    "        \"sumWeights2\": 962000.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.007882,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWW_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWW_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttWW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttWZ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199379,\n",
    "        \"nEventsNegative\": 621,\n",
    "        \"sumWeights\": 198625.183551,\n",
    "        \"sumWeights2\": 199708.972601,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.002974,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWZ_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttWZ_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttWZ/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttZZ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199686,\n",
    "        \"nEventsNegative\": 314,\n",
    "        \"sumWeights\": 199286.628891,\n",
    "        \"sumWeights2\": 199816.306332,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.001572,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZZ_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZZ_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttZZ/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttZH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199643,\n",
    "        \"nEventsNegative\": 357,\n",
    "        \"sumWeights\": 199192.234990,\n",
    "        \"sumWeights2\": 199794.753976,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.01253,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZH_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttZH_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttZH/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ttHH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 194817,\n",
    "        \"nEventsPositive\": 194516,\n",
    "        \"nEventsNegative\": 301,\n",
    "        \"sumWeights\": 194116.909912,\n",
    "        \"sumWeights2\": 194611.090542,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.0007408,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttHH_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ttHH_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ttHH/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tttJ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199273,\n",
    "        \"nEventsNegative\": 727,\n",
    "        \"sumWeights\": 198394.878491,\n",
    "        \"sumWeights2\": 199663.384954,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.0004741,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttJ_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttJ_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tttJ/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ElMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"BCDEF\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465 + 15595214 + 9164365 + 19043421 + 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_*_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_B_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_C_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_D_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_E_2017_v2.root\",\n",
    "                        \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/data_ElMu_F_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/ElMu/NOMINAL\",\n",
    "    },\n",
    "}\n",
    "cutoutV2_ToBeFixed = {\n",
    "    \"QCD_HT200\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 59200263,\n",
    "        \"nEventsPositive\": 59166789,\n",
    "        \"nEventsNegative\": 32544,\n",
    "        \"sumWeights\": 59133315.000000,\n",
    "        \"sumWeights2\": 59200263.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1712000.0,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT200_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT200_2017_v2.root\",],\n",
    "    },\n",
    "    \"QCD_HT300\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 59569132,\n",
    "        \"nEventsPositive\": 59514373,\n",
    "        \"nEventsNegative\": 54759,\n",
    "        \"sumWeights\": 59459614.000000,\n",
    "        \"sumWeights2\": 59569132.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 347700.0,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT300_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT300_2017_v2.root\",],\n",
    "    },   \n",
    "    \"QCD_HT500\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 56207744,\n",
    "        \"nEventsPositive\": 56124381,\n",
    "        \"nEventsNegative\": 83363,\n",
    "        \"sumWeights\": 56041018.000000,\n",
    "        \"sumWeights2\": 56207744.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 32100.0,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT500_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT500_2017_v2.root\",],\n",
    "    },\n",
    "    \"QCD_HT700\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 46840955,\n",
    "        \"nEventsPositive\": 46739970,\n",
    "        \"nEventsNegative\": 100985,\n",
    "        \"sumWeights\": 46638985.000000,\n",
    "        \"sumWeights2\": 46840955.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 6831.0,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT700_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT700_2017_v2.root\",],\n",
    "    },\n",
    "    \"QCD_HT1000\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 16882838,\n",
    "        \"nEventsPositive\": 16826800,\n",
    "        \"nEventsNegative\": 56038,\n",
    "        \"sumWeights\": 16770762.000000,\n",
    "        \"sumWeights2\": 16882838.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1207.0,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT1000_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT1000_2017_v2.root\",],\n",
    "    },\n",
    "    \"QCD_HT1500\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 11634434,\n",
    "        \"nEventsPositive\": 11571519,\n",
    "        \"nEventsNegative\": 62915,\n",
    "        \"sumWeights\": 11508604.000000,\n",
    "        \"sumWeights2\": 11634434.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 119.9,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT1500_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT1500_2017_v2.root\",],\n",
    "    },\n",
    "    \"QCD_HT2000\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 5941306,\n",
    "        \"nEventsPositive\": 5883436,\n",
    "        \"nEventsNegative\": 57870,\n",
    "        \"sumWeights\": 5825566.000000,\n",
    "        \"sumWeights2\": 5941306.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 25.24,\n",
    "        \"color\": leg_dict[\"QCD\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT2000_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/QCD_HT2000_2017_v2.root\",],\n",
    "    },\n",
    "    \"tt_SL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8836856,\n",
    "        \"nEventsPositive\": 8794464,\n",
    "        \"nEventsNegative\": 42392,\n",
    "        \"sumWeights\": 2653328498.476976,\n",
    "        \"sumWeights2\": 812201885978.209229,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 6,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-GF_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_SL-GF_2017_v2.root\"],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_SL-GF/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tt_DL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8510388,\n",
    "        \"nEventsPositive\": 8467543,\n",
    "        \"nEventsNegative\": 42845,\n",
    "        \"sumWeights\": 612101836.284397,\n",
    "        \"sumWeights2\": 44925503249.097206,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1.4705,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-GF-*_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-GF-1_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-GF-2_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-GF-3_2017_v2.root\",\n",
    "                       \"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tt_DL-GF-4_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tt_DL-GF/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"tttW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199852,\n",
    "        \"nEventsNegative\": 148,\n",
    "        \"sumWeights\": 199552.187377,\n",
    "        \"sumWeights2\": 199697.648421,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.007882,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttW_2017_v2.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/tttW_2017_v2.root\",],\n",
    "        \"destination\": \"/$HIST_CLASS/$HIST/tttW/$SYSTEMATIC\",\n",
    "    },\n",
    "    \"ElMu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_B_2017.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_B_2017.root\",],\n",
    "        },\n",
    "    \"ElMu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 15595214, \n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_C_2017.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_C_2017.root\",],\n",
    "        },\n",
    "    \"ElMu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 9164365,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_D_2017.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_D_2017.root\",],\n",
    "        },\n",
    "    \"ElMu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 19043421,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_E_2017.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_E_2017.root\",],\n",
    "        },\n",
    "    \"ElMu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_F_2017.root\",\n",
    "        \"sourceSPARK\": [\"root://eoshome-n.cern.ch//eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElMu_F_2017.root\",],\n",
    "        },\n",
    "    \"MuMu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 14501767,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_B_2017.root\",\n",
    "        },\n",
    "    \"MuMu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 49636525,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_C_2017.root\",\n",
    "        },\n",
    "    \"MuMu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 23075733,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_D_2017.root\",\n",
    "        },\n",
    "    \"MuMu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 51589091,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_E_2017.root\",\n",
    "        },\n",
    "    \"MuMu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 79756560,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/MuMu_F_2017.root\",\n",
    "        },\n",
    "    \"ElEl_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 58088760,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_B_2017.root\",\n",
    "        },\n",
    "    \"ElEl_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 65181125,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_C_2017.root\",\n",
    "        },\n",
    "    \"ElEl_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 25911432,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_D_2017.root\",\n",
    "        },\n",
    "    \"ElEl_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 56233597,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_E_2017.root\",\n",
    "        },\n",
    "    \"ElEl_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 74307066,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/ElEl_F_2017.root\",\n",
    "        },\n",
    "    \"Mu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136300266,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/Mu_B_2017.root\",\n",
    "        },\n",
    "    \"Mu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 165652756,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/Mu_C_2017.root\",\n",
    "        },\n",
    "    \"Mu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 70361660,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/Mu_D_2017.root\",\n",
    "        },\n",
    "    \"Mu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 154630534,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/Mu_E_2017.root\",\n",
    "        },\n",
    "    \"Mu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 242135500,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/Mu_F_2017.root\",\n",
    "        },\n",
    "    \"El_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 60537490,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/El_B_2017.root\",\n",
    "        },\n",
    "    \"El_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136637888,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/El_C_2017.root\",\n",
    "        },\n",
    "    \"El_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 51526710,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/El_D_2017.root\",\n",
    "        },\n",
    "    \"El_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 102121689,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/El_E_2017.root\",\n",
    "        },\n",
    "    \"El_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 128467223,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/FilesV2/El_F_2017.root\",\n",
    "    },\n",
    "}\n",
    "ttbooker = {\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017_PUFix.root\",\n",
    "        },\n",
    "}\n",
    "ttttbooker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017_PUFix.root\",\n",
    "        },\n",
    "}\n",
    "microbooker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tW_2017_PUFix.root\",\n",
    "        },\n",
    "}\n",
    "theOriginal = {\n",
    "    \"tttt_orig\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt-orig_2.root\",\n",
    "        },\n",
    "}\n",
    "pyrdfbooker = {\n",
    "    \"tt_DL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8510388,\n",
    "        \"nEventsPositive\": 8467543,\n",
    "        \"nEventsNegative\": 42845,\n",
    "        \"sumWeights\": 612101836.284397,\n",
    "        \"sumWeights2\": 44925503249.097206,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1.4705,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL-GF-*_2017_PUFix.root\",\n",
    "        },\n",
    "}\n",
    "booker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tt_SL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8836856,\n",
    "        \"nEventsPositive\": 8794464,\n",
    "        \"nEventsNegative\": 42392,\n",
    "        \"sumWeights\": 2653328498.476976,\n",
    "        \"sumWeights2\": 812201885978.209229,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 6,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL-GF_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tt_DL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8510388,\n",
    "        \"nEventsPositive\": 8467543,\n",
    "        \"nEventsNegative\": 42845,\n",
    "        \"sumWeights\": 612101836.284397,\n",
    "        \"sumWeights2\": 44925503249.097206,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1.4705,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL-GF-*_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tW_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ST_tbarW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7745276,\n",
    "        \"nEventsPositive\": 7715654,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 270762750.172525,\n",
    "        \"sumWeights2\": 9611964941.797768,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tbarW_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ttH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8000000,\n",
    "        \"nEventsPositive\": 7916867,\n",
    "        \"nEventsNegative\": 83133,\n",
    "        \"sumWeights\": 4216319.315884,\n",
    "        \"sumWeights2\": 2317497.816608,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.2934,\n",
    "        \"color\": leg_dict[\"ttH\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttH_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ttWJets\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 9425384,\n",
    "        \"nEventsPositive\": 9404856,\n",
    "        \"nEventsNegative\": 20528,\n",
    "        \"sumWeights\": 9384328.000000,\n",
    "        \"sumWeights2\": 9425384.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.611,\n",
    "        \"color\": leg_dict[\"ttVJets\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWJets_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ttZJets\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8536618,\n",
    "        \"nEventsPositive\": 8527846,\n",
    "        \"nEventsNegative\": 8772,\n",
    "        \"sumWeights\": 8519074.000000,\n",
    "        \"sumWeights2\": 8536618.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.783,\n",
    "        \"color\": leg_dict[\"ttVJets\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttZJets_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ttWH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199491,\n",
    "        \"nEventsNegative\": 509,\n",
    "        \"sumWeights\": 198839.680865,\n",
    "        \"sumWeights2\": 199704.039588,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.001572,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWH_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ttWW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 962000,\n",
    "        \"nEventsPositive\": 962000,\n",
    "        \"nEventsNegative\": 0,\n",
    "        \"sumWeights\": 962000.000000,\n",
    "        \"sumWeights2\": 962000.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.007882,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWW_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ttWZ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199379,\n",
    "        \"nEventsNegative\": 621,\n",
    "        \"sumWeights\": 198625.183551,\n",
    "        \"sumWeights2\": 199708.972601,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.002974,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttWZ_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ttZZ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199686,\n",
    "        \"nEventsNegative\": 314,\n",
    "        \"sumWeights\": 199286.628891,\n",
    "        \"sumWeights2\": 199816.306332,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.001572,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttZZ_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ttZH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199643,\n",
    "        \"nEventsNegative\": 357,\n",
    "        \"sumWeights\": 199192.234990,\n",
    "        \"sumWeights2\": 199794.753976,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.01253,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttZH_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ttHH\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 194817,\n",
    "        \"nEventsPositive\": 194516,\n",
    "        \"nEventsNegative\": 301,\n",
    "        \"sumWeights\": 194116.909912,\n",
    "        \"sumWeights2\": 194611.090542,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.0007408,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ttHH_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tttW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199852,\n",
    "        \"nEventsNegative\": 148,\n",
    "        \"sumWeights\": 199552.187377,\n",
    "        \"sumWeights2\": 199697.648421,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.007882,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttW_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tttJ\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 200000,\n",
    "        \"nEventsPositive\": 199273,\n",
    "        \"nEventsNegative\": 727,\n",
    "        \"sumWeights\": 198394.878491,\n",
    "        \"sumWeights2\": 199663.384954,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 0.0004741,\n",
    "        \"color\": leg_dict[\"ttultrarare\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttJ_2017_PUFix.root\",\n",
    "        },\n",
    "    \"DYJets_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 49125561,\n",
    "        \"nEventsPositive\": 49103859,\n",
    "        \"nEventsNegative\": 21702,\n",
    "        \"sumWeights\": 49082157.000000,\n",
    "        \"sumWeights2\": 49125561.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 5075.6,\n",
    "        \"color\": leg_dict[\"DY\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/DYJets_DL_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ElMu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_B_2017.root\",\n",
    "        },\n",
    "    \"ElMu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 15595214,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_C_2017.root\",\n",
    "        },\n",
    "    \"ElMu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 9164365,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_D_2017.root\",\n",
    "        },\n",
    "    \"ElMu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 19043421,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_E_2017.root\",\n",
    "        },\n",
    "    \"ElMu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_F_2017.root\",\n",
    "        },\n",
    "}\n",
    "cutout = {\n",
    "    \"MuMu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 14501767,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_B_2017.root\",\n",
    "        },\n",
    "    \"MuMu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 49636525,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_C_2017.root\",\n",
    "        },\n",
    "    \"MuMu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 23075733,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_D_2017.root\",\n",
    "        },\n",
    "    \"MuMu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 51589091,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_E_2017.root\",\n",
    "        },\n",
    "    \"MuMu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 79756560,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_F_2017.root\",\n",
    "        },\n",
    "    \"ElEl_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 58088760,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_B_2017.root\",\n",
    "        },\n",
    "    \"ElEl_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 65181125,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_C_2017.root\",\n",
    "        },\n",
    "    \"ElEl_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 25911432,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_D_2017.root\",\n",
    "        },\n",
    "    \"ElEl_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 56233597,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_E_2017.root\",\n",
    "        },\n",
    "    \"ElEl_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 74307066,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_F_2017.root\",\n",
    "        },\n",
    "    \"Mu_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136300266,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_B_2017.root\",\n",
    "        },\n",
    "    \"Mu_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 165652756,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_C_2017.root\",\n",
    "        },\n",
    "    \"Mu_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 70361660,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_D_2017.root\",\n",
    "        },\n",
    "    \"Mu_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 154630534,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_E_2017.root\",\n",
    "        },\n",
    "    \"Mu_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 242135500,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_F_2017.root\",\n",
    "        },\n",
    "    \"El_B\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 60537490,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_B_2017.root\",\n",
    "        },\n",
    "    \"El_C\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"C\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136637888,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_C_2017.root\",\n",
    "        },\n",
    "    \"El_D\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"D\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 51526710,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_D_2017.root\",\n",
    "        },\n",
    "    \"El_E\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"E\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 102121689,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_E_2017.root\",\n",
    "        },\n",
    "    \"El_F\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"F\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 128467223,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_F_2017.root\",\n",
    "        },\n",
    "    }\n",
    "minibooker = {\n",
    "    \"tttt\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 2273928,\n",
    "        \"nEventsPositive\": 1561946,\n",
    "        \"nEventsNegative\": 711982,\n",
    "        \"sumWeights\": 18645.487772,\n",
    "        \"sumWeights2\": 1094.209551,\n",
    "        \"isSignal\": True,\n",
    "        \"crossSection\": 0.012,\n",
    "        \"color\": leg_dict[\"tttt\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tttt_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tt_SL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8836856,\n",
    "        \"nEventsPositive\": 8794464,\n",
    "        \"nEventsNegative\": 42392,\n",
    "        \"sumWeights\": 2653328498.476976,\n",
    "        \"sumWeights2\": 812201885978.209229,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 6,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL-GF_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tt_DL-GF\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 8510388,\n",
    "        \"nEventsPositive\": 8467543,\n",
    "        \"nEventsNegative\": 42845,\n",
    "        \"sumWeights\": 612101836.284397,\n",
    "        \"sumWeights2\": 44925503249.097206,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 1.4705,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL-GF-*_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tt_SL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 20122010,\n",
    "        \"nEventsPositive\": 20040607,\n",
    "        \"nEventsNegative\": 81403,\n",
    "        \"sumWeights\": 6052480345.748356,\n",
    "        \"sumWeights2\": 1850350248120.376221,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 366.2073,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_SL_2017_PUFix.root\",\n",
    "        },\n",
    "    \"tt_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 69098644,\n",
    "        \"nEventsPositive\": 68818780,\n",
    "        \"nEventsNegative\": 279864,\n",
    "        \"sumWeights\": 4980769113.241218,\n",
    "        \"sumWeights2\": 364913493679.955078,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 89.0482,\n",
    "        \"color\": leg_dict[\"ttbar\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/tt_DL_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ST_tW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7945242,\n",
    "        \"nEventsPositive\": 7914815,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 277241050.840222,\n",
    "        \"sumWeights2\": 9823995766.508368,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tW_2017_PUFix.root\",\n",
    "        },\n",
    "    \"ST_tbarW\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 7745276,\n",
    "        \"nEventsPositive\": 7715654,\n",
    "        \"nEventsNegative\": 30427,\n",
    "        \"sumWeights\": 270762750.172525,\n",
    "        \"sumWeights2\": 9611964941.797768,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 35.8,\n",
    "        \"color\": leg_dict[\"singletop\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ST_tbarW_2017_PUFix.root\",\n",
    "        },\n",
    "\n",
    "    \"DYJets_DL\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"isData\": False,\n",
    "        \"nEvents\": 49125561,\n",
    "        \"nEventsPositive\": 49103859,\n",
    "        \"nEventsNegative\": 21702,\n",
    "        \"sumWeights\": 49082157.000000,\n",
    "        \"sumWeights2\": 49125561.000000,\n",
    "        \"isSignal\": False,\n",
    "        \"crossSection\": 5075.6,\n",
    "        \"color\": leg_dict[\"DY\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/DYJets_DL_2017_PUFix.root\",\n",
    "        },\n",
    "    \"MuMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"MuMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 14501767 + 49636525 + 23075733 + 51589091 + 79756560,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/MuMu_*_2017.root\",\n",
    "        },\n",
    "    \"ElEl\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElEl\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 58088760 + 65181125 + 25911432 + 56233597 + 74307066,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElEl_*_2017.root\",\n",
    "        },\n",
    "    \"ElMu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"ElMu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 4453465 + 15595214 + 9164365 + 19043421 + 25776363,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/ElMu_*_2017.root\",\n",
    "        },\n",
    "    \"Mu\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"Mu\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 136300266 + 165652756 + 70361660 + 154630534 + 242135500,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/Mu_*_2017.root\",\n",
    "        },\n",
    "    \"El\":{\n",
    "        \"era\": \"2017\",\n",
    "        \"subera\": \"B\",\n",
    "        \"channel\": \"El\",\n",
    "        \"isData\": True,\n",
    "        \"nEvents\": 60537490 + 136637888 + 51526710 + 102121689 + 128467223,\n",
    "        \"color\": leg_dict[\"Data\"],\n",
    "        \"source\": \"/eos/user/n/nmangane/SWAN_projects/LogicChainRDF/El_*_2017.root\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "#Set up channel bits for selection and baseline. Separation not necessary in this stage, but convenient for loops\n",
    "Chan = {}\n",
    "Chan[\"ElMu_selection\"] = 24576\n",
    "Chan[\"MuMu_selection\"] = 6144\n",
    "Chan[\"ElEl_selection\"] = 512\n",
    "Chan[\"Mu_selection\"] = 128\n",
    "Chan[\"El_selection\"] = 64\n",
    "Chan[\"selection\"] = Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"] + Chan[\"Mu_selection\"] + Chan[\"El_selection\"]\n",
    "Chan[\"ElMu_baseline\"] = 24576\n",
    "Chan[\"MuMu_baseline\"] = 6144\n",
    "Chan[\"ElEl_baseline\"] = 512\n",
    "Chan[\"Mu_baseline\"] = 128\n",
    "Chan[\"El_baseline\"] = 64\n",
    "Chan[\"baseline\"] = Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"] + Chan[\"El_baseline\"]\n",
    "\n",
    "\n",
    "#samples[\"tt_DL-GF\"] = {}\n",
    "#samples[\"tt_DL-GF\"][\"path\"] = base + \"crab_tt_DL-GF_2017/results/tree*.root\"\n",
    "#booker[\"tttt\"]['nEvents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ROOT.kBlue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transverseMassCode = '''auto MT2 = {m1}*{m1} + {m2}*{m2} + 2*(sqrt({m1}*{m1} + {pt1}*{pt1})*sqrt({m2}*{m2} + {pt2}*{pt2}) - {pt1}*{pt2}*cos({phi1} - {phi2}));\n",
    "                         return sqrt(MT2);'''\n",
    "b = transverseMassCode.format(m1 = \"GMuon_mass\", m2 = \"0\",\n",
    "                                                                  pt1 = \"GMuon_pt\",\n",
    "                                                                 pt2 = \"METFixEE2017_pt\", \n",
    "                                                                 phi1 = \"GMuon_phi\", phi2 = \"METFixEE2017_phi\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineLeptons(input_df, input_lvl_filter=None, channel=None, isData=True, useBackupChannel=False):\n",
    "    \"\"\"Function to take in a dataframe and return one with new columns defined,\n",
    "    plus event filtering based on the criteria defined inside the function\"\"\"\n",
    "    if channel == None:\n",
    "        raise RuntimeError(\"channel must be selected, such as 'MuMu' or 'ElMu'\")\n",
    "    elif channel == \"MuMu\":\n",
    "        nMuExp = 2\n",
    "        nElExp = 0\n",
    "    elif channel == \"ElMu\":\n",
    "        nMuExp = 1\n",
    "        nElExp = 1\n",
    "    elif channel == \"MuMu\":\n",
    "        nMuExp = 0\n",
    "        nElExp = 2\n",
    "        \n",
    "    #Set up channel bits for selection and baseline. Separation not necessary in this stage, but convenient for loops\n",
    "    Chan = {}\n",
    "    Chan[\"ElMu_selection\"] = 24576\n",
    "    Chan[\"MuMu_selection\"] = 6144\n",
    "    Chan[\"ElEl_selection\"] = 512\n",
    "    Chan[\"Mu_selection\"] = 128\n",
    "    Chan[\"El_selection\"] = 64\n",
    "    Chan[\"selection\"] = Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"] + Chan[\"Mu_selection\"] + Chan[\"El_selection\"]\n",
    "    Chan[\"ElMu_baseline\"] = 24576\n",
    "    Chan[\"MuMu_baseline\"] = 6144\n",
    "    Chan[\"ElEl_baseline\"] = 512\n",
    "    Chan[\"Mu_baseline\"] = 128\n",
    "    Chan[\"El_baseline\"] = 64\n",
    "    Chan[\"baseline\"] = Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"] + Chan[\"El_baseline\"]\n",
    "    b = {}\n",
    "    b[\"baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + \n",
    "                                                                            Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"] + Chan[\"El_baseline\"])\n",
    "    \n",
    "    b[\"ElMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) > 0\".format(Chan[\"ElMu_baseline\"])\n",
    "    b[\"MuMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"], \n",
    "                                                                                                                                Chan[\"MuMu_baseline\"])\n",
    "    b[\"ElEl_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"], \n",
    "                                                                                                                                Chan[\"ElEl_baseline\"])\n",
    "    b[\"Mu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"], Chan[\"Mu_baseline\"])\n",
    "    b[\"El_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + \n",
    "                                                                                                                    Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"], Chan[\"El_baseline\"])\n",
    "    b[\"selection\"] = \"ESV_TriggerAndLeptonLogic_selection > 0\"\n",
    "    b[\"ElMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) > 0\".format(Chan[\"ElMu_selection\"])\n",
    "    b[\"MuMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"], Chan[\"MuMu_selection\"])\n",
    "    b[\"ElEl_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"], Chan[\"ElEl_selection\"])\n",
    "    b[\"Mu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"], Chan[\"Mu_selection\"])\n",
    "    b[\"El_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"]\n",
    "                                                                                                                                 + Chan[\"Mu_selection\"], Chan[\"El_selection\"])\n",
    "    if input_lvl_filter == None:\n",
    "        rdf_input = input_df\\\n",
    "                .Define(\"mu_mask\", \"Muon_pt > 0\").Define(\"e_mask\", \"Electron_pt > 0\")\n",
    "    else:\n",
    "        if \"baseline\" in input_lvl_filter:\n",
    "            lvl_type = \"baseline\"\n",
    "        elif \"selection\" in input_lvl_filter:\n",
    "            lvl_type = \"selection\"\n",
    "        else:\n",
    "            raise RuntimeError(\"No such level permissable: must contain 'selection' or 'baseline'\")\n",
    "        rdf_input = input_df.Filter(b[input_lvl_filter], input_lvl_filter)\n",
    "        rdf = rdf_input\n",
    "        rdf = rdf.Define(\"mu_mask\", \"(Muon_OSV_{0} & {1}) > 0\".format(lvl_type, Chan[input_lvl_filter]))\n",
    "        rdf = rdf.Define(\"e_mask\", \"(Electron_OSV_{0} & {1}) > 0\".format(lvl_type, Chan[input_lvl_filter]))\n",
    "    indexDefineCode = '''ROOT::VecOps::RVec<int> i({0}.size());\n",
    "                     std::iota(i.begin(), i.end(), 0);\n",
    "                     return i;'''\n",
    "    transverseMassCode = '''auto MT2 = {m1}*{m1} + {m2}*{m2} + 2*(sqrt({m1}*{m1} + {pt1}*{pt1})*sqrt({m2}*{m2} + {pt2}*{pt2}) - {pt1}*{pt2}*cos(ROOT::VecOps::DeltaPhi({phi1}, {phi2})));\n",
    "                         return sqrt(MT2);'''\n",
    "    transverseMassCodeChecker = '''auto V1 = ROOT::Math::PtEtaPhiMVector({pt1}, {eta1}, {phi1}, {m1});\n",
    "                                auto V2 = ROOT::Math::PtEtaPhiMVector({pt2}, {eta2}, {phi2}, {m2});\n",
    "                                auto V = V1 + V2;\n",
    "                                return V.Mt();'''\n",
    "    transverseMassLightCode = '''auto MT2 = 2*{pt1}*{pt2}*(1 - cos(ROOT::VecOps::DeltaPhi({phi1}, {phi2})));\n",
    "                              return sqrt(MT2);'''\n",
    "    rdf = rdf.Define(\"Muon_idx\", indexDefineCode.format(\"mu_mask\"))\n",
    "    rdf = rdf.Define(\"GMuon_idx\", \"Muon_idx[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_pfIsoId\", \"Muon_pfIsoId[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_looseId\", \"Muon_looseId[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_pt\", \"Muon_pt[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_eta\", \"Muon_eta[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_phi\", \"Muon_phi[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_mass\", \"Muon_mass[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_charge\", \"Muon_charge[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_dz\", \"Muon_dz[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_dxy\", \"Muon_dxy[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_d0\", \"sqrt(Muon_dz*Muon_dz + Muon_dxy*Muon_dxy)[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_ip3d\", \"Muon_ip3d[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_pfRelIso03_all\", \"Muon_pfRelIso03_all[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_pfRelIso03_chg\", \"Muon_pfRelIso03_chg[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_pfRelIso04_all\", \"Muon_pfRelIso04_all[mu_mask]\")\n",
    "    rdf = rdf.Define(\"GMuon_jetIdx\", \"Muon_jetIdx[mu_mask]\")\n",
    "    rdf = rdf.Define(\"MTofMETandMu\", transverseMassCode.format(m1 = \"GMuon_mass\", m2 = \"0\",\n",
    "                                                                  pt1 = \"GMuon_pt\",\n",
    "                                                                 pt2 = \"METFixEE2017_pt\", \n",
    "                                                                 phi1 = \"GMuon_phi\", phi2 = \"METFixEE2017_phi\"))\n",
    "    rdf = rdf.Define(\"MTMasslessCheck\", transverseMassLightCode.format(pt1 = \"GMuon_pt.at(0)\", pt2 = \"METFixEE2017_pt\", \n",
    "                                                                            phi1 = \"GMuon_phi.at(0)\", phi2 = \"METFixEE2017_phi\"))\n",
    "    rdf = rdf.Define(\"MTCrossCheck\", transverseMassCodeChecker.format(m1 = \"GMuon_mass.at(0)\", m2 = \"0\",\n",
    "                                                                         eta1 = \"GMuon_eta.at(0)\", eta2 = \"0\",\n",
    "                                                                         pt1 = \"GMuon_pt.at(0)\", pt2 = \"METFixEE2017_pt\", \n",
    "                                                                         phi1 = \"GMuon_phi.at(0)\", phi2 = \"METFixEE2017_phi\"))\n",
    "    rdf = rdf.Define(\"MTCrossCheckDifference\", \"abs(MTofMETandMu - MTCrossCheck)/MTCrossCheck\")\n",
    "    rdf = rdf.Define(\"MTCrossCheckMasslessDifference\", \"abs(MTMasslessCheck - MTofMETandMu)/MTMasslessCheck\")\n",
    "    rdf = rdf.Define(\"nGMuon\", \"GMuon_pt.size()\")\n",
    "    rdf = rdf.Define(\"nLooseGMuon\", \"Muon_looseId[mu_mask && Muon_looseId == true].size()\")\n",
    "    rdf = rdf.Define(\"nMediumGMuon\", \"Muon_mediumId[mu_mask && Muon_mediumId == true].size()\")\n",
    "    rdf = rdf.Define(\"nTightGMuon\", \"Muon_tightId[mu_mask && Muon_tightId == true].size()\")\n",
    "    rdf = rdf.Define(\"Electron_idx\", indexDefineCode.format(\"e_mask\"))\n",
    "    rdf = rdf.Define(\"GElectron_idx\", \"Electron_idx[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_cutBased\", \"Electron_cutBased[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_pt\", \"Electron_pt[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_eta\", \"Electron_eta[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_phi\", \"Electron_phi[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_mass\", \"Electron_mass[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_charge\", \"Electron_charge[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_dz\", \"Electron_dz[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_dxy\", \"Electron_dxy[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_d0\", \"sqrt(Electron_dz*Electron_dz + Electron_dxy*Electron_dxy)[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_ip3d\", \"Electron_ip3d[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_pfRelIso03_all\", \"Electron_pfRelIso03_all[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_pfRelIso03_chg\", \"Electron_pfRelIso03_chg[e_mask]\")\n",
    "    rdf = rdf.Define(\"GElectron_jetIdx\", \"Electron_jetIdx[e_mask]\")\n",
    "    rdf = rdf.Define(\"MTofMETandEl\", transverseMassCode.format(m1 = \"GElectron_mass\", m2 = \"0\",\n",
    "                                                                  pt1 = \"GElectron_pt\",\n",
    "                                                                 pt2 = \"METFixEE2017_pt\", \n",
    "                                                                 phi1 = \"GElectron_phi\", phi2 = \"METFixEE2017_phi\"))\n",
    "    \n",
    "    rdf = rdf.Define(\"MTofElandMu\", transverseMassCode.format(m1 = \"GElectron_mass\", m2 = \"GMuon_mass\",\n",
    "                                                                  pt1 = \"GElectron_pt\",\n",
    "                                                                 pt2 = \"GMuon_pt\", \n",
    "                                                                 phi1 = \"GElectron_phi\", phi2 = \"GMuon_phi\"))\n",
    "    rdf = rdf.Define(\"nGElectron\", \"GElectron_pt.size()\")\n",
    "    rdf = rdf.Define(\"nLooseGElectron\", \"Sum(GElectron_cutBased >= 2)\")\n",
    "    rdf = rdf.Define(\"nMediumGElectron\", \"Sum(GElectron_cutBased >= 3)\")\n",
    "    rdf = rdf.Define(\"nTightGElectron\", \"Sum(GElectron_cutBased >= 4)\")\n",
    "    rdf = rdf.Define(\"GLepton_argsort\", \"Reverse(Argsort(Concatenate(Muon_pt[mu_mask], Electron_pt[e_mask])))\")\n",
    "    rdf = rdf.Define(\"GLepton_pt\", \"Take(Concatenate(Muon_pt[mu_mask], Electron_pt[e_mask]), GLepton_argsort)\")\n",
    "    rdf = rdf.Define(\"GLepton_eta\", \"Take(Concatenate(Muon_eta[mu_mask], Electron_eta[e_mask]), GLepton_argsort)\")\n",
    "    rdf = rdf.Define(\"GLepton_phi\", \"Take(Concatenate(Muon_phi[mu_mask], Electron_phi[e_mask]), GLepton_argsort)\")\n",
    "    rdf = rdf.Define(\"GLepton_jetIdx\", \"Take(Concatenate(Muon_jetIdx[mu_mask], Electron_jetIdx[e_mask]), GLepton_argsort)\")\n",
    "    rdf = rdf.Define(\"GLepton_pdgId\", \"Take(Concatenate(Muon_pdgId[mu_mask], Electron_pdgId[e_mask]), GLepton_argsort)\")\n",
    "    rdf = rdf.Define(\"GLepton_dRll\", \"GLepton_pt.size() > 1 ? ROOT::VecOps::DeltaR(GLepton_eta.at(0), GLepton_eta.at(1), GLepton_phi.at(0), GLepton_phi.at(1)) : -0.1\")\n",
    "    rdf = rdf.Define(\"GLepton_dPhill\", \"GLepton_pt.size() > 1 ? ROOT::VecOps::DeltaPhi(GLepton_phi.at(0), GLepton_phi.at(1)) : -999\")\n",
    "    rdf = rdf.Define(\"GLepton_dEtall\", \"GLepton_pt.size() > 1 ? abs(GLepton_eta.at(0) - GLepton_eta.at(1)) : -999\")\n",
    "    rdf = rdf.Define(\"nGLepton\", \"GLepton_pt.size()\")\n",
    "    rdf = rdf.Define(\"GLepton_pt_LeadLep\", \"GLepton_pt.size() > 0 ? GLepton_pt.at(0) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GLepton_pt_SubleadLep\", \"GLepton_pt.size() > 1 ? GLepton_pt.at(1) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GLepton_jetIdx_0\", \"GLepton_jetIdx.size() > 0 ? GLepton_jetIdx.at(0) : -1\")\n",
    "    rdf = rdf.Define(\"GLepton_jetIdx_1\", \"GLepton_jetIdx.size() > 1 ? GLepton_jetIdx.at(1) : -1\")\n",
    "    if isData == False:\n",
    "        rdf = rdf.Define(\"GMuon_SF_ID_nom\", \"Muon_SF_ID_nom[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GMuon_SF_ID_stat\", \"Muon_SF_ID_stat[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GMuon_SF_ID_syst\", \"Muon_SF_ID_syst[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GMuon_SF_ISO_nom\", \"Muon_SF_ISO_nom[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GMuon_SF_ISO_stat\", \"Muon_SF_ISO_stat[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GMuon_SF_ISO_syst\", \"Muon_SF_ISO_syst[mu_mask]\")\n",
    "        rdf = rdf.Define(\"GElectron_SF_EFF_nom\", \"Electron_SF_EFF_nom[e_mask]\")\n",
    "        rdf = rdf.Define(\"GElectron_SF_EFF_unc\", \"Electron_SF_EFF_unc[e_mask]\")\n",
    "        rdf = rdf.Define(\"GElectron_SF_ID_nom\", \"Electron_SF_ID_nom[e_mask]\")\n",
    "        rdf = rdf.Define(\"GElectron_SF_ID_unc\", \"Electron_SF_ID_unc[e_mask]\")\n",
    "        rdf = rdf.Define(\"GLepton_SF_nom\", \"Take(Concatenate(Muon_SF_ID_nom[mu_mask]*Muon_SF_ISO_nom[mu_mask], Electron_SF_ID_nom[e_mask]*Electron_SF_EFF_nom[e_mask]), GLepton_argsort)\")\n",
    "#    else:\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ID_nom\", \"1\")\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ID_stat\", \"0\")\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ID_syst\", \"0\")\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ISO_nom\", \"1\")\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ISO_stat\", \"0\")\n",
    "#        rdf = rdf.Define(\"GMuon_SF_ISO_syst\", \"0\")\n",
    "#        rdf = rdf.Define(\"GElectron_SF_EFF_nom\", \"1\")\n",
    "#        rdf = rdf.Define(\"GElectron_SF_EFF_unc\", \"0\")\n",
    "#        rdf = rdf.Define(\"GElectron_SF_ID_nom\", \"1\")\n",
    "#        rdf = rdf.Define(\"GElectron_SF_ID_unc\", \"0\")\n",
    "#        rdf = rdf.Define(\"GLepton_SF_nom\", \"Take(Concatenate(Muon_SF_ID_nom[mu_mask]*Muon_SF_ISO_nom[mu_mask], Electron_SF_ID_nom[e_mask]*Electron_SF_EFF_nom[e_mask]), GLepton_argsort)\")\n",
    "    \n",
    "                \n",
    "    #Things that don't work...\n",
    "    #NOPE doesn't work .Define(\"nLooseGMuon\", \"Sum(Muon_looseId[mu_mask])\")\\\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineWeights(input_df, crossSection=0, sumWeights=-1, lumi=0,\n",
    "                  nEvents=-1, nEventsPositive=2, nEventsNegative=1,\n",
    "                  channel=None, isData=True, verbose=False):\n",
    "    \n",
    "    mc_def = collections.OrderedDict()\n",
    "    data_def = collections.OrderedDict()\n",
    "    mc_def[\"wgt_NUMW\"] = \"({xs:s} * {lumi:s} * 1000 * genWeight) / (abs(genWeight) * ( {nevtp:s} - {nevtn:s} ) )\"\\\n",
    "            .format(xs=str(crossSection), lumi=str(lumi), nevt=str(nEvents),\n",
    "                    nevtp=str(nEventsPositive), nevtn=str(nEventsNegative))\n",
    "    mc_def[\"wgt_SUMW\"] = \"({xs:s} * {lumi:s} * 1000 * genWeight) / {sumw:s}\"\\\n",
    "            .format(xs=str(crossSection), lumi=str(lumi), sumw=str(sumWeights))\n",
    "    mc_def[\"wgt_LSF\"] = \"(GLepton_SF_nom.size() > 1 ? GLepton_SF_nom.at(0) * GLepton_SF_nom.at(1) : GLepton_SF_nom.at(0))\"\n",
    "    mc_def[\"wgt_SUMW_PU\"] = \"wgt_SUMW * puWeight\"\n",
    "    mc_def[\"wgt_SUMW_LSF\"] = \"wgt_SUMW * wgt_LSF\"\n",
    "    mc_def[\"wgt_SUMW_L1PF\"] = \"wgt_SUMW * L1PreFiringWeight_Nom\"\n",
    "    mc_def[\"wgt_SUMW_PU_LSF\"] = \"wgt_SUMW * puWeight * wgt_LSF\"\n",
    "    mc_def[\"wgt_SUMW_PU_LSF_L1PF\"] = \"wgt_SUMW * puWeight * wgt_LSF * L1PreFiringWeight_Nom\"\n",
    "    mc_def[\"wgt_SUMW_LSF_L1PF\"] = \"wgt_SUMW * wgt_LSF * L1PreFiringWeight_Nom\"\n",
    "    mc_def[\"wgt_NUMW_LSF_L1PF\"] = \"wgt_NUMW * wgt_LSF * L1PreFiringWeight_Nom\"\n",
    "    #mc_def[\"wgt_SUMW_PU_LSF\"] = \"wgt_SUMW * puWeight * GLepton_SF_nom.at(0) * GLepton_SF_nom.at(1)\"\n",
    "    mc_def[\"SPL_SP\"] = \"wgt_SUMW_PU_LSF/wgt_SUMW_PU\"\n",
    "    mc_def[\"wgt_diff\"] = \"abs(wgt_NUMW - wgt_SUMW)/max(abs(wgt_SUMW), abs(wgt_NUMW))\"\n",
    "    for k in mc_def.keys():\n",
    "        data_def[k] = \"1\"\n",
    "    if verbose == True:\n",
    "        print(\"===data and mc weight definitions===\")\n",
    "        print(data_def)\n",
    "        print(mc_def)\n",
    "        \n",
    "    rdf = input_df\n",
    "    if isData:\n",
    "        for k, v in data_def.items():\n",
    "            rdf = rdf.Define(k, v)\n",
    "    else:\n",
    "        for k, v in mc_def.items():\n",
    "            rdf = rdf.Define(k, v)\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineJets(input_df, era=\"2017\", doAK8Jets=False, debugInfo = True, nJetsToHisto=10):\n",
    "    \"\"\"Function to take in a dataframe and return one with new columns defined,\n",
    "    plus event filtering based on the criteria defined inside the function\"\"\"\n",
    "    indexDefineCode = '''ROOT::VecOps::RVec<int> i({0}.size());\n",
    "                     std::iota(i.begin(), i.end(), 0);\n",
    "                     return i;'''\n",
    "    bTagWorkingPointDict = {\n",
    "        '2016':{\n",
    "            'DeepCSV':{'L': 0.2217, 'M': 0.6321, 'T': 0.8953, 'Var': 'btagDeepB'},\n",
    "            'DeepJet':{ 'L': 0.0614, 'M': 0.3093, 'T': 0.7221, 'Var': 'btagDeepFlavB'}\n",
    "        },\n",
    "        '2017':{\n",
    "            'CSVv2':{'L': 0.5803, 'M': 0.8838, 'T': 0.9693, 'Var': 'btagCSVV2'},\n",
    "            'DeepCSV':{'L': 0.1522, 'M': 0.4941, 'T': 0.8001, 'Var': 'btagDeepB'},\n",
    "            'DeepJet':{'L': 0.0521, 'M': 0.3033, 'T': 0.7489, 'Var': 'btagDeepFlavB'}\n",
    "        },\n",
    "        '2018':{\n",
    "            'DeepCSV':{'L': 0.1241, 'M': 0.4184, 'T': 0.7527, 'Var': 'btagDeepB'},\n",
    "            'DeepJet':{'L': 0.0494, 'M': 0.2770, 'T': 0.7264, 'Var': 'btagDeepFlavB'}\n",
    "        }\n",
    "    }\n",
    "    print(\"FIXMEFIXME: Setting Jet_pt min to 30GeV! Must fix!\")\n",
    "    rdf = input_df\n",
    "    rdf = rdf.Define(\"jet_maskALT\", \"(Jet_OSV_baseline & {0}) > {0}\".format(23))\n",
    "    rdf = rdf.Define(\"jet_submask\", \"(Jet_pt >= 30 && abs(Jet_eta) <= 2.5 && Jet_jetId > 2)\")\n",
    "    rdf = rdf.Define(\"Jet_idx\", indexDefineCode.format(\"Jet_pt\"))\n",
    "    rdf = rdf.Define(\"jet_mask\", \"(jet_submask && Jet_idx != GLepton_jetIdx_0 && Jet_idx != GLepton_jetIdx_1)\")\n",
    "    rdf = rdf.Define(\"jet_ptsort\", \"Reverse(Argsort(Jet_pt[jet_mask]))\")\n",
    "    rdf = rdf.Define(\"jet_deepcsvsort\", \"Reverse(Argsort(Jet_{0}[jet_mask]))\".format(bTagWorkingPointDict[era][\"DeepCSV\"][\"Var\"]))\n",
    "    rdf = rdf.Define(\"jet_deepjetsort\", \"Reverse(Argsort(Jet_{0}[jet_mask]))\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"]))\n",
    "    rdf = rdf.Define(\"GJet_idx\", \"Jet_idx[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_pt\", \"Jet_pt[jet_mask]\")\n",
    "    for x in xrange(nJetsToHisto):\n",
    "        rdf = rdf.Define(\"GJet_pt_jet{}\".format(x+1), \"GJet_pt.size() > {} ? GJet_pt.at({}) : -9999\".format(x, x))\n",
    "    rdf = rdf.Define(\"GJet_eta\", \"Jet_eta[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_phi\", \"Jet_phi[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_mass\", \"Jet_mass[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_jetId\", \"Jet_jetId[jet_mask]\")\n",
    "    rdf = rdf.Define(\"nGJet\", \"GJet_pt.size()\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepB\", \"Jet_btagDeepB[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepB_LeadtagJet\", \"GJet_btagDeepB.size() > 0 ? Reverse(Sort(GJet_btagDeepB)).at(0) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepB_SubleadtagJet\", \"GJet_btagDeepB.size() > 1 ? Reverse(Sort(GJet_btagDeepB)).at(1) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepFlavB\", \"Jet_btagDeepFlavB[jet_mask]\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepFlavB_sorted\", \"Take(Jet_btagDeepFlavB[jet_mask], jet_deepjetsort)\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepFlavB_sorted_LeadtagJet\", \"GJet_btagDeepFlavB_sorted.size() > 0 ? GJet_btagDeepFlavB_sorted.at(0) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GJet_btagDeepFlavB_sorted_SubleadtagJet\", \"GJet_btagDeepFlavB_sorted.size() > 1 ? GJet_btagDeepFlavB_sorted.at(1) : -0.000000000001\")\n",
    "    rdf = rdf.Define(\"GJet_MediumDeepCSV\", \"GJet_{0}[GJet_{0} > {1}]\".format(bTagWorkingPointDict[era][\"DeepCSV\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepCSV\"][\"M\"]))\n",
    "    rdf = rdf.Define(\"nGJet_MediumDeepCSV\", \"GJet_MediumDeepCSV.size()\")\n",
    "    rdf = rdf.Define(\"GJet_MediumDeepJet\", \"GJet_{0}[GJet_{0} > {1}]\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepJet\"][\"M\"]))\n",
    "    rdf = rdf.Define(\"nGJet_MediumDeepJet\", \"GJet_MediumDeepJet.size()\")\n",
    "    #These might be more efficiently calculated with my own custom code, instead of this... well, lets try for the sake of experimentation\n",
    "    #HT is just the sum of good jet pts\n",
    "    # HT2M is the sum of jet pt's for all but the two highest-b-tagged jets (2016 analysis requires 4+ jets to define this quantity), so here Take() is used twice.\n",
    "    # The first call acquires the good jet pt's sorted by b-tagging, the senond Take() gets the last n-2 elements, thereby excluding the two highest b-tagged jet's pt\n",
    "    # HTRat = HT(two highest b-tagged) / HT, so it's useful to define this similarly to HT2M (and crosscheck that HTNum + HT2M = HT!)\n",
    "    # H and H2M are defined similarly for the overall momentum magnitude...\n",
    "    # P = pt/sin(theta) = pt * (1/sin(theta)) = pt * cosh(eta)\n",
    "    rdf = rdf.Define(\"GJet_HT\", \"Sum(GJet_pt)\")\n",
    "    rdf = rdf.Define(\"GJet_pt_bsrt\", \"Take(GJet_pt, jet_deepjetsort)\")\n",
    "    rdf = rdf.Define(\"GJet_eta_bsrt\", \"Take(GJet_eta, jet_deepjetsort)\")\n",
    "    rdf = rdf.Define(\"GJet_phi_bsrt\", \"Take(GJet_phi, jet_deepjetsort)\")\n",
    "    rdf = rdf.Define(\"GJet_P_bsrt\", \"GJet_pt_bsrt * ROOT::VecOps::cosh(GJet_eta_bsrt)\")\n",
    "    rdf = rdf.Define(\"GJet_HT2M\", \"GJet_pt_bsrt.size() > 2 ? Sum(Take(GJet_pt_bsrt, (2 - GJet_pt_bsrt.size()))) : -0.1\")\n",
    "    rdf = rdf.Define(\"GJet_HTNum\", \"GJet_pt_bsrt.size() > 2 ? Sum(Take(GJet_pt_bsrt, 2)) : -0.1\")\n",
    "    rdf = rdf.Define(\"GJet_HTRat\", \"GJet_pt_bsrt.size() > 2 ? (GJet_HT2M / GJet_HT) : -0.1\")\n",
    "    rdf = rdf.Define(\"GJet_dRbb\", \"GJet_pt_bsrt.size() > 2 ? ROOT::VecOps::DeltaR(GJet_eta_bsrt.at(0), GJet_eta_bsrt.at(1), GJet_phi_bsrt.at(0), GJet_phi_bsrt.at(1)) : -0.1\")\n",
    "    rdf = rdf.Define(\"GJet_dPhibb\", \"GJet_pt_bsrt.size() > 2 ? ROOT::VecOps::DeltaPhi(GJet_phi_bsrt.at(0), GJet_phi_bsrt.at(1)) : -999\")\n",
    "    rdf = rdf.Define(\"GJet_dEtabb\", \"GJet_pt_bsrt.size() > 2 ? abs(GJet_eta_bsrt.at(0) - GJet_eta_bsrt.at(1)) : -999\")\n",
    "    rdf = rdf.Define(\"GJet_H\", \"Sum(GJet_P_bsrt)\")\n",
    "    rdf = rdf.Define(\"GJet_H2M\", \"GJet_pt_bsrt.size() > 2 ? Sum(Take(GJet_P_bsrt, (2 - GJet_pt_bsrt.size()))) : -0.1\")\n",
    "    rdf = rdf.Define(\"GJet_HTH\", \"GJet_HT/GJet_H\")\n",
    "    rdf = rdf.Define(\"GJet_HTb\", \"Sum(GJet_pt[GJet_{0} > {1}])\".format(bTagWorkingPointDict[era][\"DeepJet\"][\"Var\"],\n",
    "                                                                                bTagWorkingPointDict[era][\"DeepJet\"][\"M\"]))\n",
    "    if debugInfo == True:\n",
    "        rdf = rdf.Define(\"GJet_ptALT\", \"Jet_pt[jet_maskALT]\")\n",
    "        rdf = rdf.Define(\"GJet_etaALT\", \"Jet_eta[jet_maskALT]\")\n",
    "        rdf = rdf.Define(\"GJet_phiALT\", \"Jet_phi[jet_maskALT]\")\n",
    "        rdf = rdf.Define(\"GJet_massALT\", \"Jet_mass[jet_maskALT]\")\n",
    "        rdf = rdf.Define(\"GJet_jetIdALT\", \"Jet_jetId[jet_maskALT]\")\n",
    "        rdf = rdf.Define(\"DiffMaskVsALT\", \"GJet_ptALT.size() - GJet_pt.size()\")\n",
    "        rdf = rdf.Define(\"DiffnJet\", \"nGJet - ESV_JetMETLogic_nJet_selection\")\n",
    "        rdf = rdf.Define(\"dR_Jet_Mu_leading\", \"GLepton_jetIdx_0 > -1 && abs(GLepton_pdgId.at(0)) == 13 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_0), GLepton_eta.at(0), Jet_phi.at(GLepton_jetIdx_0), GLepton_phi.at(0)) : -0.01\")\n",
    "        rdf = rdf.Define(\"dR_Jet_Mu_sublead\", \"GLepton_jetIdx_1 > -1 && abs(GLepton_pdgId.at(1)) == 13 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_1), GLepton_eta.at(1), Jet_phi.at(GLepton_jetIdx_1), GLepton_phi.at(1)) : -0.01\")\n",
    "        rdf = rdf.Define(\"dR_Jet_El_leading\", \"GLepton_jetIdx_0 > -1 && abs(GLepton_pdgId.at(1)) == 11 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_0), GLepton_eta.at(0), Jet_phi.at(GLepton_jetIdx_0), GLepton_phi.at(0)) : -0.01\")\n",
    "        rdf = rdf.Define(\"dR_Jet_El_sublead\", \"GLepton_jetIdx_1 > -1 && abs(GLepton_pdgId.at(1)) == 11 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_1), GLepton_eta.at(1), Jet_phi.at(GLepton_jetIdx_1), GLepton_phi.at(1)) : -0.01\")\n",
    "        #rdf = rdf.Define(\"dR_Jet_lep0\", \"GLepton_jetIdx_0 > -1 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_0), GLepton_eta.at(0), Jet_phi.at(GLepton_jetIdx_0), GLepton_phi.at(0)) : -0.01\")\n",
    "        #rdf = rdf.Define(\"dR_Jet_lep1\", \"GLepton_jetIdx_1 > -1 ? ROOT::VecOps::DeltaR(Jet_eta.at(GLepton_jetIdx_1), GLepton_eta.at(1), Jet_phi.at(GLepton_jetIdx_1), GLepton_phi.at(1)) : -0.01\")\n",
    "        rdf = rdf.Define(\"GJet_btagDeepFlavB_jet0Med\", \"GJet_MediumDeepJet.size() > 0 ? Reverse(Sort(GJet_MediumDeepJet)).at(0) : -0.000000000001\")\n",
    "        rdf = rdf.Define(\"GJet_btagDeepFlavB_jet1Med\", \"GJet_MediumDeepJet.size() > 1 ? Reverse(Sort(GJet_MediumDeepJet)).at(1) : -0.000000000001\")\n",
    "        rdf = rdf.Define(\"DeepJetSorted\", \"GJet_btagDeepFlavB_sorted.size() > 1 ? (GJet_btagDeepFlavB_sorted.at(0) >= GJet_btagDeepFlavB_sorted.at(1)) : true\")\n",
    "        rdf = rdf.Define(\"DeepJet0Minus1\", \"GJet_btagDeepFlavB_sorted.size() > 1 ? (GJet_btagDeepFlavB_sorted.at(0) - GJet_btagDeepFlavB_sorted.at(1)) : 0\")\n",
    "        rdf = rdf.Define(\"MediumDeepJetSorted\", \"GJet_MediumDeepJet.size() > 1 ? (Reverse(Sort(GJet_MediumDeepJet)).at(0) >= Reverse(Sort(GJet_MediumDeepJet)).at(1)) : true\")\n",
    "        rdf = rdf.Define(\"MediumDeepJet0Minus1\", \"GJet_MediumDeepJet.size() > 1 ? (Reverse(Sort(GJet_MediumDeepJet)).at(0) - Reverse(Sort(GJet_MediumDeepJet)).at(1)) : 0\")\n",
    "    return rdf\n",
    "    #Code taht doesn't work...\n",
    "    #Can see that the jets are in fact not sorted when calling Reverse(GJet_MediumDeepJet).at(0), for example, as the one .at(1) can sometimes not be smaller\n",
    "    #Looking at the definition makes it obvious, because Reverse is not short for \"ReverseSort\" but is literally just std::reverse. Must call (Arg)sort first...\n",
    "    #Definig a functor in the string like this doesn't work either:\n",
    "    #.Define(\"GJet_btagDeepB_jet0\", \"GJet_btagDeepB.size() > 0 ? Sort(GJet_btagDeepB, [](double x, double y) {return x > y;}).at(0) : -0.000000000001\")\\\n",
    "    #Cannot use ternary operator with RVec and double return types (Take(...) : -0.0000000001)\n",
    "    #.Define(\"GJet_btagDeepFlavB_jet0\", \"GJet_btagDeepFlavB.size() > 0 ? Take(Reverse(GJet_btagDeepFlavB), {0}) : -0.000000000001\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MET_corrections(input_df, uncormet_pt_branch = \"METFixEE2017_pt\", uncormet_phi_branch = \"METFixEE2017_phi\", \n",
    "                    run_branch = \"run\", year = \"2017\", isMC = False, npv_branch = \"\"):\n",
    "    MET_CorrXY_Code = '''\n",
    "enum TheRunEra{y2016B,y2016C,y2016D,y2016E,y2016F,y2016G,y2016H,y2017B,y2017C,y2017D,y2017E,y2017F,y2018A,y2018B,y2018C,y2018D,y2016MC,y2017MC,y2018MC};\n",
    "\n",
    "std::pair<double,double> METXYCorr_Met_MetPhi(double uncormet, double uncormet_phi, int runnb, int year, bool isMC, int npv){\n",
    "\n",
    "  std::pair<double,double>  TheXYCorr_Met_MetPhi(uncormet,uncormet_phi);\n",
    "  \n",
    "  if(npv>100) npv=100;\n",
    "  int runera =-1;\n",
    "  bool usemetv2 =false;\n",
    "  if(isMC && year == 2016) runera = y2016MC;\n",
    "  else if(isMC && year == 2017) {runera = y2017MC; usemetv2 =true;}\n",
    "  else if(isMC && year == 2018) runera = y2018MC;\n",
    "  \n",
    "  else if(!isMC && runnb >=272007 &&runnb<=275376  ) runera = y2016B;\n",
    "  else if(!isMC && runnb >=275657 &&runnb<=276283  ) runera = y2016C;\n",
    "  else if(!isMC && runnb >=276315 &&runnb<=276811  ) runera = y2016D;\n",
    "  else if(!isMC && runnb >=276831 &&runnb<=277420  ) runera = y2016E;\n",
    "  else if(!isMC && runnb >=277772 &&runnb<=278808  ) runera = y2016F;\n",
    "  else if(!isMC && runnb >=278820 &&runnb<=280385  ) runera = y2016G;\n",
    "  else if(!isMC && runnb >=280919 &&runnb<=284044  ) runera = y2016H;\n",
    "  \n",
    "  else if(!isMC && runnb >=297020 &&runnb<=299329 ){ runera = y2017B; usemetv2 =true;}\n",
    "  else if(!isMC && runnb >=299337 &&runnb<=302029 ){ runera = y2017C; usemetv2 =true;}\n",
    "  else if(!isMC && runnb >=302030 &&runnb<=303434 ){ runera = y2017D; usemetv2 =true;}\n",
    "  else if(!isMC && runnb >=303435 &&runnb<=304826 ){ runera = y2017E; usemetv2 =true;}\n",
    "  else if(!isMC && runnb >=304911 &&runnb<=306462 ){ runera = y2017F; usemetv2 =true;}\n",
    "  \n",
    "  else if(!isMC && runnb >=315252 &&runnb<=316995 ) runera = y2018A;\n",
    "  else if(!isMC && runnb >=316998 &&runnb<=319312 ) runera = y2018B;\n",
    "  else if(!isMC && runnb >=319313 &&runnb<=320393 ) runera = y2018C;\n",
    "  else if(!isMC && runnb >=320394 &&runnb<=325273 ) runera = y2018D;\n",
    "\n",
    "  else {\n",
    "    //Couldn't find data/MC era => no correction applied\n",
    "    return TheXYCorr_Met_MetPhi;\n",
    "  }\n",
    "  \n",
    "  double METxcorr(0.),METycorr(0.);\n",
    "\n",
    "  if(!usemetv2){//Current recommendation for 2016 and 2018\n",
    "    if(runera==y2016B) METxcorr = -(-0.0478335*npv -0.108032);\n",
    "    if(runera==y2016B) METycorr = -(0.125148*npv +0.355672);\n",
    "    if(runera==y2016C) METxcorr = -(-0.0916985*npv +0.393247);\n",
    "    if(runera==y2016C) METycorr = -(0.151445*npv +0.114491);\n",
    "    if(runera==y2016D) METxcorr = -(-0.0581169*npv +0.567316);\n",
    "    if(runera==y2016D) METycorr = -(0.147549*npv +0.403088);\n",
    "    if(runera==y2016E) METxcorr = -(-0.065622*npv +0.536856);\n",
    "    if(runera==y2016E) METycorr = -(0.188532*npv +0.495346);\n",
    "    if(runera==y2016F) METxcorr = -(-0.0313322*npv +0.39866);\n",
    "    if(runera==y2016F) METycorr = -(0.16081*npv +0.960177);\n",
    "    if(runera==y2016G) METxcorr = -(0.040803*npv -0.290384);\n",
    "    if(runera==y2016G) METycorr = -(0.0961935*npv +0.666096);\n",
    "    if(runera==y2016H) METxcorr = -(0.0330868*npv -0.209534);\n",
    "    if(runera==y2016H) METycorr = -(0.141513*npv +0.816732);\n",
    "    if(runera==y2017B) METxcorr = -(-0.259456*npv +1.95372);\n",
    "    if(runera==y2017B) METycorr = -(0.353928*npv -2.46685);\n",
    "    if(runera==y2017C) METxcorr = -(-0.232763*npv +1.08318);\n",
    "    if(runera==y2017C) METycorr = -(0.257719*npv -1.1745);\n",
    "    if(runera==y2017D) METxcorr = -(-0.238067*npv +1.80541);\n",
    "    if(runera==y2017D) METycorr = -(0.235989*npv -1.44354);\n",
    "    if(runera==y2017E) METxcorr = -(-0.212352*npv +1.851);\n",
    "    if(runera==y2017E) METycorr = -(0.157759*npv -0.478139);\n",
    "    if(runera==y2017F) METxcorr = -(-0.232733*npv +2.24134);\n",
    "    if(runera==y2017F) METycorr = -(0.213341*npv +0.684588);\n",
    "    if(runera==y2018A) METxcorr = -(0.362865*npv -1.94505);\n",
    "    if(runera==y2018A) METycorr = -(0.0709085*npv -0.307365);\n",
    "    if(runera==y2018B) METxcorr = -(0.492083*npv -2.93552);\n",
    "    if(runera==y2018B) METycorr = -(0.17874*npv -0.786844);\n",
    "    if(runera==y2018C) METxcorr = -(0.521349*npv -1.44544);\n",
    "    if(runera==y2018C) METycorr = -(0.118956*npv -1.96434);\n",
    "    if(runera==y2018D) METxcorr = -(0.531151*npv -1.37568);\n",
    "    if(runera==y2018D) METycorr = -(0.0884639*npv -1.57089);\n",
    "    if(runera==y2016MC) METxcorr = -(-0.195191*npv -0.170948);\n",
    "    if(runera==y2016MC) METycorr = -(-0.0311891*npv +0.787627);\n",
    "    if(runera==y2017MC) METxcorr = -(-0.217714*npv +0.493361);\n",
    "    if(runera==y2017MC) METycorr = -(0.177058*npv -0.336648);\n",
    "    if(runera==y2018MC) METxcorr = -(0.296713*npv -0.141506);\n",
    "    if(runera==y2018MC) METycorr = -(0.115685*npv +0.0128193);\n",
    "  }\n",
    "  else {//these are the corrections for v2 MET recipe (currently recommended for 2017)\n",
    "    if(runera==y2016B) METxcorr = -(-0.0374977*npv +0.00488262);\n",
    "    if(runera==y2016B) METycorr = -(0.107373*npv +-0.00732239);\n",
    "    if(runera==y2016C) METxcorr = -(-0.0832562*npv +0.550742);\n",
    "    if(runera==y2016C) METycorr = -(0.142469*npv +-0.153718);\n",
    "    if(runera==y2016D) METxcorr = -(-0.0400931*npv +0.753734);\n",
    "    if(runera==y2016D) METycorr = -(0.127154*npv +0.0175228);\n",
    "    if(runera==y2016E) METxcorr = -(-0.0409231*npv +0.755128);\n",
    "    if(runera==y2016E) METycorr = -(0.168407*npv +0.126755);\n",
    "    if(runera==y2016F) METxcorr = -(-0.0161259*npv +0.516919);\n",
    "    if(runera==y2016F) METycorr = -(0.141176*npv +0.544062);\n",
    "    if(runera==y2016G) METxcorr = -(0.0583851*npv +-0.0987447);\n",
    "    if(runera==y2016G) METycorr = -(0.0641427*npv +0.319112);\n",
    "    if(runera==y2016H) METxcorr = -(0.0706267*npv +-0.13118);\n",
    "    if(runera==y2016H) METycorr = -(0.127481*npv +0.370786);\n",
    "    if(runera==y2017B) METxcorr = -(-0.19563*npv +1.51859);\n",
    "    if(runera==y2017B) METycorr = -(0.306987*npv +-1.84713);\n",
    "    if(runera==y2017C) METxcorr = -(-0.161661*npv +0.589933);\n",
    "    if(runera==y2017C) METycorr = -(0.233569*npv +-0.995546);\n",
    "    if(runera==y2017D) METxcorr = -(-0.180911*npv +1.23553);\n",
    "    if(runera==y2017D) METycorr = -(0.240155*npv +-1.27449);\n",
    "    if(runera==y2017E) METxcorr = -(-0.149494*npv +0.901305);\n",
    "    if(runera==y2017E) METycorr = -(0.178212*npv +-0.535537);\n",
    "    if(runera==y2017F) METxcorr = -(-0.165154*npv +1.02018);\n",
    "    if(runera==y2017F) METycorr = -(0.253794*npv +0.75776);\n",
    "    if(runera==y2018A) METxcorr = -(0.362642*npv +-1.55094);\n",
    "    if(runera==y2018A) METycorr = -(0.0737842*npv +-0.677209);\n",
    "    if(runera==y2018B) METxcorr = -(0.485614*npv +-2.45706);\n",
    "    if(runera==y2018B) METycorr = -(0.181619*npv +-1.00636);\n",
    "    if(runera==y2018C) METxcorr = -(0.503638*npv +-1.01281);\n",
    "    if(runera==y2018C) METycorr = -(0.147811*npv +-1.48941);\n",
    "    if(runera==y2018D) METxcorr = -(0.520265*npv +-1.20322);\n",
    "    if(runera==y2018D) METycorr = -(0.143919*npv +-0.979328);\n",
    "    if(runera==y2016MC) METxcorr = -(-0.159469*npv +-0.407022);\n",
    "    if(runera==y2016MC) METycorr = -(-0.0405812*npv +0.570415);\n",
    "    if(runera==y2017MC) METxcorr = -(-0.182569*npv +0.276542);\n",
    "    if(runera==y2017MC) METycorr = -(0.155652*npv +-0.417633);\n",
    "    if(runera==y2018MC) METxcorr = -(0.299448*npv +-0.13866);\n",
    "    if(runera==y2018MC) METycorr = -(0.118785*npv +0.0889588);\n",
    "  }\n",
    "\n",
    "  double CorrectedMET_x = uncormet *cos( uncormet_phi)+METxcorr;\n",
    "  double CorrectedMET_y = uncormet *sin( uncormet_phi)+METycorr;\n",
    "\n",
    "  double CorrectedMET = sqrt(CorrectedMET_x*CorrectedMET_x+CorrectedMET_y*CorrectedMET_y);\n",
    "  double CorrectedMETPhi;\n",
    "  if(CorrectedMET_x==0 && CorrectedMET_y>0) CorrectedMETPhi = TMath::Pi();\n",
    "  else if(CorrectedMET_x==0 && CorrectedMET_y<0 )CorrectedMETPhi = -TMath::Pi();\n",
    "  else if(CorrectedMET_x >0) CorrectedMETPhi = TMath::ATan(CorrectedMET_y/CorrectedMET_x);\n",
    "  else if(CorrectedMET_x <0&& CorrectedMET_y>0) CorrectedMETPhi = TMath::ATan(CorrectedMET_y/CorrectedMET_x) + TMath::Pi();\n",
    "  else if(CorrectedMET_x <0&& CorrectedMET_y<0) CorrectedMETPhi = TMath::ATan(CorrectedMET_y/CorrectedMET_x) - TMath::Pi();\n",
    "  else CorrectedMETPhi =0;\n",
    "\n",
    "  TheXYCorr_Met_MetPhi.first= CorrectedMET;\n",
    "  TheXYCorr_Met_MetPhi.second= CorrectedMETPhi;\n",
    "  return TheXYCorr_Met_MetPhi;\n",
    "\n",
    "}\n",
    "'''\n",
    "    #rdf = input_df\n",
    "    #rdf = rdf.Define()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineEventVars(input_df):\n",
    "    rdf = input_df\n",
    "    rdf = rdf.Define(\"JML_baseline_pass\", \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00001100011111111111))\n",
    "    rdf = rdf.Define(\"JML_selection_pass\", \"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00001100011111111111))\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillHistos(input_df, input_name=None, wgtVar=\"wgt_SUMW\", isData = True, histos1D_dict=None, histos2D_dict=None, histosNS_dict=None, \n",
    "               doMuons=False, doElectrons=False, doLeptons=False, doJets=False, doWeights=False, doEventVars=False, \n",
    "               makeMountains=False, debugInfo=True, nJetsToHisto=10):\n",
    "    \"\"\"Method to fill histograms given an input RDataFrame, input sample/dataset name, input histogram dictionaries.\n",
    "    Has several options of which histograms to fill, such as Leptons, Jets, Weights, EventVars, etc.\n",
    "    Types of histograms (1D, 2D, those which will not be stacked(NS - histosNS)) are filled by passing non-None\n",
    "    value to that histosXX_dict variable. Internally stored with structure separating the categories of histos,\n",
    "    with 'Muons,' 'Electrons,' 'Leptons,' 'Jets,' 'EventVars,' 'Weights' subcategories.\"\"\"\n",
    "    if doMuons == False and doElectrons == False and doLeptons == False\\\n",
    "                and doJets==False and doWeights==False and doEventVars==False:\n",
    "        raise RuntimeError(\"Must select something to plot:\"\\\n",
    "                               \"Set do{Muons,Electrons,Leptons,Jets,Weights,EventVars,etc} = True in init method\")\n",
    "    \n",
    "    pi = ROOT.TMath.Pi()\n",
    "    if doWeights == True:\n",
    "        if histosNS_dict != None:\n",
    "            if \"EventVars\" not in histosNS_dict:\n",
    "                histosNS_dict[\"EventVars\"] = {}\n",
    "            histosNS[name][lvl][\"EventVars\"][\"wgt_NUMW\"] = input_df.Histo1D(\"wgt_NUMW\")\n",
    "            histosNS[name][lvl][\"EventVars\"][wgtVar] = input_df.Histo1D(wgtVar)\n",
    "        if histos1D_dict != None:\n",
    "            if \"EventVars\" not in histos1D_dict:\n",
    "                histos1D_dict[\"EventVars\"] = {}\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_diff\"] = input_df.Histo1D((\"wgt_diff\", \"(wgt_NUMW - wgt_SUMW)/wgt_SUMW\", 2000, -1, 1), \"wgt_diff\", \"1\")\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_PU\"] = input_df.Histo1D((\"wgt_PU\", \"\", 2000, 0, 5), \"puWeight\", \"wgt_SUMW\")\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_LSF\"] = input_df.Histo1D((\"wgt_LSF\", \"\", 2000, 0, 5), \"wgt_LSF\", \"wgt_SUMW\")\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_L1PF\"] = input_df.Histo1D((\"wgt_L1PF\", \"\", 2000, 0, 5), \"L1PreFiringWeight_Nom\", \"wgt_SUMW\")\n",
    "            histos1D_dict[\"EventVars\"][\"wgt_PU_LSF_L1PF\"] = input_df.Histo1D((\"wgt_PU_LSF_L1PF\", \"\", 2000, 0, 5), \"wgt_PU_LSF_L1PF\", \"wgt_SUMW\")\n",
    "    if doMuons == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Muons\" not in histos1D_dict: \n",
    "                histos1D_dict[\"Muons\"] = {}\n",
    "            histos1D_dict[\"Muons\"][\"idx\"] = input_df.Histo1D((\"idx_({})\".format(wgtVar), \"\", 5, 0, 5), \"Muon_idx\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"Gidx\"] = input_df.Histo1D((\"Gidx_({})\".format(wgtVar), \"\", 5, 0, 5), \"GMuon_idx\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"nMu\"] = input_df.Histo1D((\"nMuon_({})\".format(wgtVar), \"\", 5, 0, 5), \"nGMuon\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"nLooseMu\"] = input_df.Histo1D((\"nLooseMuon_({})\".format(wgtVar), \"\", 5, 0, 5), \"nLooseGMuon\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"nMediumMu\"] = input_df.Histo1D((\"nMediumMuon_({})\".format(wgtVar), \"\", 5, 0, 5), \"nMediumGMuon\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"pt\"] = input_df.Histo1D((\"Muon_pt_({})\".format(wgtVar), \"\", 100, 0, 500), \"GMuon_pt\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"eta\"] = input_df.Histo1D((\"Muon_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GMuon_eta\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"phi\"] = input_df.Histo1D((\"Muon_phi_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GMuon_phi\", wgtVar)\n",
    "            #histos1D_dict[\"Muons\"][\"mass\"] = input_df.Histo1D((\"Muon_mass_({})\".format(wgtVar), \"\", 50, 0, 1), \"GMuon_mass\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"iso\"] = input_df.Histo1D((\"Muon_iso_({})\".format(wgtVar), \"\", 8, 0, 8), \"GMuon_pfIsoId\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"dz\"] = input_df.Histo1D((\"Muon_dz_({})\".format(wgtVar), \"\", 100, -0.01, 0.01), \"GMuon_dz\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"dxy\"] = input_df.Histo1D((\"Muon_dxy_({})\".format(wgtVar), \"\", 100, -0.1, 0.1), \"GMuon_dxy\", wgtVar)\n",
    "            #histos1D_dict[\"Muons\"][\"d0\"] = input_df.Histo1D((\"Muon_d0_({})\".format(wgtVar), \"\", 100, -0.01, 0.01), \"GMuon_d0\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"ip3d\"] = input_df.Histo1D((\"Muon_ip3d_({})\".format(wgtVar), \"\", 100, 0, 0.01), \"GMuon_ip3d\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"pfRelIso03_all\"] = input_df.Histo1D((\"Muon_pfRelIso03_all_({})\".format(wgtVar), \"\", 100, 0, 0.2), \"GMuon_pfRelIso03_all\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"pfRelIso03_chg\"] = input_df.Histo1D((\"Muon_pfRelIso03_chg_({})\".format(wgtVar), \"\", 100, 0, 0.2), \"GMuon_pfRelIso03_chg\", wgtVar)\n",
    "            histos1D_dict[\"Muons\"][\"pfRelIso04_all\"] = input_df.Histo1D((\"Muon_pfRelIso04_all_({})\".format(wgtVar), \"\", 100, 0, 0.2), \"GMuon_pfRelIso04_all\", wgtVar)\n",
    "        if histos2D_dict != None:\n",
    "            if \"Muons\" not in histos2D_dict:\n",
    "                histos2D_dict[\"Muons\"] = {}\n",
    "            histos2D_dict[\"Muons\"][\"eta_phi\"] = input_df.Histo2D((\"Muon_eta_phi_({})\".format(wgtVar), \"\",\n",
    "                                                                  104, -2.6, 2.6,\n",
    "                                                                  64, -pi, pi),\n",
    "                                                                 \"GMuon_eta\", \"GMuon_phi\", wgtVar)\n",
    "            histos2D_dict[\"Muons\"][\"dz_ip3d\"] = input_df.Histo2D((\"Muon_dz_ip3d_({})\".format(wgtVar), \"\",\n",
    "                                                                  100, -0.01, 0.01,\n",
    "                                                                  100, 0, 0.01),\n",
    "                                                                 \"GMuon_dz\", \"GMuon_ip3d\", wgtVar)\n",
    "    if doElectrons == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Electrons\" not in histos1D_dict: \n",
    "                histos1D_dict[\"Electrons\"] = {}\n",
    "            histos1D_dict[\"Electrons\"][\"nEl\"] = input_df.Histo1D((\"nElectron_({})\".format(wgtVar), \"\", 5, 0, 5), \"nGElectron\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"nLooseEl\"] = input_df.Histo1D((\"nLooseElectron_({})\".format(wgtVar), \"\", 5, 0, 5), \"nLooseGElectron\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"nMediumEl\"] = input_df.Histo1D((\"nMediumElectron_({})\".format(wgtVar), \"\", 5, 0, 5), \"nMediumGElectron\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"pt\"] = input_df.Histo1D((\"Electron_pt_({})\".format(wgtVar), \"\", 100, 0, 500), \"GElectron_pt\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"eta\"] = input_df.Histo1D((\"Electron_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GElectron_eta\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"phi\"] = input_df.Histo1D((\"Electron_phi_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GElectron_phi\", wgtVar)\n",
    "            #histos1D_dict[\"Electrons\"][\"mass\"] = input_df.Histo1D((\"Electron_mass_({})\".format(wgtVar), \"\", 50, 0, 1), \"GElectron_mass\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"dz\"] = input_df.Histo1D((\"Electron_dz_({})\".format(wgtVar), \"\", 100, -0.01, 0.01), \"GElectron_dz\", wgtVar)\n",
    "            #histos1D_dict[\"Electrons\"][\"d0\"] = input_df.Histo1D((\"Electron_d0_({})\".format(wgtVar), \"\", 100, 0, 0.01), \"GElectron_d0\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"ip3d\"] = input_df.Histo1D((\"Electron_ip3d_({})\".format(wgtVar), \"\", 100, 0, 0.01), \"GElectron_ip3d\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"pfRelIso03_all\"] = input_df.Histo1D((\"Electron_pfRelIso03_all_({})\".format(wgtVar), \"\", 100, 0, 0.2), \"GElectron_pfRelIso03_all\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"pfRelIso03_chg\"] = input_df.Histo1D((\"Electron_pfRelIso03_chg_({})\".format(wgtVar), \"\", 100, 0, 0.2), \"GElectron_pfRelIso03_chg\", wgtVar)\n",
    "            histos1D_dict[\"Electrons\"][\"cutBased\"] = input_df.Histo1D((\"Electron_cutBased_({})\".format(wgtVar), \"\", 5, 0, 5), \"GElectron_cutBased\", wgtVar)\n",
    "        if histos2D_dict != None:\n",
    "            if \"Electrons\" not in histos2D_dict: \n",
    "                histos2D_dict[\"Electrons\"] = {}\n",
    "            histos2D_dict[\"Electrons\"][\"eta_phi\"] = input_df.Histo2D((\"Electron_eta_phi_({})\".format(wgtVar), \"\",\n",
    "                                                                      104, -2.6, 2.6,\n",
    "                                                                      64, -pi, pi),\n",
    "                                                                     \"GElectron_eta\", \"GElectron_phi\", wgtVar)\n",
    "            histos2D_dict[\"Electrons\"][\"dz_ip3d\"] = input_df.Histo2D((\"Electron_dz_ip3d_({})\".format(wgtVar), \"\",\n",
    "                                                                      100, -0.01, 0.01,\n",
    "                                                                      100, 0, 0.01),\n",
    "                                                                     \"GElectron_dz\", \"GElectron_ip3d\", wgtVar)\n",
    "    if doLeptons == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Leptons\" not in histos1D_dict: \n",
    "                histos1D_dict[\"Leptons\"] = {}\n",
    "            histos1D_dict[\"Leptons\"][\"pt_LeadLep\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_pt_LeadLep_({})\".format(wgtVar), \"\", 100, 0, 500),\"GLepton_pt_LeadLep\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"pt_SubleadLep\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_pt_SubleadLep_({})\".format(wgtVar), \"\", 100, 0, 500),\"GLepton_pt_SubleadLep\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"eta\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6),\"GLepton_eta\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"phi\"] = input_df\\\n",
    "                    .Histo1D((\"GLepton_phi_({})\".format(wgtVar), \"\", 64, -pi, pi),\"GLepton_phi\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"nLepton\"] = input_df\\\n",
    "                    .Histo1D((\"nLepton_({})\".format(wgtVar), \"\", 5, 0, 5), \"nGLepton\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"pdgId\"] = input_df\\\n",
    "                    .Histo1D((\"Lepton_pdgId_({})\".format(wgtVar), \"\", 32, -16, 16), \"GLepton_pdgId\", wgtVar)\n",
    "            histos1D_dict[\"Leptons\"][\"jetIdx\"] = input_df\\\n",
    "                    .Histo1D((\"Lepton_jetIdx_({})\".format(wgtVar), \"\", 20, 0, 20), \"GLepton_jetIdx\", wgtVar)\n",
    "            #histos1D_dict[\"Leptons\"][\"LepSF\"] = input_df\\\n",
    "            #        .Histo1D((\"Lepton_SF_({})\".format(\"wgt_SUMW_PU:HARDCODED\"), \"\", 100, 0.93, 1.03), \"GLepton_SF_nom\", \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"LSF\"] = input_df\\\n",
    "            #        .Histo1D((\"LSF_({})\".format(\"wgt_SUMW_PU:HARDCODED\"), \"\", 200, 0.80, 1.1), \"wgt_LSF\", \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"SPL_SP\"] = input_df\\\n",
    "            #        .Histo1D((\"SPL_SP_({})\".format(\"wgt_SUMW_PU:HARDCODED\"), \"\", 200, 0.80, 1.1), \"SPL_SP\", \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"LepSF\"] = input_df.Histo1D(\"GLepton_SF_nom\")#, \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"LSF\"] = input_df.Histo1D(\"wgt_LSF\")#, \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"SPL_SP\"] = input_df.Histo1D(\"SPL_SP\")#, \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"SUMW_PU\"] = input_df.Histo1D(\"wgt_SUMW_PU\")#, \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"SUMW_PU_LSF\"] = input_df.Histo1D(\"wgt_SUMW_PU_LSF\")#, \"wgt_SUMW_PU\")\n",
    "            #histos1D_dict[\"Leptons\"][\"PU\"] = input_df.Histo1D(\"puWeight\")#, \"wgt_SUMW_PU\")\n",
    "    if doJets == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"Jets\" not in histos1D_dict:\n",
    "                histos1D_dict[\"Jets\"] = {}\n",
    "            histos1D_dict[\"Jets\"][\"pt\"] = input_df.Histo1D((\"Jet_pt_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_pt\", wgtVar)\n",
    "            for x in xrange(nJetsToHisto):\n",
    "                histos1D_dict[\"Jets\"][\"pt_jet{}\".format(x+1)] = input_df.Histo1D((\"Jet_pt_jet{}({})\".format(x+1, wgtVar), \"\", 100, 0, 500), \"GJet_pt_jet{}\".format(x+1), wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"eta\"] = input_df.Histo1D((\"Jet_eta_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GJet_eta\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"phi\"] = input_df.Histo1D((\"Jet_phi_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GJet_phi\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"mass\"] = input_df.Histo1D((\"Jet_mass_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_mass\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"jetId\"] = input_df.Histo1D((\"Jet_jetId_({})\".format(wgtVar), \"\", 8, 0, 8), \"GJet_jetId\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepB_LeadtagJet\"] = input_df.Histo1D((\"Jet_btagDeepB_LeadtagJet_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepB_LeadtagJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepB_SubleadtagJet\"] = input_df.Histo1D((\"Jet_btagDeepB_SubleadtagJet_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepB_SubleadtagJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepJet_LeadtagJet\"] = input_df.Histo1D((\"Jet_btagDeepJetB_LeadtagJet_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepFlavB_sorted_LeadtagJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"btagDeepJet_SubleadtagJet\"] = input_df.Histo1D((\"Jet_btagDeepJetB_SubleadtagJet_({})\".format(wgtVar), \"\", 101, -0.01, 1), \"GJet_btagDeepFlavB_sorted_SubleadtagJet\", wgtVar)\n",
    "            #histos1D_dict[\"Jets\"][\"nMediumCSVv2\"] = input_df.Histo1D((\"nJet_MediumCSVv2_({})\".format(wgtVar), \"\", 10, 0, 10), \"nGJet_MediumCSVv2\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"nMediumDeepCSV\"] = input_df.Histo1D((\"nJet_MediumDeepCSV_({})\".format(wgtVar), \"\", 10, 0, 10), \"nGJet_MediumDeepCSV\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"nMediumDeepJet\"] = input_df.Histo1D((\"nJet_MediumDeepJet_({})\".format(wgtVar), \"\", 10, 0, 10), \"nGJet_MediumDeepJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"nJet\"] = input_df.Histo1D((\"nJet_({})\".format(wgtVar), \"\", 15, 0, 15), \"nGJet\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"dR_Jet_Mu_leading\"] = input_df.Histo1D((\"dR_Jet_Mu_leading_({})\".format(wgtVar), \"dR(Jet, #mu_{leading}); dR; Events)\", 40, 0, 0.8), \"dR_Jet_Mu_leading\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"dR_Jet_Mu_sublead\"] = input_df.Histo1D((\"dR_Jet_Mu_sublead_({})\".format(wgtVar), \"dR(Jet, #mu_{subleading}); dR; Events)\", 40, 0, 0.8), \"dR_Jet_Mu_sublead\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"dR_Jet_El_leading\"] = input_df.Histo1D((\"dR_Jet_El_leading_({})\".format(wgtVar), \"dR(Jet, #e_{leading}); dR; Events)\", 40, 0, 0.8), \"dR_Jet_El_leading\", wgtVar)\n",
    "            histos1D_dict[\"Jets\"][\"dR_Jet_El_sublead\"] = input_df.Histo1D((\"dR_Jet_El_sublead_({})\".format(wgtVar), \"dR(Jet, #e_{subleading}); dR; Events)\", 40, 0, 0.8), \"dR_Jet_El_sublead\", wgtVar)\n",
    "                \n",
    "            if debugInfo == True:\n",
    "                #histos1D_dict[\"Jets\"][\"DiffMaskVsALT\"] = input_df.Histo1D((\"DiffMaskVsALT\", \"\", 10, -10, 10), \"DiffMaskVsALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"DiffnJet\"] = input_df.Histo1D((\"DiffnJet\", \"\", 10, -10, 10), \"DiffnJet\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"DeepJetSorted\"] = input_df.Histo1D(\"DeepJetSorted\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"DeepJetLeadtagMinusSubleadtag\"] = input_df.Histo1D((\"DeepJetLeadtagMinusSubleadtag\", \"DeepJet(Leadtag - Subleadtag);;Events\", 100, -1, 1), \"DeepJet0Minus1\", wgtVar)\n",
    "                histos1D_dict[\"Jets\"][\"MediumDeepJetSorted\"] = input_df.Histo1D(\"MediumDeepJetSorted\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"MediumDeepJet0Minus1\"] = input_df.Histo1D((\"MediumDeepJet0Minus1\", \"\", 100, -1, 1), \"MediumDeepJet0Minus1\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"btagDeepJet_jet0Med\"] = input_df.Histo1D((\"Jet_btagDeepJetB_jet0Med_({})\".format(wgtVar), \"\", 102, -0.02, 1), \"GJet_btagDeepFlavB_jet0Med\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"btagDeepJet_jet1Med\"] = input_df.Histo1D((\"Jet_btagDeepJetB_jet1Med_({})\".format(wgtVar), \"\", 102, -0.02, 1), \"GJet_btagDeepFlavB_jet1Med\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"nJetNUMW\"] = input_df.Histo1D((\"nJet_NUMW\", \"\", 15, 0, 15), \"nGJet\", \"wgt_NUMW_V2\")\n",
    "                #histos1D_dict[\"Jets\"][\"nJetSUMW_PU\"] = input_df.Histo1D((\"nJet_SUMW_PU\", \"\", 15, 0, 15), \"nGJet\", \"wgt_SUMW_PU\")\n",
    "                #histos1D_dict[\"Jets\"][\"nJetSUMW_LSF\"] = input_df.Histo1D((\"nJet_SUMW_LSF\", \"\", 15, 0, 15), \"nGJet\", \"wgt_SUMW_LSF\")\n",
    "                #histos1D_dict[\"Jets\"][\"ptALT\"] = input_df.Histo1D((\"Jet_ptALT_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_ptALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"etaALT\"] = input_df.Histo1D((\"Jet_etaALT_({})\".format(wgtVar), \"\", 104, -2.6, 2.6), \"GJet_etaALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"phiALT\"] = input_df.Histo1D((\"Jet_phiALT_({})\".format(wgtVar), \"\", 64, -pi, pi), \"GJet_phiALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"massALT\"] = input_df.Histo1D((\"Jet_massALT_({})\".format(wgtVar), \"\", 100, 0, 500), \"GJet_massALT\", wgtVar)\n",
    "                #histos1D_dict[\"Jets\"][\"jetIdALT\"] = input_df.Histo1D((\"Jet_jetIdALT_({})\".format(wgtVar), \"\", 8, 0, 8), \"GJet_jetIdALT\", wgtVar)\n",
    "        if histos2D_dict != None:\n",
    "            if \"Jets\" not in histos2D_dict:\n",
    "                histos2D_dict[\"Jets\"] = {}\n",
    "            histos2D_dict[\"Jets\"][\"eta_phi\"] = input_df.Histo2D((\"Jet_eta_phi_({})\".format(wgtVar), \"\",\n",
    "                                                                 104, -2.6, 2.6,\n",
    "                                                                 64, -pi, pi),\n",
    "                                                                \"GJet_eta\", \"GJet_phi\", wgtVar)\n",
    "    if doEventVars == True:\n",
    "        if histos1D_dict != None:\n",
    "            if \"EventVars\" not in histos1D_dict:\n",
    "                histos1D_dict[\"EventVars\"] = {}\n",
    "            #histos1D_dict[\"EventVars\"][\"JML_baseline\"] = input_df.Histo1D((\"JML_baseline_({})\".format(wgtVar), \"\", 2,0,2), \"JML_baseline_pass\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"JML_selection\"] = input_df.Histo1D((\"JML_selection_({})\".format(wgtVar), \"\", 2,0,2), \"JML_selection_pass\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HT_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT_baseline_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_HT_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"H_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_H_baseline_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_H_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HT2M_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT2M_baseline_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HT2M_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"H2M_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_H2M_baseline_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_H2M_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTb_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTb_baseline_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HTb_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTH_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTH_baseline_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTH_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTRat_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTRat_baseline_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTRat_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"dRbb_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_dRbb_baseline_({})\".format(wgtVar), \"\", 64,0,2*pi), \"ESV_JetMETLogic_dRbb_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"DiLepMass_baseline\"] = input_df.Histo1D((\"ESV_JetMETLogic_DiLepMass_baseline_({})\".format(wgtVar), \"\", 100,0,500), \"ESV_JetMETLogic_DiLepMass_baseline\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HT_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT_selection_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_HT_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"H_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_H_selection_({})\".format(wgtVar), \"\", 100,400,1400), \"ESV_JetMETLogic_H_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HT2M_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HT2M_selection_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HT2M_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"H2M_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_H2M_selection_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_H2M_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTb_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTb_selection_({})\".format(wgtVar), \"\", 100,400,900), \"ESV_JetMETLogic_HTb_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTH_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTH_selection_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTH_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"HTRat_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_HTRat_selection_({})\".format(wgtVar), \"\", 100,0,1), \"ESV_JetMETLogic_HTRat_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"dRbb_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_dRbb_selection_({})\".format(wgtVar), \"\", 64,0,2*pi), \"ESV_JetMETLogic_dRbb_selection\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"DiLepMass_selection\"] = input_df.Histo1D((\"ESV_JetMETLogic_DiLepMass_selection_({})\".format(wgtVar), \"\", 100,0,500), \"ESV_JetMETLogic_DiLepMass_selection\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"MET_pt\"] = input_df.Histo1D((\"MET_pt_({})\".format(wgtVar), \"\", 100,30,1030), \"METFixEE2017_pt\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"MET_phi\"] = input_df.Histo1D((\"MET_phi_({})\".format(wgtVar), \"\", 100,-pi,pi), \"METFixEE2017_phi\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HT\"] = input_df.Histo1D((\"HT_({})\".format(wgtVar), \"\", 130,400,1700), \"GJet_HT\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"H\"] = input_df.Histo1D((\"H_({})\".format(wgtVar), \"\", 160,400,2000), \"GJet_H\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HT2M\"] = input_df.Histo1D((\"HT2M_({})\".format(wgtVar), \"\", 100,0,1000), \"GJet_HT2M\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"H2M\"] = input_df.Histo1D((\"H2M_({})\".format(wgtVar), \"\", 150,0,1500), \"GJet_H2M\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTb\"] = input_df.Histo1D((\"HTb_({})\".format(wgtVar), \"\", 100,0,1000), \"GJet_HTb\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTH\"] = input_df.Histo1D((\"HTH_({})\".format(wgtVar), \"\", 100,0,1), \"GJet_HTH\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"HTRat\"] = input_df.Histo1D((\"HTRat_({})\".format(wgtVar), \"\", 100,0,1), \"GJet_HTRat\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dRbb\"] = input_df.Histo1D((\"dRbb_({})\".format(wgtVar), \"\", 64,0,2*pi), \"GJet_dRbb\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dPhibb\"] = input_df.Histo1D((\"dPhibb_({})\".format(wgtVar), \"\", 64,-pi,pi), \"GJet_dPhibb\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dEtabb\"] = input_df.Histo1D((\"dEtabb_({})\".format(wgtVar), \"\", 50,0,5), \"GJet_dEtabb\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dRll\"] = input_df.Histo1D((\"dRll_({})\".format(wgtVar), \"\", 64,0,2*pi), \"GLepton_dRll\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dPhill\"] = input_df.Histo1D((\"dPhill_({})\".format(wgtVar), \"\", 64,-pi,pi), \"GLepton_dPhill\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"dEtall\"] = input_df.Histo1D((\"dEtall_({})\".format(wgtVar), \"\", 50,0,5), \"GLepton_dEtall\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"MTofMETandEl\"] = input_df.Histo1D((\"MTofMETandEl_({})\".format(wgtVar), \"\", 100, 0, 200), \"MTofMETandEl\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"MTofMETandMu\"] = input_df.Histo1D((\"MTofMETandMu_({})\".format(wgtVar), \"\", 100, 0, 200), \"MTofMETandMu\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"MTofElandMu\"] = input_df.Histo1D((\"MTofElandMu_({})\".format(wgtVar), \"\", 100, 0, 200), \"MTofElandMu\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"MTMasslessCheck\"] = input_df.Histo1D((\"MTMasslessCheck_({})\".format(wgtVar), \"\", 100, 0, 200), \"MTMasslessCheck\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"MTCrossCheck\"] = input_df.Histo1D((\"MTCrossCheck_({})\".format(wgtVar), \"\", 100, 0, 200), \"MTCrossCheck\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"MTCrossCheckDifference\"] = input_df.Histo1D((\"MTCrossCheckDifference_({})\".format(wgtVar), \"\", 100, 0, 10), \"MTCrossCheckDifference\", wgtVar)\n",
    "            #histos1D_dict[\"EventVars\"][\"MTCrossCheckMasslessDifference\"] = input_df.Histo1D((\"MTCrossCheckMasslessDifference_({})\".format(wgtVar), \"\", 100, 0, 0.02), \"MTCrossCheckMasslessDifference\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"PV_npvsGood\"] = input_df.Histo1D((\"PV_npvsGood_({})\".format(wgtVar), \"\", 100, 0, 100), \"PV_npvsGood\", wgtVar)\n",
    "            histos1D_dict[\"EventVars\"][\"PV_npvs\"] = input_df.Histo1D((\"PV_npvs_({})\".format(wgtVar), \"\", 150, 0, 150), \"PV_npvs\", wgtVar)\n",
    "            if isData == False:\n",
    "                histos1D_dict[\"EventVars\"][\"Pileup_nTrueInt\"] = input_df.Histo1D((\"Pileup_TrueInt_({})\".format(wgtVar), \";Pileup_TrueInt;Events\", 150, 0, 150), \"Pileup_nTrueInt\", wgtVar)\n",
    "                histos1D_dict[\"EventVars\"][\"Pileup_nTrueInt_XS\"] = input_df.Histo1D((\"Pileup_TrueInt_({})\".format(\"wgt_SUMW\"), \";Pileup_TrueInt;Events\", 150, 0, 150), \"Pileup_nTrueInt\", \"wgt_SUMW\")\n",
    "                histos1D_dict[\"EventVars\"][\"Pileup_nPU_XS\"] = input_df.Histo1D((\"Pileup_nPU_({})\".format(\"wgt_SUMW\"), \";Pileup_nPU;Events\", 150, 0, 150), \"Pileup_nPU\", \"wgt_SUMW\")\n",
    "                histos1D_dict[\"EventVars\"][\"Pileup_nPU\"] = input_df.Histo1D((\"Pileup_nPU_({})\".format(wgtVar), \";Pileup_nPU;Events\", 150, 0, 150), \"Pileup_nPU\", wgtVar)\n",
    "            \n",
    "        if histos2D_dict != None:\n",
    "            if \"EventVars\" not in histos2D_dict:\n",
    "                histos2D_dict[\"EventVars\"] = {}\n",
    "            if isData == False:\n",
    "                histos2D_dict[\"EventVars\"][\"npvsGood_vs_nTrueInt\"] = input_df.Histo2D((\"npvsGood_vs_nTrueInt_({})\".format(wgtVar), \";nTrueInt;npvsGood\", 150, 0, 150, 150, 0, 150), \"Pileup_nTrueInt\", \"PV_npvsGood\", wgtVar)\n",
    "                histos2D_dict[\"EventVars\"][\"npvsGood_vs_nPU\"] = input_df.Histo2D((\"npvsGood_vs_nPU_({})\".format(wgtVar), \";nPU;npvsGood\", 150, 0, 150, 150, 0, 150), \"Pileup_nPU\", \"PV_npvsGood\", wgtVar)\n",
    "                histos2D_dict[\"EventVars\"][\"npvs_vs_nTrueInt\"] = input_df.Histo2D((\"npvs_vs_nTrueInt_({})\".format(wgtVar), \";nTrueInt;npvs\", 150, 0, 150, 150, 0, 150), \"Pileup_nTrueInt\", \"PV_npvs\", wgtVar)\n",
    "                histos2D_dict[\"EventVars\"][\"npvs_vs_nPU\"] = input_df.Histo2D((\"npvs_vs_nPU_({})\".format(wgtVar), \";nPU;npvs\", 150, 0, 150, 150, 0, 150), \"Pileup_nPU\", \"PV_npvs\", wgtVar)\n",
    "            \n",
    "            if debugInfo == True:\n",
    "                #histos1D_dict[\"EventVars\"][\"GJet_HT_Match\"] = input_df.Histo1D((\"GJet_HT_Match_({})\".format(wgtVar), \"\", 2,0,2), \"GJet_HT_matches\", wgtVar)\n",
    "                pass\n",
    "            \n",
    "    if makeMountains == True:\n",
    "        theCats = collections.OrderedDict()\n",
    "        theCats[\"nJet4\"] = \"nGJet == 4\"\n",
    "        theCats[\"nJet5\"] = \"nGJet == 5\"\n",
    "        theCats[\"blind_nJet6\"] = \"nGJet == 6\"\n",
    "        theCats[\"blind_nJet7\"] = \"nGJet == 7\"\n",
    "        theCats[\"blind_nJet8+\"] = \"nGJet >= 8\"\n",
    "        #theCats[\"nMediumDeepCSV0\"] = \"nGJet_MediumDeepCSV == 0\"\n",
    "        #theCats[\"nMediumDeepCSV1\"] = \"nGJet_MediumDeepCSV == 1\"\n",
    "        theCats[\"nMediumDeepJet0\"] = \"nGJet_MediumDeepJet == 0\"\n",
    "        theCats[\"nMediumDeepJet1\"] = \"nGJet_MediumDeepJet == 1\"\n",
    "        theCats[\"nMediumDeepJet2\"] = \"nGJet_MediumDeepJet == 2\"\n",
    "        \n",
    "        theCats[\"nMediumDeepJet0_nJet4\"] = \"nGJet_MediumDeepJet == 0 && nGJet == 4\"\n",
    "        theCats[\"nMediumDeepJet1_nJet4\"] = \"nGJet_MediumDeepJet == 1 && nGJet == 4\"\n",
    "        theCats[\"nMediumDeepJet2_nJet4\"] = \"nGJet_MediumDeepJet == 2 && nGJet == 4\"\n",
    "        theCats[\"blind_nMediumDeepJet3_nJet4\"] = \"nGJet_MediumDeepJet == 3 && nGJet == 4\"\n",
    "        theCats[\"blind_nMediumDeepJet4+_nJet4\"] = \"nGJet_MediumDeepJet >= 4 && nGJet == 4\"\n",
    "        \n",
    "        theCats[\"nMediumDeepJet0_nJet5\"] = \"nGJet_MediumDeepJet == 0 && nGJet == 5\"\n",
    "        theCats[\"nMediumDeepJet1_nJet5\"] = \"nGJet_MediumDeepJet == 1 && nGJet == 5\"\n",
    "        theCats[\"nMediumDeepJet2_nJet5\"] = \"nGJet_MediumDeepJet == 2 && nGJet == 5\"\n",
    "        theCats[\"blind_nMediumDeepJet3_nJet5\"] = \"nGJet_MediumDeepJet == 3 && nGJet == 5\"\n",
    "        theCats[\"blind_nMediumDeepJet4+_nJet5\"] = \"nGJet_MediumDeepJet >= 4 && nGJet == 5\"\n",
    "        \n",
    "        theCats[\"nMediumDeepJet0_nJet6\"] = \"nGJet_MediumDeepJet == 0 && nGJet == 6\"\n",
    "        theCats[\"nMediumDeepJet1_nJet6\"] = \"nGJet_MediumDeepJet == 1 && nGJet == 6\"\n",
    "        theCats[\"nMediumDeepJet2_nJet6\"] = \"nGJet_MediumDeepJet == 2 && nGJet == 6\"\n",
    "        theCats[\"blind_nMediumDeepJet3_nJet6\"] = \"nGJet_MediumDeepJet == 3 && nGJet == 6\"\n",
    "        theCats[\"blind_nMediumDeepJet4+_nJet6\"] = \"nGJet_MediumDeepJet >= 4 && nGJet == 6\"\n",
    "        \n",
    "        theCats[\"nMediumDeepJet0_nJet7\"] = \"nGJet_MediumDeepJet == 0 && nGJet == 7\"\n",
    "        theCats[\"nMediumDeepJet1_nJet7\"] = \"nGJet_MediumDeepJet == 1 && nGJet == 7\"\n",
    "        theCats[\"blind_nMediumDeepJet2_nJet7\"] = \"nGJet_MediumDeepJet == 2 && nGJet == 7\"\n",
    "        theCats[\"blind_nMediumDeepJet3_nJet7\"] = \"nGJet_MediumDeepJet == 3 && nGJet == 7\"\n",
    "        theCats[\"blind_nMediumDeepJet4+_nJet7\"] = \"nGJet_MediumDeepJet >= 4 && nGJet == 7\"\n",
    "        \n",
    "        theCats[\"nMediumDeepJet0_nJet8+\"] = \"nGJet_MediumDeepJet == 0 && nGJet >= 8\"\n",
    "        theCats[\"nMediumDeepJet1_nJet8+\"] = \"nGJet_MediumDeepJet == 1 && nGJet >= 8\"\n",
    "        theCats[\"blind_nMediumDeepJet2_nJet8+\"] = \"nGJet_MediumDeepJet == 2 && nGJet >= 8\"\n",
    "        theCats[\"blind_nMediumDeepJet3_nJet8+\"] = \"nGJet_MediumDeepJet == 3 && nGJet >= 8\"\n",
    "        theCats[\"blind_nMediumDeepJet4+_nJet8+\"] = \"nGJet_MediumDeepJet >= 4 && nGJet >= 8\"\n",
    "        cat_df = collections.OrderedDict()\n",
    "        for ck, cs in theCats.items():\n",
    "            cat_df[ck] = input_df.Filter(cs, cs)\n",
    "        if histos1D_dict != None:\n",
    "            if \"Mountains\" not in histos1D_dict:\n",
    "                histos1D_dict[\"Mountains\"] = {}\n",
    "            for tc in theCats.keys(): \n",
    "                if tc not in histos1D_dict[\"Mountains\"]: \n",
    "                    histos1D_dict[\"Mountains\"][tc] = {}\n",
    "            for tc, cut in theCats.items():\n",
    "                tcn = tc.replace(\"blind_\", \"\")\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MET_pt\"] = cat_df[tc].Histo1D((\"MET_pt_[{}]({})\".format(tcn, wgtVar), \"\", 20,30,1030), \"METFixEE2017_pt\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MET_phi\"] = cat_df[tc].Histo1D((\"MET_phi_[{}]({})\".format(tcn, wgtVar), \"\", 20,-pi,pi), \"METFixEE2017_phi\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_all\"] = cat_df[tc].Histo1D((\"Muon_pfRelIso03_all_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 0.2), \"GMuon_pfRelIso03_all\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_chg\"] = cat_df[tc].Histo1D((\"Muon_pfRelIso03_chg_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 0.2), \"GMuon_pfRelIso03_chg\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso04_all\"] = cat_df[tc].Histo1D((\"Muon_pfRelIso04_all_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 0.2), \"GMuon_pfRelIso04_all\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_all\"] = cat_df[tc].Histo1D((\"Electron_pfRelIso03_all_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 0.2), \"GElectron_pfRelIso03_all\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_chg\"] = cat_df[tc].Histo1D((\"Electron_pfRelIso03_chg_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 0.2), \"GElectron_pfRelIso03_chg\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"HT\"] = cat_df[tc].Histo1D((\"HT_[{}]({})\".format(tcn, wgtVar), \"\", 30,400,2000), \"GJet_HT\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"H\"] = cat_df[tc].Histo1D((\"H_[{}]({})\".format(tcn, wgtVar), \"\", 30,400,2000), \"GJet_H\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"HT2M\"] = cat_df[tc].Histo1D((\"HT2M_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1000), \"GJet_HT2M\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"H2M\"] = cat_df[tc].Histo1D((\"H2M_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1500), \"GJet_H2M\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"HTb\"] = cat_df[tc].Histo1D((\"HTb_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1000), \"GJet_HTb\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"HTH\"] = cat_df[tc].Histo1D((\"HTH_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1), \"GJet_HTH\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"HTRat\"] = cat_df[tc].Histo1D((\"HTRat_[{}]({})\".format(tcn, wgtVar), \"\", 20,0,1), \"GJet_HTRat\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dRbb\"] = cat_df[tc].Histo1D((\"dRbb_[{}]({})\".format(tcn, wgtVar), \"\", 16,0,2*pi), \"GJet_dRbb\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dPhibb\"] = cat_df[tc].Histo1D((\"dPhibb_[{}]({})\".format(tcn, wgtVar), \"\", 16,-pi,pi), \"GJet_dPhibb\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dEtabb\"] = cat_df[tc].Histo1D((\"dEtabb_[{}]({})\".format(tcn, wgtVar), \"\", 10,0,5), \"GJet_dEtabb\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dRll\"] = cat_df[tc].Histo1D((\"dRll_[{}]({})\".format(tcn, wgtVar), \"\", 16,0,2*pi), \"GLepton_dRll\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dPhill\"] = cat_df[tc].Histo1D((\"dPhill_[{}]({})\".format(tcn, wgtVar), \"\", 16,-pi,pi), \"GLepton_dPhill\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"dEtall\"] = cat_df[tc].Histo1D((\"dEtall_[{}]({})\".format(tcn, wgtVar), \"\", 10,0,5), \"GLepton_dEtall\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofMETandEl\"] = cat_df[tc].Histo1D((\"MTofMETandEl_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofMETandEl\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofMETandMu\"] = cat_df[tc].Histo1D((\"MTofMETandMu_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofMETandMu\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofElandMu\"] = cat_df[tc].Histo1D((\"MTofElandMu_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofElandMu\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nMediumDeepCSV\"] = cat_df[tc].Histo1D((\"nJet_MediumDeepCSV_[{}]({})\".format(tcn, wgtVar), \"\", 10, 0, 10), \"nGJet_MediumDeepCSV\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"nMediumDeepJet\"] = cat_df[tc].Histo1D((\"nJet_MediumDeepJet_[{}]({})\".format(tcn, wgtVar), \"\", 10, 0, 10), \"nGJet_MediumDeepJet\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofMETandEl\"] = cat_df[tc].Histo1D((\"MTofMETandEl_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofMETandEl\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofMETandMu\"] = cat_df[tc].Histo1D((\"MTofMETandMu_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofMETandMu\", wgtVar)\n",
    "                histos1D_dict[\"Mountains\"][tc][\"MTofElandMu\"] = cat_df[tc].Histo1D((\"MTofElandMu_[{}]({})\".format(tcn, wgtVar), \"\", 20, 0, 200), \"MTofElandMu\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 30, 0., 0.2, 20,30.,1030.), \"GMuon_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 30, 0, 0.2, 20,30,1030), \"GMuon_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso04_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso04_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso04_all;MET\", 30, 0, 0.2, 20,30,1030), \"GMuon_pfRelIso04_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 30, 0, 0.2, 20,30,1030), \"GElectron_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 30, 0, 0.2, 20,30,1030), \"GElectron_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                \n",
    "                if isData == False:\n",
    "                    pass                \n",
    "            \n",
    "        if histos2D_dict != None:\n",
    "            if \"Mountains\" not in histos2D_dict:\n",
    "                histos2D_dict[\"Mountains\"] = {}\n",
    "            for tc in theCats.keys(): \n",
    "                if tc not in histos2D_dict[\"Mountains\"]: \n",
    "                    histos2D_dict[\"Mountains\"][tc] = {}\n",
    "            for tc, cut in theCats.items():\n",
    "                tcn = tc.replace(\"blind_\", \"\")\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 30, 0., 0.2, 20,30.,1030.), \"GMuon_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 30, 0, 0.2, 20,30,1030), \"GMuon_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Muon_pfRelIso04_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso04_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso04_all;MET\", 30, 0, 0.2, 20,30,1030), \"GMuon_pfRelIso04_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 30, 0, 0.2, 20,30,1030), \"GElectron_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos1D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 30, 0, 0.2, 20,30,1030), \"GElectron_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                #### Older versions\n",
    "                #histos2D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 100, 0., 0.2, 100,30.,1030.), \"GMuon_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos2D_dict[\"Mountains\"][tc][\"Muon_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 100, 0, 0.2, 100,30,1030), \"GMuon_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos2D_dict[\"Mountains\"][tc][\"Muon_pfRelIso04_all_vs_MET\"] = cat_df[tc].Histo2D((\"Muon_pfRelIso04_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso04_all;MET\", 100, 0, 0.2, 100,30,1030), \"GMuon_pfRelIso04_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos2D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_all_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_all_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_all;MET\", 100, 0, 0.2, 100,30,1030), \"GElectron_pfRelIso03_all\", \"RVec_MET_pt\", wgtVar)\n",
    "                #histos2D_dict[\"Mountains\"][tc][\"Electron_pfRelIso03_chg_vs_MET\"] = cat_df[tc].Histo2D((\"Electron_pfRelIso03_chg_vs_MET_[{}]({})\".format(tcn, wgtVar), \";pfRelIso03_chg;MET\", 100, 0, 0.2, 100,30,1030), \"GElectron_pfRelIso03_chg\", \"RVec_MET_pt\", wgtVar)\n",
    "                if isData == False:\n",
    "                    #histos2D_dict[\"Mountains\"][tc][\"test1\"] = cat_df[tc].Histo2D((\"test1_[{}]({})\".format(tcn, wgtVar), \";nTrueInt;npvsGood\", 150, 0, 150, 150, 0, 150), \"GMuon_pfRelIso03_all\", \"PV_npvsGood\", wgtVar)\n",
    "                    #histos2D_dict[\"Mountains\"][tc][\"test2\"] = cat_df[tc].Histo2D((\"test2_[{}]({})\".format(tcn, wgtVar), \";nTrueInt;npvsGood\", 150, 0, 150, 150, 0, 150), \"GMuon_pfRelIso03_all\", \"METFixEE2017_pt\", wgtVar)\n",
    "                    #histos2D_dict[\"Mountains\"][tc][\"npvsGood_vs_nTrueInttest\"] = cat_df[tc].Histo2D((\"npvsGood_vs_nTrueInttest_[{}]({})\".format(tcn, wgtVar), \";nTrueInt;npvsGood\", 150, 0, 150, 150, 0, 150), \"GElectron_pfRelIso03_all\", \"MET_pt_flat\", wgtVar)\n",
    "                    histos2D_dict[\"Mountains\"][tc][\"npvsGood_vs_nTrueInt\"] = cat_df[tc].Histo2D((\"npvsGood_vs_nTrueInt_[{}]({})\".format(tcn, wgtVar), \";nTrueInt;npvsGood\", 150, 0, 150, 150, 0, 150), \"Pileup_nTrueInt\", \"PV_npvsGood\", wgtVar)\n",
    "                    histos2D_dict[\"Mountains\"][tc][\"npvsGood_vs_nPU\"] = cat_df[tc].Histo2D((\"npvsGood_vs_nPU_[{}]({})\".format(tcn, wgtVar), \";nPU;npvsGood\", 150, 0, 150, 150, 0, 150), \"Pileup_nPU\", \"PV_npvsGood\", wgtVar)\n",
    "                    histos2D_dict[\"Mountains\"][tc][\"npvs_vs_nTrueInt\"] = cat_df[tc].Histo2D((\"npvs_vs_nTrueInt_[{}]({})\".format(tcn, wgtVar), \";nTrueInt;npvs\", 150, 0, 150, 150, 0, 150), \"Pileup_nTrueInt\", \"PV_npvs\", wgtVar)\n",
    "                    histos2D_dict[\"Mountains\"][tc][\"npvs_vs_nPU\"] = cat_df[tc].Histo2D((\"npvs_vs_nPU_[{}]({})\".format(tcn, wgtVar), \";nPU;npvs\", 150, 0, 150, 150, 0, 150), \"Pileup_nPU\", \"PV_npvs\", wgtVar)\n",
    "      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jet bit dictionary, for reference\n",
    "JMLpassbits = {'PV_minNDoF':                            0b00000000000000000001,\n",
    "                 'PV_maxAbsZ':                            0b00000000000000000010,\n",
    "                 'PV_maxRho':                             0b00000000000000000100,\n",
    "                 'MET_globalSuperTightHalo2016Filter':    0b00000000000000001000,\n",
    "                 'MET_goodVertices':                      0b00000000000000010000,\n",
    "                 'MET_HBHENoiseFilter':                   0b00000000000000100000,\n",
    "                 'MET_HBHENoiseIsoFilter':                0b00000000000001000000,\n",
    "                 'MET_EcalDeadCellTriggerPrimitiveFilter':0b00000000000010000000,\n",
    "                 'MET_BadPFMuonFilter':                   0b00000000000100000000,\n",
    "                 'MET_ecalBadCalibFilterV2':              0b00000000001000000000,\n",
    "                 'MET_pt':                                0b00000000010000000000,\n",
    "                 'unused1':                               0b00000000100000000000, #N\n",
    "                 'Lepton_ZWindow':                        0b00000001000000000000, #N\n",
    "                 'Jet_nJet25':                            0b00000010000000000000, #N\n",
    "                 'Jet_nJet20':                            0b00000100000000000000,\n",
    "                 'HT':                                    0b00001000000000000000,\n",
    "                 'Jet_nBJet_2DCSV':                       0b00010000000000000000, #N\n",
    "                 'Jet_nBJet_2DJet':                       0b00100000000000000000, #N\n",
    "                 'unused2':                               0b01000000000000000000, #N\n",
    "                 'unused3':                               0b10000000000000000000, #N\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##################################################\n",
    "### CHOOSE SAMPLE DICT AND CHANNEL TO ANALYZE ####\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    "#Focus on limited set of events at a time\n",
    "levels_of_interest = set([\"ElMu_selection\"])\n",
    "#levels_of_interest = set([\"selection\", \"ElMu_selection\", \"ElEl_selection\", \"MuMu_selection\", \"Mu_selection\", \"El_selection\"])\n",
    "#levels_of_interest = set([\"baseline\", \"MuMu_baseline\", \"ElEl_baseline\", \"selection\", \"MuMu_selection\", \"ElMu_selection\"])\n",
    "#levels_of_interest = set([\"baseline\", \"MuMu_selection\", \"ElMu_selection\"])\n",
    "\n",
    "#Choose the sample dictionary to run\n",
    "#theSampleDict = ttbooker #needs modification to make work...\n",
    "#theSampleDict = ttttbooker\n",
    "theSampleDict = microbooker #tttt, ttbar-DL unfiltered, DY, one single top sample\n",
    "#theSampleDict = minibooker #tttt, all ttbar, both single top, DY\n",
    "#theSampleDict = booker #All\n",
    "#theSampleDict = bookerV2 #All with reprocessing (WIP: Other data streams, ttVJets, Filtered samples!)\n",
    "#theSampleDict = tt_data_V2\n",
    "#theSampleDict = pyrdfbooker\n",
    "\n",
    "#Choose the weight variation\n",
    "#theWeight = \"wgt_SUMW\"\n",
    "#theWeight = \"wgt_SUMW_PU\"\n",
    "#theWeight = \"wgt_SUMW_LSF\"\n",
    "#theWeight = \"wgt_SUMW_L1PF\"\n",
    "#theWeight = \"wgt_SUMW_PU_LSF\"\n",
    "theWeight = \"wgt_SUMW_PU_LSF_L1PF\"\n",
    "#theWeight = \"wgt_SUMW_LSF_L1PF\"\n",
    "#theWeight = \"wgt_NUMW_LSF_L1PF\"\n",
    "\n",
    "#Name the channel that's being analyzed for saving files, and the format (.C, .root, .pdf, .eps, .gif, .png, .jpeg, etc)\n",
    "fileChannel = \"ElMu\"\n",
    "#theFormat = \".pdf\"\n",
    "theFormat = \".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating selection and baseline bits\")\n",
    "b = {}\n",
    "b[\"ElMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) > 0\".format(Chan[\"ElMu_baseline\"])\n",
    "b[\"MuMu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"], \n",
    "                                                                                                                                Chan[\"MuMu_baseline\"])\n",
    "b[\"ElEl_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"], \n",
    "                                                                                                                                Chan[\"ElEl_baseline\"])\n",
    "b[\"Mu_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + Chan[\"ElEl_baseline\"], Chan[\"Mu_baseline\"])\n",
    "b[\"El_baseline\"] = \"(ESV_TriggerAndLeptonLogic_baseline & {0}) == 0 && (ESV_TriggerAndLeptonLogic_baseline & {1}) > 0\".format(Chan[\"ElMu_baseline\"] + Chan[\"MuMu_baseline\"] + \n",
    "                                                                                                                    Chan[\"ElEl_baseline\"] + Chan[\"Mu_baseline\"], Chan[\"El_baseline\"])\n",
    "b[\"selection\"] = \"ESV_TriggerAndLeptonLogic_selection > 0\"\n",
    "b[\"ElMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) > 0\".format(Chan[\"ElMu_selection\"])\n",
    "b[\"MuMu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"], Chan[\"MuMu_selection\"])\n",
    "b[\"ElEl_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"], Chan[\"ElEl_selection\"])\n",
    "b[\"Mu_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"], Chan[\"Mu_selection\"])\n",
    "b[\"El_selection\"] = \"(ESV_TriggerAndLeptonLogic_selection & {0}) == 0 && (ESV_TriggerAndLeptonLogic_selection & {1}) > 0\".format(Chan[\"ElMu_selection\"] + Chan[\"MuMu_selection\"] + Chan[\"ElEl_selection\"]\n",
    "                                                                            + Chan[\"Mu_selection\"], Chan[\"El_selection\"]) \n",
    "b[\"ESV_JetMETLogic_baseline\"] = \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00001100011111111111)\n",
    "#b[\"ESV_JetMETLogic_selection\"] = \"(ESV_JetMETLogic_baseline & {0}) >= {0}\".format(0b00001100011111111111) #FIXME, this isn't right!\n",
    "b[\"ESV_JetMETLogic_selection\"] = \"(ESV_JetMETLogic_selection & {0}) >= {0}\".format(0b00001100011111111111)\n",
    "b[\"ESV_JetMETLogic_default\"] = \"(ESV_JetMETLogic_baseline & {}) > 0\".format(0b11111111111111111111)\n",
    "#print(b[\"ESV_JetMETLogic_selection\"])\n",
    "\n",
    "\n",
    "\n",
    "filtered = {}\n",
    "for name, vals in theSampleDict.items():\n",
    "    if name == \"tttt_orig\": continue\n",
    "    print(\"Initializing RDataFrame - {}\".format(name))\n",
    "    filtered[name] = {}\n",
    "    for lvl in levels_of_interest:\n",
    "        if \"baseline\" in lvl:\n",
    "            JMLOG = \"ESV_JetMETLogic_baseline\"\n",
    "        elif \"selection\" in lvl:\n",
    "            JMLOG = \"ESV_JetMETLogic_selection\"\n",
    "        else:\n",
    "            JMLOG = \"ESV_JetMETLogic_default\"\n",
    "        if lvl == \"baseline\":\n",
    "            filtered[name][lvl] = RDF(\"Events\", vals[\"source\"])#.Filter(b[JMLOG], JMLOG)#.Cache()\n",
    "        else:\n",
    "            filtered[name][lvl] = RDF(\"Events\", vals[\"source\"])#.Filter(b[lvl], lvl).Filter(b[JMLOG], JMLOG)#.Cache()\n",
    "        #Cache() seemingly has an issue with the depth/breadth of full NanoAOD file. Perhaps one with fewer branches would work\n",
    "        #filtered[name][lvl] = filtered[name][lvl].Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = {}\n",
    "counts = {}\n",
    "histos1D = {}\n",
    "histos1D_PU = {}\n",
    "histos2D = {}\n",
    "histosNS = {} #unstacked histograms\n",
    "the_df = {}\n",
    "print(\"Starting loop for booking\")\n",
    "for name, vals in theSampleDict.items():\n",
    "    if name == \"tttt_orig\": continue\n",
    "    #if name not in [\"tttt\", \"ElMu_F\"]: continue\n",
    "    print(\"Booking - {}\".format(name))\n",
    "    counts[name] = {}\n",
    "    histos1D[name] = {}\n",
    "    histos1D_PU[name] = {}\n",
    "    histos2D[name] = {}\n",
    "    histosNS[name] = {}\n",
    "    the_df[name] = {}\n",
    "    #counts[name][\"baseline\"] = filtered[name].Count() #Unnecessary with baseline in levels of interest?\n",
    "    for lvl in levels_of_interest:\n",
    "        the_df[name][lvl] = defineLeptons(filtered[name][lvl], \n",
    "                                            input_lvl_filter=lvl, \n",
    "                                            channel=\"MuMu\", \n",
    "                                            isData=vals[\"isData\"], \n",
    "                                            useBackupChannel=False)\n",
    "        if vals[\"isData\"] == False:\n",
    "            the_df[name][lvl] = defineWeights(the_df[name][lvl],\n",
    "                                            crossSection=vals[\"crossSection\"], \n",
    "                                            sumWeights=vals[\"sumWeights\"], \n",
    "                                            lumi=lumi[era],\n",
    "                                            nEvents=vals[\"nEvents\"], \n",
    "                                            nEventsPositive=vals[\"nEventsPositive\"], \n",
    "                                            nEventsNegative=vals[\"nEventsNegative\"],\n",
    "                                            channel=\"MuMu\", \n",
    "                                            isData=vals[\"isData\"], \n",
    "                                            verbose=False,)\n",
    "        else:\n",
    "            the_df[name][lvl] = defineWeights(the_df[name][lvl],\n",
    "                                             isData=True,\n",
    "                                             verbose=False)\n",
    "        the_df[name][lvl] = defineJets(the_df[name][lvl],\n",
    "                                       era=\"2017\",\n",
    "                                      )\n",
    "        the_df[name][lvl] = defineEventVars(the_df[name][lvl])\n",
    "        the_df[name][lvl] = the_df[name][lvl].Define(\"RVec_MET_pt\", \"ROOT::VecOps::RVec<float> encaps; encaps.push_back(METFixEE2017_pt); return encaps;\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet > 2\", \"nJet > 2\")\n",
    "        the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet > 3\", \"nJet > 3\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet_MediumDeepCSV > 1\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"nGJet_MediumDeepJet > 1\", \"nMedDeepJet > 1\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"METFixEE2017_pt > 40\", \"MET > 40\")\n",
    "        the_df[name][lvl] = the_df[name][lvl].Filter(\"METFixEE2017_pt > 50\", \"MET > 50\")\n",
    "        #the_df[name][lvl] = the_df[name][lvl].Filter(\"GJet_HT > 450\", \"HT > 450\")\n",
    "        the_df[name][lvl] = the_df[name][lvl].Filter(\"GJet_HT > 500\", \"HT > 500\")\n",
    "        counts[name][lvl] = the_df[name][lvl].Count()\n",
    "        histos1D[name][lvl] = {}\n",
    "        histos1D_PU[name][lvl] = {}\n",
    "        histosNS[name][lvl] = {}\n",
    "        histos2D[name][lvl] = {}\n",
    "        fillHistos(the_df[name][lvl], wgtVar=theWeight, isData = vals[\"isData\"],\n",
    "                   histos1D_dict=histos1D[name][lvl], histos2D_dict=histos2D[name][lvl], \n",
    "                   histosNS_dict=histosNS[name][lvl],\n",
    "                   doMuons=True, doElectrons=True, doLeptons=True, \n",
    "                   doJets=True, doWeights=False, doEventVars=True,\n",
    "                   makeMountains=True)\n",
    "#        fillHistos(the_df[name][lvl], wgtVar=\"wgt_SUMW_PU_LSF\", histos1D_dict=histos1D[name][lvl], \n",
    "#                   histos2D_dict=histos2D[name][lvl], histosNS_dict=histosNS[name][lvl],\n",
    "#                   doMuons=False, doElectrons=False, doLeptons=True, \n",
    "#                   doJets=False, doWeights=True, doEventVars=False)\n",
    "#        fillHistos(the_df[name][lvl], wgtVar=\"wgt_SUMW_PU\", histos1D_dict=histos1D[name][lvl], \n",
    "#                   histos2D_dict=histos2D[name][lvl], histosNS_dict=histosNS[name][lvl],\n",
    "#                   doMuons=False, doElectrons=False, doLeptons=False, \n",
    "#                   doJets=False, doWeights=False, doEventVars=True)\n",
    "#        fillHistos(the_df[name][lvl], wgtVar=\"wgt_SUMW_PU\", histos1D_dict=histos1D_PU[name][lvl], \n",
    "#                   histos2D_dict=histos2D[name][lvl], histosNS_dict=histosNS[name][lvl],\n",
    "#                   doMuons=True, doElectrons=True, doLeptons=True, \n",
    "#                   doJets=True, doWeights=True, doEventVars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Warning: if filtered[name][lvl] RDFs are not reset, then calling Define(*) on them will cause the error\"\\\n",
    "      \" with 'program state reset' due to multiple definitions for the same variable\")\n",
    "loopcounter = 0\n",
    "start = time.clock()\n",
    "substart = {}\n",
    "subfinish = {}\n",
    "for name, cnt in counts.items():\n",
    "    substart[name] = time.clock()\n",
    "    loopcounter += 1\n",
    "    print(\"==========={}/{}\\n{}\".format(loopcounter, len(counts), name))\n",
    "    if \"baseline\" in cnt:\n",
    "        print(\"Baseline = \" + str(cnt[\"baseline\"].GetValue()))\n",
    "    else:\n",
    "        print(\"Baseline\")\n",
    "    if \"ElMu_baseline\" in cnt:\n",
    "        print(\"\\tElMu = {}\".format(cnt[\"ElMu_baseline\"].GetValue()),end='')\n",
    "    if \"MuMu_baseline\" in cnt:\n",
    "        print(\"\\tMuMu = {}\".format(cnt[\"MuMu_baseline\"].GetValue()),end='')\n",
    "    if \"ElEl_baseline\" in cnt:\n",
    "        print(\"\\tElEl = {}\".format(cnt[\"ElEl_baseline\"].GetValue()),end='')\n",
    "    if \"Mu_baseline\" in cnt:\n",
    "        print(\"\\tMu = {}\".format(cnt[\"Mu_baseline\"].GetValue()),end='')\n",
    "    if \"El_baseline\" in cnt:\n",
    "        print(\"\\tEl = {}\".format(cnt[\"El_baseline\"].GetValue()),end='')\n",
    "    print(\"\")\n",
    "    if \"ElMu_baseline\" in cnt and \"ElEl_baseline\" in cnt and \"MuMu_baseline\" in cnt\\\n",
    "            and \"Mu_baseline\" in cnt and \"El_baseline\" in cnt:\n",
    "        print(\"\\nTotal = {}\".format(cnt[\"ElMu_baseline\"].GetValue() + cnt[\"MuMu_baseline\"].GetValue() + cnt[\"ElEl_baseline\"].GetValue() + cnt[\"Mu_baseline\"].GetValue() + cnt[\"El_baseline\"].GetValue()))\n",
    "    if \"selection\" in cnt:\n",
    "        print(\"Selection = \" + str(cnt[\"selection\"].GetValue()))\n",
    "    else: \n",
    "        print(\"Selection\")\n",
    "    if \"ElMu_selection\" in cnt:\n",
    "        print(\"\\tElMu = {}\".format(cnt[\"ElMu_selection\"].GetValue()),end='')\n",
    "    if \"MuMu_selection\" in cnt:\n",
    "        print(\"\\tMuMu = {}\".format(cnt[\"MuMu_selection\"].GetValue()),end='')\n",
    "    if \"ElEl_selection\" in cnt:\n",
    "        print(\"\\tElEl = {}\".format(cnt[\"ElEl_selection\"].GetValue()),end='')\n",
    "    if \"Mu_selection\" in cnt:\n",
    "        print(\"\\tMu = {}\".format(cnt[\"Mu_selection\"].GetValue()),end='')\n",
    "    if \"El_selection\" in cnt:\n",
    "        print(\"\\tEl = {}\".format(cnt[\"El_selection\"].GetValue()),end='')\n",
    "    print(\"\")  \n",
    "    if \"ElMu_selection\" in cnt and \"ElEl_selection\" in cnt and \"MuMu_selection\" in cnt\\\n",
    "            and \"Mu_selection\" in cnt and \"El_selection\" in cnt:\n",
    "        print(\"\\nTotal = {}\".format(cnt[\"ElMu_selection\"].GetValue() + cnt[\"MuMu_selection\"].GetValue() + cnt[\"ElEl_selection\"].GetValue() + cnt[\"Mu_selection\"].GetValue() + cnt[\"El_selection\"].GetValue()))\n",
    "    subfinish[name] = time.clock()\n",
    "    print(\"====> Took {}s to process sample {}\".format(subfinish[name] - substart[name], name))\n",
    "finish = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Took {}s to process\".format(finish - start))\n",
    "for name, val in substart.items():\n",
    "    print(\"Took {}s to process sample {}\".format(subfinish[name] - substart[name], name))\n",
    "print()\n",
    "masterfinish = time.time() #clock gives cpu time, not accurate multi-core?\n",
    "print(\"Took {}m {}s to process in real-time\".format((masterfinish - masterstart)//60, (masterfinish - masterstart)%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDict = {}\n",
    "histDir = \"test_20200123\"\n",
    "if not os.path.isdir(histDir):\n",
    "    os.makedirs(histDir)\n",
    "for name, levels_dict in histos1D.items():\n",
    "    #if \"DY\" not in name and \"t\" not in name: continue\n",
    "    #if theSampleDict[name][\"isData\"] == True: continue\n",
    "    print(name, end='')\n",
    "    #print(theSampleDict[name].keys())\n",
    "    print(\" - c=\" + str(theSampleDict[name][\"color\"]))\n",
    "    for level, obj_dict in levels_dict.items():\n",
    "        if level not in levels_of_interest: continue\n",
    "        print(\"\\t\" + level)\n",
    "        for pre_obj_name, obj_val in obj_dict[\"Mountains\"].items():\n",
    "            obj_name = \"Mountains_\" + pre_obj_name\n",
    "            print(\"\\t\\t\" + obj_name)\n",
    "            for hname, hist in obj_val.items():\n",
    "                print(\"\\t\\t\\t\" + hname)\n",
    "                #help(hist)\n",
    "                dictKey = pre_obj_name + \"_\" + hname\n",
    "                if dictKey not in rootDict:\n",
    "                    rootDict[dictKey] = ROOT.TFile.Open(\"{}.root\"\\\n",
    "                                 .format(histDir + \"/\" + dictKey), \"RECREATE\")\n",
    "                rootDict[dictKey].cd()\n",
    "                hptr = hist.GetPtr()\n",
    "                oldname = hptr.GetName()\n",
    "                hptr.SetName(\"{}\".format(name))\n",
    "                hptr.Write()\n",
    "                hptr.SetName(\"{}\".format(oldname)) #Avoid overwriting things by switching back, save from segfault\n",
    "                #hptr.SetFillColor(theSampleDict[name][\"color\"])\n",
    "                #hptr.SetLineColor(theSampleDict[name][\"color\"])\n",
    "                #stacks[level][obj_name][hname].Add(hptr)\n",
    "                #stacksource[level][obj_name][hname].append((hptr, hptr.GetIntegral()))\n",
    "                #Integral fails sometimes, use sum of weights...\n",
    "                #if theSampleDict[name][\"isData\"] == False:\n",
    "                #    stacksource[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "                #else:\n",
    "                #    stacksource_data[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "        #for obj_name, obj_val in obj_dict.items():\n",
    "        #    if obj_name == \"Mountains\": continue #extra depth to account for, custom implementation until next version developed\n",
    "        #    print(\"\\t\\t\" + obj_name)\n",
    "        #    for hname, hist in obj_val.items():\n",
    "        #        print(\"\\t\\t\\t\" + hname)\n",
    "        #        #help(hist)\n",
    "        #        hptr = hist.GetPtr().Clone()\n",
    "        #        hptr.SetFillColor(theSampleDict[name][\"color\"])\n",
    "        #        hptr.SetLineColor(theSampleDict[name][\"color\"])\n",
    "        #        #stacks[level][obj_name][hname].Add(hptr)\n",
    "        #        #stacksource[level][obj_name][hname].append((hptr, hptr.GetIntegral()))\n",
    "        #        #Integral fails sometimes, use sum of weights...\n",
    "        #        if theSampleDict[name][\"isData\"] == False:\n",
    "        #            stacksource[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "        #        else:\n",
    "        #            stacksource_data[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "print()\n",
    "for f in rootDict.values():\n",
    "    print(type(f))\n",
    "    f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacks = {}\n",
    "stacksource = {} #Create sortable lists to fill stacks from\n",
    "stacksource_data = {} #create separte list to append all the data to, so that they can be conbined into one hist file and added to the stacksoure at the end\n",
    "model_dict = [histos1D[k] for k in theSampleDict.keys() if theSampleDict[k][\"isData\"] == False]\n",
    "model_dict = model_dict[0]\n",
    "if len(model_dict) < 1:\n",
    "    raise RuntimeError(\"Failure, no histogram dictionary found to form stacks from\")\n",
    "for level, obj_dict in model_dict.items():\n",
    "    if level not in levels_of_interest: continue\n",
    "    stacks[level] = {}\n",
    "    stacksource[level] = {}\n",
    "    stacksource_data[level] = {}\n",
    "    for obj_name, obj_val in obj_dict.items():\n",
    "        if obj_name == \"Mountains\": continue #extra depth to account for, custom implementation until next version developed\n",
    "        stacks[level][obj_name] = {}\n",
    "        stacksource[level][obj_name] = {}\n",
    "        stacksource_data[level][obj_name] = {}\n",
    "        for hname, hist in obj_val.items():\n",
    "            stacks[level][obj_name][hname] = []\n",
    "            stacks[level][obj_name][hname].append(ROOT.THStack(\"s_{}_{}_{}\".format(level, obj_name, hname), \"{}_{}_{}\".format(level, obj_name, hname)))\n",
    "            stacksource[level][obj_name][hname] = []\n",
    "            stacksource_data[level][obj_name][hname] = []\n",
    "    for pre_obj_name, obj_val in obj_dict[\"Mountains\"].items():\n",
    "        obj_name = \"Mountains_\" + pre_obj_name\n",
    "        stacks[level][obj_name] = {}\n",
    "        stacksource[level][obj_name] = {}\n",
    "        stacksource_data[level][obj_name] = {}\n",
    "        for hname, hist in obj_val.items():\n",
    "            stacks[level][obj_name][hname] = []\n",
    "            stacks[level][obj_name][hname].append(ROOT.THStack(\"s_{}_{}_{}\".format(level, obj_name, hname), \"{}_{}_{}\".format(level, obj_name, hname)))\n",
    "            stacksource[level][obj_name][hname] = []\n",
    "            stacksource_data[level][obj_name][hname] = []\n",
    "for name, levels_dict in histos1D.items():\n",
    "    #if \"DY\" not in name and \"t\" not in name: continue\n",
    "    #if theSampleDict[name][\"isData\"] == True: continue\n",
    "    print(name, end='')\n",
    "    #print(theSampleDict[name].keys())\n",
    "    print(\" - c=\" + str(theSampleDict[name][\"color\"]))\n",
    "    for level, obj_dict in levels_dict.items():\n",
    "        if level not in levels_of_interest: continue\n",
    "        print(\"\\t\" + level)\n",
    "        for pre_obj_name, obj_val in obj_dict[\"Mountains\"].items():\n",
    "            obj_name = \"Mountains_\" + pre_obj_name\n",
    "            print(\"\\t\\t\" + obj_name)\n",
    "            for hname, hist in obj_val.items():\n",
    "                print(\"\\t\\t\\t\" + hname)\n",
    "                #help(hist)\n",
    "                hptr = hist.GetPtr().Clone()\n",
    "                hptr.SetFillColor(theSampleDict[name][\"color\"])\n",
    "                hptr.SetLineColor(theSampleDict[name][\"color\"])\n",
    "                #stacks[level][obj_name][hname].Add(hptr)\n",
    "                #stacksource[level][obj_name][hname].append((hptr, hptr.GetIntegral()))\n",
    "                #Integral fails sometimes, use sum of weights...\n",
    "                if theSampleDict[name][\"isData\"] == False:\n",
    "                    stacksource[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "                else:\n",
    "                    stacksource_data[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "        for obj_name, obj_val in obj_dict.items():\n",
    "            if obj_name == \"Mountains\": continue #extra depth to account for, custom implementation until next version developed\n",
    "            print(\"\\t\\t\" + obj_name)\n",
    "            for hname, hist in obj_val.items():\n",
    "                print(\"\\t\\t\\t\" + hname)\n",
    "                #help(hist)\n",
    "                hptr = hist.GetPtr().Clone()\n",
    "                hptr.SetFillColor(theSampleDict[name][\"color\"])\n",
    "                hptr.SetLineColor(theSampleDict[name][\"color\"])\n",
    "                #stacks[level][obj_name][hname].Add(hptr)\n",
    "                #stacksource[level][obj_name][hname].append((hptr, hptr.GetIntegral()))\n",
    "                #Integral fails sometimes, use sum of weights...\n",
    "                if theSampleDict[name][\"isData\"] == False:\n",
    "                    stacksource[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "                else:\n",
    "                    stacksource_data[level][obj_name][hname].append((hptr, hptr.GetSumOfWeights(), theSampleDict[name][\"isData\"]))\n",
    "print()\n",
    "#Now cycle through and sort each list, once it contains all hists from every source (outermost loop - name - above)\n",
    "print(stacksource_data)\n",
    "for level, obj_dict in model_dict.items():\n",
    "    if level not in levels_of_interest: continue\n",
    "    for pre_obj_name, obj_val in obj_dict[\"Mountains\"].items():\n",
    "        obj_name = \"Mountains_\" + pre_obj_name\n",
    "        for hname, hist in obj_val.items():\n",
    "            #Sort the MC-only histograms\n",
    "            stacksource[level][obj_name][hname].sort(key=lambda b: b[1], reverse=False)\n",
    "            \n",
    "            #Create a MC-only histogram for statistics purposes\n",
    "            tmpMC = None\n",
    "            for himc, h_mc in enumerate(stacksource[level][obj_name][hname]):\n",
    "                if himc == 0:\n",
    "                    #take first histo\n",
    "                    tmpMC = h_mc[0].Clone()\n",
    "                    tmpMC.SetTitle(\"MC\")\n",
    "                else:\n",
    "                    #hadd the other histos\n",
    "                    #tmpMC = tmpMC + h_mc[0].Clone()\n",
    "                    tmpMC.Add(h_mc[0].Clone())\n",
    "            if tmpMC != None:\n",
    "                #tmpMC.SetMarkerStyle(0)\n",
    "                tmpMC.SetLineColor(ROOT.kRed)  #FIXME Color from largest sample?\n",
    "                tmpMC.SetFillColorAlpha(ROOT.kRed, 0) #FIXME\n",
    "            stacks[level][obj_name][hname].append(tmpMC)\n",
    "            \n",
    "            tmp = None\n",
    "            for hid, h_data in enumerate(stacksource_data[level][obj_name][hname]):\n",
    "                if hid == 0:\n",
    "                    #take first histo\n",
    "                    tmp = h_data[0].Clone()\n",
    "                    tmp.SetTitle(\"Data\")\n",
    "                else:\n",
    "                    #hadd the other histos\n",
    "                    #tmp = tmp + h_data[0].Clone()\n",
    "                    tmp.Add(h_data[0].Clone())\n",
    "            if tmp != None:\n",
    "                tmp.SetMarkerStyle(0) #20 round dot, with SetMarkerSize(1.0) in an example\n",
    "                tmp.SetLineColor(ROOT.kBlack)\n",
    "                tmp.SetFillColorAlpha(ROOT.kWhite, 0)\n",
    "            stacks[level][obj_name][hname].append(tmp)\n",
    "                \n",
    "            for hptrTup in stacksource[level][obj_name][hname]:\n",
    "                #add to the THStack in the first position of the tuple\n",
    "                stacks[level][obj_name][hname][0].Add(hptrTup[0])\n",
    "    for obj_name, obj_val in obj_dict.items():\n",
    "        if obj_name == \"Mountains\": continue #extra depth to account for, custom implementation until next version developed\n",
    "        for hname, hist in obj_val.items():\n",
    "            #Sort the MC-only histograms\n",
    "            stacksource[level][obj_name][hname].sort(key=lambda b: b[1], reverse=False)\n",
    "            \n",
    "            #Create a MC-only histogram for statistics purposes\n",
    "            tmpMC = None\n",
    "            for himc, h_mc in enumerate(stacksource[level][obj_name][hname]):\n",
    "                if himc == 0:\n",
    "                    #take first histo\n",
    "                    tmpMC = h_mc[0].Clone()\n",
    "                    tmpMC.SetTitle(\"MC\")\n",
    "                else:\n",
    "                    #hadd the other histos\n",
    "                    #tmpMC = tmpMC + h_mc[0].Clone()\n",
    "                    tmpMC.Add(h_mc[0].Clone())\n",
    "            if tmpMC != None:\n",
    "                #tmpMC.SetMarkerStyle(0)\n",
    "                tmpMC.SetLineColor(ROOT.kRed) #FIXME Color set to highest integral's\n",
    "                tmpMC.SetLineWidth(0)\n",
    "                tmpMC.SetFillColorAlpha(ROOT.kRed, 0)\n",
    "            stacks[level][obj_name][hname].append(tmpMC)\n",
    "            \n",
    "            tmp = None\n",
    "            for hid, h_data in enumerate(stacksource_data[level][obj_name][hname]):\n",
    "                if hid == 0:\n",
    "                    #take first histo\n",
    "                    tmp = h_data[0].Clone()\n",
    "                    tmp.SetTitle(\"Data\")\n",
    "                else:\n",
    "                    #hadd the other histos\n",
    "                    #tmp = tmp + h_data[0].Clone()\n",
    "                    tmp.Add(h_data[0].Clone())\n",
    "            if tmp != None:\n",
    "                tmp.SetMarkerStyle(0) #20 round dot, with SetMarkerSize(1.0) in an example\n",
    "                tmp.SetLineColor(ROOT.kBlack)\n",
    "                #tmp.SetFillColorAlpha(ROOT.kWhite, 0)\n",
    "            stacks[level][obj_name][hname].append(tmp)\n",
    "                \n",
    "            for hptrTup in stacksource[level][obj_name][hname]:\n",
    "                #add to the THStack in the first position of the tuple\n",
    "                stacks[level][obj_name][hname][0].Add(hptrTup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2 = ROOT.TCanvas()\n",
    "#c2.cd()\n",
    "#histos2D[\"tttt\"][\"ElMu_selection\"][\"Mountains\"][\"nMediumDeepCSV0\"][\"npvsGood_vs_nTrueInt\"].Draw(\"COLZ\")\n",
    "#c2.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leg = ROOT.TLegend(0.75,0.80, 0.95, 0.90)\n",
    "#leg = ROOT.TLegend(0.15,0.10)\n",
    "#leg.SetFillColor(0)\n",
    "#leg.SetBorderSize(0)\n",
    "leg.SetNColumns(2)\n",
    "leg.SetTextSize(0.03)\n",
    "leg_colors = set([smpl[\"color\"] for smpl in theSampleDict.values()])\n",
    "leg_tuple = [(smpl[0], smpl[1]) for smpl in leg_dict.items() if smpl[1] in leg_colors]\n",
    "leg_hists = {}\n",
    "for samplecategory, color in leg_tuple:\n",
    "    leg_hists[color] = ROOT.TH1D(samplecategory, samplecategory, 0, 0, 1)\n",
    "    if samplecategory != \"Data\":\n",
    "        leg_hists[color].SetFillColor(color)\n",
    "        leg.AddEntry(leg_hists[color], samplecategory, \"F\")\n",
    "    else:\n",
    "        leg.AddEntry(leg_hists[color], samplecategory, \"P\")\n",
    "%jsroot on \n",
    "#help(ROOT.TLegend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%jsroot off\n",
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if obj_name != \"Jets\": continue\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        c.Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        #The `mode` has up to nine digits that can be set to on (1 or 2), off (0).\n",
    " \n",
    "         #mode = ksiourmen  (default = 000001111)\n",
    "         #k = 1;  kurtosis printed\n",
    "         #k = 2;  kurtosis and kurtosis error printed\n",
    "         #s = 1;  skewness printed\n",
    "         #s = 2;  skewness and skewness error printed\n",
    "         #i = 1;  integral of bins printed\n",
    "         #i = 2;  integral of bins with option \"width\" printed\n",
    "         #o = 1;  number of overflows printed\n",
    "         #u = 1;  number of underflows printed\n",
    "         #r = 1;  standard deviation printed\n",
    "         #r = 2;  standard deviation and standard deviation error printed\n",
    "         #m = 1;  mean value printed\n",
    "         #m = 2;  mean and mean error values printed\n",
    "         #e = 1;  number of entries printed\n",
    "         #n = 1;  name of histogram is printed\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[1].Draw(\"SAMES\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        c.SetLogy()\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        c.SetLogy(0)\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if obj_name != \"Muons\": continue\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        c.Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[1].Draw(\"SAMES\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        c.SetLogy()\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        c.SetLogy(0)\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if obj_name != \"Electrons\": continue\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        c.Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[1].Draw(\"SAMES\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        c.SetLogy()\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        c.SetLogy(0)\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if obj_name != \"Leptons\": continue\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        c.Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[1].Draw(\"SAMES\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        c.SetLogy()\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        c.SetLogy(0)\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if obj_name != \"EventVars\": continue\n",
    "    print(obj_name)\n",
    "    for sname, stack in obj_dict.items():\n",
    "        c = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "        c.cd()\n",
    "        c.Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        stack[0].Draw(\"HIST S\")\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[1].Draw(\"SAMES\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Preliminary}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        c.Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None:\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        c.SetLogy()\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        c.SetLogy(0)\n",
    "        c.SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%jsroot on\n",
    "unblind_whitelist = set([])\n",
    "CanvasCache = {}\n",
    "CanvasCache[\"Open/Close\"] = ROOT.TCanvas(\"open_close\", \"\", 800, 100)\n",
    "\n",
    "for obj_name, obj_dict in stacks[\"ElMu_selection\"].items():\n",
    "    if \"Mountains\" not in obj_name: continue\n",
    "    print(obj_name)\n",
    "    CanvasCache[obj_name] = {}\n",
    "    #Save to a pdf using the '.pdf(' string to make a file that stays open for subsequent writes to the same filename. To be closed by '.pdf)' \n",
    "    CanvasCache[\"Open/Close\"].SaveAs(\"./{channel}/{object_name}_All.pdf(\".format(channel=fileChannel.replace(\"_selection\", \"\"), object_name=obj_name.replace(\"Mountains_\", \"\")))\n",
    "    for sname, stack in sorted(obj_dict.items()):\n",
    "        c = None\n",
    "        if \"_vs_\" in sname: #hack to draw 2D histos in the 1D histo dict\n",
    "            CanvasCache[obj_name][sname] = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 1800)\n",
    "            CanvasCache[obj_name][sname].Divide(1,3)\n",
    "            CanvasCache[obj_name][sname].cd(1)\n",
    "        else:\n",
    "        #if True:\n",
    "            CanvasCache[obj_name][sname] = ROOT.TCanvas(\"cs_{}_{}\".format(obj_name, sname), \"\", 800, 600)\n",
    "            CanvasCache[obj_name][sname].cd()\n",
    "        CanvasCache[obj_name][sname].SetLogy()\n",
    "        CanvasCache[obj_name][sname].Update()\n",
    "        #For data first\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1\")\n",
    "        #    stack[0].Draw(\"HIST SAME\")\n",
    "        #else:\n",
    "        #    stack[0].Draw(\"HIST\")\n",
    "        #if len(stack) > 1:\n",
    "        #    stack[1].Draw(\"PE1 SAME\")\n",
    "        #for MC first\n",
    "        if \"_vs_\" in sname: #hack to draw 2D histos in the 1D histo dict\n",
    "            stack[0].Draw(\"\")\n",
    "        else:\n",
    "            stack[0].Draw(\"HIST S\")\n",
    "        #Draw the MC summed histogram for stats (better way with THStack? why the fuck don't people document this in a useful way?)\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            if \"_vs_\" in sname: #hack to draw 2D histos in the 1D histo dict\n",
    "                stack[1].Draw(\"SAMES\") #Also SAME0, SAMES0 which 'do not use the z axis of the previous plot'\n",
    "                CanvasCache[obj_name][sname].cd(2)\n",
    "                tmp1 = stack[1].Clone()\n",
    "                tmp1.SetLineColor(ROOT.kBlue)\n",
    "                tmp1.SetFillColorAlpha(ROOT.kGreen, 0.7)\n",
    "                tmp1.Draw(\"VIOLINX\")\n",
    "                #stack[1].ProfileX().Draw(\"E3\")\n",
    "                CanvasCache[obj_name][sname].cd(3)\n",
    "                tmp1.Draw(\"VIOLINY\")\n",
    "                #stack[1].ProfileY().Draw(\"E3\")\n",
    "                CanvasCache[obj_name][sname].cd(1)\n",
    "            else:\n",
    "                stack[1].Draw(\"SAMES HIST\")\n",
    "        #Draw the data histogram, assuming that it's unblinded (\"blind\" not in the name and or in the whitelist )\n",
    "        if len(stack) > 2 and stack[2] != None and (\"blind\" not in obj_name or obj_name in unblind_whitelist):\n",
    "            ROOT.gStyle.SetOptStat(1111111)\n",
    "            if \"_vs_\" in sname: #hack to draw 2D histos in the 1D histo dict\n",
    "                stack[2].Draw(\"SAMES\") #Maybe add ARR for arrow mode? or something else\n",
    "                CanvasCache[obj_name][sname].cd(2)\n",
    "                tmp2 = stack[2].Clone()\n",
    "                tmp2.SetLineColor(ROOT.kRed)\n",
    "                tmp2.SetFillColorAlpha(ROOT.kGray, 0.4)\n",
    "                tmp2.Draw(\"SAMES CANDLEX\")\n",
    "                #stack[2].ProfileX().Draw(\"PE1 SAMES\")\n",
    "                CanvasCache[obj_name][sname].cd(3)\n",
    "                tmp2.Draw(\"SAMES CANDLEY\")\n",
    "                #stack[2].ProfileY().Draw(\"PE1 SAMES\")\n",
    "                CanvasCache[obj_name][sname].cd(1)\n",
    "            else:\n",
    "                stack[2].Draw(\"PE1 SAMES\")\n",
    "        # Add header\n",
    "        cms_label = ROOT.TLatex()\n",
    "        cms_label.SetTextSize(0.04)\n",
    "        cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Internal}\")\n",
    "        header = ROOT.TLatex()\n",
    "        header.SetTextSize(0.03)\n",
    "        header.DrawLatexNDC(0.63, 0.92, \"#sqrt{{s}} = 13 TeV, L_{{int}} = {0} fb^{{-1}}\".format(lumi[era]))\n",
    "        leg.Draw()\n",
    "        CanvasCache[obj_name][sname].Draw()\n",
    "        if len(stack) > 1 and stack[1] != None:\n",
    "            ROOT.gStyle.SetOptStat(1001111)\n",
    "            StatBox = stack[1].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.7)\n",
    "            StatBox.SetY2NDC(0.5)\n",
    "            #StatBox.SetName(\"MC\")\n",
    "        if len(stack) > 2 and stack[2] != None and (\"blind\" not in obj_name or obj_name in unblind_whitelist):\n",
    "            #ROOT.gStyle.SetOptStat(111111)\n",
    "            StatBox = stack[2].GetListOfFunctions().FindObject(\"stats\")\n",
    "            StatBox.SetY1NDC(0.5)\n",
    "            StatBox.SetY2NDC(0.3)\n",
    "            #StatBox.SetLabel(\"Data\")\n",
    "\n",
    "        if not os.path.isdir(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name)):\n",
    "            os.makedirs(\"./{channel}/{object_name}/\".format(channel=fileChannel, object_name=obj_name))\n",
    "        CanvasCache[obj_name][sname].SetLogy()\n",
    "        CanvasCache[obj_name][sname].SaveAs(\"./{channel}/{object_name}/{hname}_LOGY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        CanvasCache[obj_name][sname].SaveAs(\"./{channel}/{object_name}_All.pdf\".format(channel=fileChannel.replace(\"_selection\", \"\"), object_name=obj_name.replace(\"Mountains_\", \"\"), wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        CanvasCache[obj_name][sname].SetLogy(0)\n",
    "        CanvasCache[obj_name][sname].SaveAs(\"./{channel}/{object_name}/{hname}_LINY{filetype}\".format(channel=fileChannel, object_name=obj_name, wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "        CanvasCache[obj_name][sname].SaveAs(\"./{channel}/{object_name}_All.pdf\".format(channel=fileChannel.replace(\"_selection\", \"\"), object_name=obj_name.replace(\"Mountains_\", \"\"), wgtVar=theWeight, hname=sname, filetype=theFormat))\n",
    "    #Close the pdf using '.pdf)' \n",
    "    CanvasCache[\"Open/Close\"].SaveAs(\"./{channel}/{object_name}_All.pdf)\".format(channel=fileChannel.replace(\"_selection\", \"\"), object_name=obj_name.replace(\"Mountains_\", \"\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterfinish2 = time.time() #clock gives cpu time, not accurate multi-core?\n",
    "print(\"Took {}m {}s to process in real-time including plots\".format((masterfinish2 - masterstart)//60, (masterfinish - masterstart)%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From example: https://root.cern.ch/doc/master/df103__NanoAODHiggsAnalysis_8py_source.html\n",
    "\n",
    "#def plot(sig, bkg, data, x_label, filename):\n",
    "#     \"\"\"\n",
    "#     Plot invariant mass for signal and background processes from simulated\n",
    "#     events overlay the measured data.\n",
    "#     \"\"\"\n",
    "#     # Canvas and general style options\n",
    "#     ROOT.gStyle.SetOptStat(0)\n",
    "#     ROOT.gStyle.SetTextFont(42)\n",
    "#     d = ROOT.TCanvas(\"d\", \"\", 800, 700)\n",
    "#     d.SetLeftMargin(0.15)\n",
    "# \n",
    "#     # Get signal and background histograms and stack them to show Higgs signal\n",
    "#     # on top of the background process\n",
    "#     h_bkg = bkg\n",
    "#     h_cmb = sig.Clone()\n",
    "# \n",
    "#     h_cmb.Add(h_bkg)\n",
    "#     h_cmb.SetTitle(\"\")\n",
    "#     h_cmb.GetXaxis().SetTitle(x_label)\n",
    "#     h_cmb.GetXaxis().SetTitleSize(0.04)\n",
    "#     h_cmb.GetYaxis().SetTitle(\"N_{Events}\")\n",
    "#     h_cmb.GetYaxis().SetTitleSize(0.04)\n",
    "#     h_cmb.SetLineColor(ROOT.kRed)\n",
    "#     h_cmb.SetLineWidth(2)\n",
    "#     h_cmb.SetMaximum(18)\n",
    "#     h_bkg.SetLineWidth(2)\n",
    "#     h_bkg.SetFillStyle(1001)\n",
    "#     h_bkg.SetLineColor(ROOT.kBlack)\n",
    "#     h_bkg.SetFillColor(ROOT.kAzure - 9)\n",
    "# \n",
    "#     # Get histogram of data points\n",
    "#     h_data = data\n",
    "#     h_data.SetLineWidth(1)\n",
    "#     h_data.SetMarkerStyle(20)\n",
    "#     h_data.SetMarkerSize(1.0)\n",
    "#     h_data.SetMarkerColor(ROOT.kBlack)\n",
    "#     h_data.SetLineColor(ROOT.kBlack)\n",
    "# \n",
    "#     # Draw histograms\n",
    "#     h_cmb.DrawCopy(\"HIST\")\n",
    "#     h_bkg.DrawCopy(\"HIST SAME\")\n",
    "#     h_data.DrawCopy(\"PE1 SAME\")\n",
    "# \n",
    "#     # Add legend\n",
    "#     legend = ROOT.TLegend(0.62, 0.70, 0.82, 0.88)\n",
    "#     legend.SetFillColor(0)\n",
    "#     legend.SetBorderSize(0)\n",
    "#     legend.SetTextSize(0.03)\n",
    "#     legend.AddEntry(h_data, \"Data\", \"PE1\")\n",
    "#     legend.AddEntry(h_bkg, \"ZZ\", \"f\")\n",
    "#     legend.AddEntry(h_cmb, \"m_{H} = 125 GeV\", \"f\")\n",
    "#     legend.Draw()\n",
    "# \n",
    "#     # Add header\n",
    "#     cms_label = ROOT.TLatex()\n",
    "#     cms_label.SetTextSize(0.04)\n",
    "#     cms_label.DrawLatexNDC(0.16, 0.92, \"#bf{CMS Open Data}\")\n",
    "#     header = ROOT.TLatex()\n",
    "#     header.SetTextSize(0.03)\n",
    "#     header.DrawLatexNDC(0.63, 0.92, \"#sqrt{s} = 8 TeV, L_{int} = 11.6 fb^{-1}\")\n",
    "# \n",
    "#     # Save plot\n",
    "#     d.SaveAs(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gg1 = ROOT.ROOT.RDF.SaveGraph(the_df['tttt']['ElMu_selection'], './mydot.dot')\n",
    "#!dot -Tsvg mydot.dot -o mydot.svg\n",
    "#listOfImageNames = ['./mydot.svg',\n",
    "#                    ]\n",
    "#\n",
    "#for imageName in listOfImageNames:\n",
    "#    display(SVG(filename=imageName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = ROOT.TCanvas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacks[\"ElMu_selection\"][\"Mountains_nMediumDeepJet0\"][\"Muon_pfRelIso03_chg_vs_MET\"]\n",
    "#stacksource_data[\"ElMu_selection\"][\"Mountains_nMediumDeepJet0\"][\"Muon_pfRelIso03_chg_vs_MET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
